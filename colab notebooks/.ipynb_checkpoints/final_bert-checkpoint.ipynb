{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "nfwylcitNI-f",
    "outputId": "85ca403a-6ca2-467e-da9c-ad4c79059f64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive \n",
    "#drive.mount('/content/gdrive') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "z7JzdJTaPTXw",
    "outputId": "0719dbba-b3e3-451b-b808-eadb1d3b37ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "#%cd /content/gdrive/My\\ Drive/Colab\\ Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "gPqtorpvPc3w",
    "outputId": "e73cf9bc-3082-4347-b3d1-f7eedf53283d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\r",
      "\u001b[K     |██▋                             | 10kB 19.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 20kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 30kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 40kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 51kB 5.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 61kB 6.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 71kB 6.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 81kB 7.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 92kB 6.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 102kB 6.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 112kB 6.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 122kB 6.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 133kB 6.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.38.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.12.38)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.15.38)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.5)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (1.12.0)\n",
      "Installing collected packages: pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "8IR7rJSTPc1P",
    "outputId": "1822a997-519c-4ff7-9c0a-512e6d7008f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-nlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
      "\r",
      "\u001b[K     |███▋                            | 10kB 17.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 20kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 30kB 5.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 40kB 5.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 51kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 61kB 5.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 71kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 81kB 6.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 92kB 4.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (1.18.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (4.38.0)\n",
      "Installing collected packages: pytorch-nlp\n",
      "Successfully installed pytorch-nlp-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "sJ9tMsO0n6aT",
    "outputId": "cb5738e9-6b4d-4306-ca32-463a7e2e1681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown==3.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/12/33/e9f21d0b3f85804ca570d124fb7a80c12a99948ff495cf54dfb72f18bf9e/gdown-3.6.0.tar.gz\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown==3.6.0) (2.21.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown==3.6.0) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown==3.6.0) (4.38.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (1.24.3)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gdown: filename=gdown-3.6.0-cp36-none-any.whl size=5238 sha256=88dddda3e883807f3ab8252aa25631b02dfec498bb1cd1142622b89f6b0245e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/97/90/fa/25654eb65da3e6da7752db71a164e0eb8f7a6fb4335eeb46ab\n",
      "Successfully built gdown\n",
      "Installing collected packages: gdown\n",
      "  Found existing installation: gdown 3.6.4\n",
      "    Uninstalling gdown-3.6.4:\n",
      "      Successfully uninstalled gdown-3.6.4\n",
      "Successfully installed gdown-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "4tJMDaweoj_n",
    "outputId": "52c92268-55c5-43d5-c140-ef9d02fe7880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-0hjozQqjknhLIm67uhKdFBJUHNfiIrD\n",
      "To: /content/gdrive/My Drive/Colab Notebooks/fake_news_bert2.pt\n",
      "438MB [00:02, 155MB/s]\n"
     ]
    }
   ],
   "source": [
    "#filename = \"https://drive.google.com/file/d/1mHW0zXK6gzJs0nQUle_yrWqiAHKOORUI/view\"\n",
    "#filename2 = https://drive.google.com/open?id=1-0hjozQqjknhLIm67uhKdFBJUHNfiIrD\n",
    "#fid = \"1mHW0zXK6gzJs0nQUle_yrWqiAHKOORUI\"\n",
    "fid = \"1-0hjozQqjknhLIm67uhKdFBJUHNfiIrD\"\n",
    "!gdown https://drive.google.com/uc?id={fid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "60sufl1rPcwS",
    "outputId": "41926c65-844e-45aa-f675-00a44d10df83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch.nn as nn\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torchnlp.datasets import imdb_dataset\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter \n",
    "import http.client\n",
    "import json\n",
    "\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-w4OWHMk0dO"
   },
   "outputs": [],
   "source": [
    "server = \"stark-anchorage-45962.herokuapp.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuvLX0Y1Pcu3"
   },
   "outputs": [],
   "source": [
    "def get_data(link_conn) :\n",
    "    try :\n",
    "        conn = http.client.HTTPSConnection(link_conn)\n",
    "    except :\n",
    "        conn = http.client.HTTPSConnection('localhost:5000')\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    conn.request('GET', '/getAllUntestedPosts', None, headers)\n",
    "    response = conn.getresponse()\n",
    "    return response.read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCNvbpM5Pcs6"
   },
   "outputs": [],
   "source": [
    "class BertBinaryClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(BertBinaryClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, tokens, masks=None):\n",
    "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        proba = self.sigmoid(linear_output)\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HHcIF2N3Pcp7"
   },
   "outputs": [],
   "source": [
    "def training(batch_size, epoch_size, filename) :\n",
    "    '''very unethical way of loading and traing the data in same function'''\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    train_data, test_data = imdb_dataset(train=True, test=True)\n",
    "    df = pd.read_csv(\"./fake-news/fake.csv\")\n",
    "    df = df[['text', 'type']]\n",
    "    #print(len(df))\n",
    "\n",
    "    #print(Counter(df['type'].values))\n",
    "\n",
    "    df = df[df['type'].isin(['fake', 'satire'])]\n",
    "    df.dropna(inplace = True)\n",
    "    df_fake = df[df['type'] == 'fake'] \n",
    "    df_statire = df[df['type'] == 'satire'] \n",
    "    df_statire = df_statire.sample(n=len(df_fake))\n",
    "    df = df_statire.append(df_fake)\n",
    "    df = df.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
    "\n",
    "    #print(Counter(df['type'].values))\n",
    "\n",
    "    train_data = df.head(19)\n",
    "    test_data = df.tail(19)\n",
    "\n",
    "    #print(train_data)\n",
    "    train_data = [{'text': text, 'type': type_data } for text in list(train_data['text']) for type_data in list(train_data['type'])]\n",
    "    test_data = [{'text': text, 'type': type_data } for text in list(test_data['text']) for type_data in list(test_data['type'])]\n",
    "\n",
    "    train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['type']), train_data)))\n",
    "    test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['type']), test_data)))\n",
    "\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], train_texts))\n",
    "    test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], test_texts))\n",
    "\n",
    "    train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))\n",
    "    test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))\n",
    "\n",
    "\n",
    "\n",
    "    train_tokens_ids = pad_sequences(train_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "    test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "\n",
    "\n",
    "    train_y = np.array(train_labels) == 'fake'\n",
    "    test_y = np.array(test_labels) == 'fake'\n",
    "    \n",
    "    BATCH_SIZE = batch_size\n",
    "    EPOCHS = epoch_size\n",
    "\n",
    "\n",
    "    train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
    "    test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
    "    train_masks_tensor = torch.tensor(train_masks)\n",
    "    test_masks_tensor = torch.tensor(test_masks)\n",
    "\n",
    "    train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
    "    train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
    "    test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
    "    test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
    "    train_dataset =  torch.utils.data.TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
    "    train_sampler =  torch.utils.data.RandomSampler(train_dataset)\n",
    "    train_dataloader =  torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "    test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
    "    test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
    "    test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    bert_clf = BertBinaryClassifier()\n",
    "    optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
    "    bert_clf = bert_clf.to(device)\n",
    "    for epoch_num in range(EPOCHS):\n",
    "        bert_clf.train()\n",
    "        train_loss = 0\n",
    "        for step_num, batch_data in enumerate(train_dataloader):\n",
    "            token_ids, masks, labels = tuple(t for t in batch_data)\n",
    "            token_ids = token_ids.to(device)\n",
    "            masks = masks.to(device)\n",
    "            labels = labels.to(device)\n",
    "            probas = bert_clf(token_ids, masks)\n",
    "            loss_func = nn.BCELoss()\n",
    "            batch_loss = loss_func(probas, labels)\n",
    "            train_loss += batch_loss.item()\n",
    "            bert_clf.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            print('Epoch: ', epoch_num + 1)\n",
    "            print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
    "\n",
    "    torch.save(bert_clf, filename)\n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVUlg0oxPcny"
   },
   "outputs": [],
   "source": [
    "def testing(df, filename) :\n",
    "    \n",
    "    #input\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    l = len(df)\n",
    "    lst = []\n",
    "    if(l%2 == 1):\n",
    "        for i in range(l) :\n",
    "            if(i%2 == 1) :\n",
    "                lst.append('fake')\n",
    "            else:\n",
    "                lst.append('satire')\n",
    "    else :\n",
    "        for i in range(l) :\n",
    "            if(i%2 == 0) :\n",
    "                lst.append('fake')\n",
    "            else:\n",
    "                lst.append('satire')\n",
    "    df['type'] = lst\n",
    "    test_data = df\n",
    "    test_data1 = [{'text': text, 'type': \"\"} for text in list(test_data['text']) ]\n",
    "\n",
    "    i = 0\n",
    "    for type_data in list(test_data['type']) :\n",
    "        test_data1[i]['type'] = type_data\n",
    "        i = i + 1\n",
    "        \n",
    "    test_data = test_data1\n",
    "    test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['type']), test_data)))\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], test_texts))\n",
    "    test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))\n",
    "    test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "    test_y = np.array(test_labels) == 'fake'\n",
    "    test_y = torch.from_numpy(np.array(test_y, dtype=np.uint8))\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    \n",
    "    test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
    "    test_masks_tensor = torch.tensor(test_masks)\n",
    "    test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
    "    test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
    "    test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
    "    test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
    "    test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "    bert_clf = BertBinaryClassifier()\n",
    "    optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
    "    bert_clf = torch.load(filename)\n",
    "    bert_clf = bert_clf.to(device)\n",
    "    bert_clf.eval()\n",
    "    bert_predicted = []\n",
    "    all_logits = []\n",
    "    lst = []\n",
    "    with torch.no_grad():\n",
    "        for step_num, batch_data in enumerate(test_dataloader):\n",
    "\n",
    "            token_ids, masks, labels = tuple(t for t in batch_data)\n",
    "            token_ids = token_ids.to(device)\n",
    "            masks = masks.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = bert_clf(token_ids, masks)\n",
    "            logits = logits.to(device)\n",
    "            \n",
    "            loss_func = nn.BCELoss()\n",
    "            loss = loss_func(logits, labels)\n",
    "            numpy_logits = logits.cpu().detach().numpy()\n",
    "            lst.append(numpy_logits)\n",
    "\n",
    "            bert_predicted += list(numpy_logits[:, 0])\n",
    "            all_logits += list(numpy_logits[:, 0])\n",
    "\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u_eFqU6hPtpd"
   },
   "outputs": [],
   "source": [
    "'''def fake_post(article, score, link_conn) :\n",
    "    try :\n",
    "        conn = http.client.HTTPSConnection(link_conn)\n",
    "    except :\n",
    "        conn = http.client.HTTPSConnection('localhost:5000')\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    data = article\n",
    "    if(score > 0.5) :\n",
    "      data['fake'] = \"True\"\n",
    "    else:\n",
    "      data['fake'] = \"False\"\n",
    "    data['fakeness'] = str(score)\n",
    "    json_data = json.dumps(data)\n",
    "    conn.request('POST', '/fakePost', json_data, headers)\n",
    "    response = conn.getresponse()\n",
    "    print(response.read().decode())\n",
    "    return\n",
    "  \n",
    "def true_post(article, score, link_conn) :\n",
    "    try :\n",
    "        conn = http.client.HTTPSConnection(link_conn)\n",
    "    except :\n",
    "        conn = http.client.HTTPSConnection('localhost:5000')\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    data = article\n",
    "    if(score > 0.5) :\n",
    "      data['fake'] = \"True\"\n",
    "    else:\n",
    "      data['fake'] = \"False\"\n",
    "    data['fakeness'] = str(score)\n",
    "    json_data = json.dumps(data)\n",
    "    conn.request('POST', '/testedPost', json_data, headers)\n",
    "    response = conn.getresponse()\n",
    "    print(response.read().decode())\n",
    "    return'''\n",
    "\n",
    "\n",
    "def display(article, score, link_conn) :\n",
    "    try :\n",
    "        conn = http.client.HTTPSConnection(link_conn)\n",
    "    except :\n",
    "        conn = http.client.HTTPSConnection('localhost:5000')\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    data = dict()\n",
    "    data['url'] = article['url']\n",
    "    data['fakeness'] = str(score)\n",
    "    json_data = json.dumps(data)\n",
    "    conn.request('POST', '/fakePost', json_data, headers)\n",
    "    response = conn.getresponse()\n",
    "    print(response.read().decode())\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "45G9AGLSPtnY",
    "outputId": "46ba0283-fb4b-493b-9695-12d5e3caa3bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def malicious_url_detector(lst_url, link_conn) :\\n    lst = []\\n    for t in lst_url :\\n        lst.append(t[\\'url\\'])\\n    df = pd.DataFrame(lst, columns=[\"url\"])\\n    test_data = df[\\'url\\']\\n    data = pd.read_csv(\"./data/url.csv\")\\n    y = data[\"label\"]\\n    url_list = data[\"url\"]\\n    # Using Tokenizer\\n    vectorizer = TfidfVectorizer()\\n    # Store vectors into X variable as Our XFeatures\\n    X = vectorizer.fit_transform(url_list)\\n    # Split into training and testing dataset 80:20 ratio\\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n    # Model Building using logistic regression\\n    logit = LogisticRegression()\\n    logit.fit(X, y)\\n    vectorizer = TfidfVectorizer()\\n    test_data = vectorizer.fit_transform(lst)\\n    scores = logit.predict(test_data)\\n    i = 0\\n    limit = 0\\n    for article in lst_bert :\\n        limit = limit + 1\\n        if(limit == 20) :\\n            time.sleep(61)\\n            limit = 0\\n        if(scores[i] > 0.5 ) :\\n            fake_post(article, scores[i], link_conn)\\n        else :\\n            true_post(article, scores[i], link_conn)\\n        i = i + 1\\n    return'"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def using_bert(lst_bert, filename, link_conn) :\n",
    "    lst = []\n",
    "    original = []\n",
    "    for t in lst_bert :\n",
    "        try:\n",
    "          lst.append(t['text'])\n",
    "          original.append(t)\n",
    "        except:\n",
    "          continue\n",
    "    df = pd.DataFrame(lst, columns=[\"text\"])\n",
    "    scores = testing(df, filename)\n",
    "    #scores = scores.tolist()\n",
    "    '''print(len(scores))\n",
    "    print(len(original))\n",
    "    print(len(lst))\n",
    "    print(len(lst_bert))'''\n",
    "    i = 0\n",
    "    #limit = 0\n",
    "    for article in original :\n",
    "        #limit = limit + 1\n",
    "        #if(limit == 20) :\n",
    "        #    tiime.sleep(61)\n",
    "        #    limit = 0\n",
    "        '''if(scores[i] > 0.5 ) :\n",
    "            fake_post(article, scores[i], link_conn)\n",
    "        else :\n",
    "            true_post(article, scores[i], link_conn)'''\n",
    "        #print(scores[i][0][0])\n",
    "        display(article, str(scores[i][0][0]), link_conn)\n",
    "        i = i + 1\n",
    "    return\n",
    "            \n",
    "'''def malicious_url_detector(lst_url, link_conn) :\n",
    "    lst = []\n",
    "    for t in lst_url :\n",
    "        lst.append(t['url'])\n",
    "    df = pd.DataFrame(lst, columns=[\"url\"])\n",
    "    test_data = df['url']\n",
    "    data = pd.read_csv(\"./data/url.csv\")\n",
    "    y = data[\"label\"]\n",
    "    url_list = data[\"url\"]\n",
    "    # Using Tokenizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # Store vectors into X variable as Our XFeatures\n",
    "    X = vectorizer.fit_transform(url_list)\n",
    "    # Split into training and testing dataset 80:20 ratio\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # Model Building using logistic regression\n",
    "    logit = LogisticRegression()\n",
    "    logit.fit(X, y)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    test_data = vectorizer.fit_transform(lst)\n",
    "    scores = logit.predict(test_data)\n",
    "    i = 0\n",
    "    limit = 0\n",
    "    for article in lst_bert :\n",
    "        limit = limit + 1\n",
    "        if(limit == 20) :\n",
    "            time.sleep(61)\n",
    "            limit = 0\n",
    "        if(scores[i] > 0.5 ) :\n",
    "            fake_post(article, scores[i], link_conn)\n",
    "        else :\n",
    "            true_post(article, scores[i], link_conn)\n",
    "        i = i + 1\n",
    "    return'''\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BoPuFp5PtlW"
   },
   "outputs": [],
   "source": [
    "def run() :\n",
    "  data = get_data(server) \n",
    "  data = json.loads(data)\n",
    "  lst_bert = []\n",
    "  #lst_url = []\n",
    "  for article in data:\n",
    "    lst_bert.append(article)\n",
    "  if(len(lst_bert) != 0):\n",
    "      #using_bert(lst_bert, \"/content/fake_news_bert.pt\", server)\n",
    "      using_bert(lst_bert, \"./fake_news_bert2.pt\", server)\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "UWbRT4laouBL",
    "outputId": "f76d60c4-1738-477e-ccdb-e7f6aaca3824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while(1) :\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m42fXjxrq2l9",
    "outputId": "4bbf1948-714f-4c7b-a68b-fbb6901d6970"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 700691.61B/s]\n",
      "100%|██████████| 407873900/407873900 [00:14<00:00, 29112933.10B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "27/361.0 loss: 0.6895899666207177 \n",
      "Epoch:  44\n",
      "28/361.0 loss: 0.6872089854602156 \n",
      "Epoch:  44\n",
      "29/361.0 loss: 0.6842895448207855 \n",
      "Epoch:  44\n",
      "30/361.0 loss: 0.6826097311512116 \n",
      "Epoch:  44\n",
      "31/361.0 loss: 0.6859509125351906 \n",
      "Epoch:  44\n",
      "32/361.0 loss: 0.6864682309555284 \n",
      "Epoch:  44\n",
      "33/361.0 loss: 0.6875203111592461 \n",
      "Epoch:  44\n",
      "34/361.0 loss: 0.6860725215503147 \n",
      "Epoch:  44\n",
      "35/361.0 loss: 0.6869102468093237 \n",
      "Epoch:  44\n",
      "36/361.0 loss: 0.6873726957553142 \n",
      "Epoch:  44\n",
      "37/361.0 loss: 0.6887381453263132 \n",
      "Epoch:  44\n",
      "38/361.0 loss: 0.6873731735425118 \n",
      "Epoch:  44\n",
      "39/361.0 loss: 0.6863726049661636 \n",
      "Epoch:  44\n",
      "40/361.0 loss: 0.6845256628059759 \n",
      "Epoch:  44\n",
      "41/361.0 loss: 0.682696187780017 \n",
      "Epoch:  44\n",
      "42/361.0 loss: 0.6841673698536185 \n",
      "Epoch:  44\n",
      "43/361.0 loss: 0.6859273747964338 \n",
      "Epoch:  44\n",
      "44/361.0 loss: 0.6846403439839681 \n",
      "Epoch:  44\n",
      "45/361.0 loss: 0.6835963907449142 \n",
      "Epoch:  44\n",
      "46/361.0 loss: 0.6825515209360326 \n",
      "Epoch:  44\n",
      "47/361.0 loss: 0.6812029232581457 \n",
      "Epoch:  44\n",
      "48/361.0 loss: 0.6808509486062186 \n",
      "Epoch:  44\n",
      "49/361.0 loss: 0.6812545311450958 \n",
      "Epoch:  44\n",
      "50/361.0 loss: 0.6819358818671283 \n",
      "Epoch:  44\n",
      "51/361.0 loss: 0.6817090545709317 \n",
      "Epoch:  44\n",
      "52/361.0 loss: 0.6810556054115295 \n",
      "Epoch:  44\n",
      "53/361.0 loss: 0.6801240212387509 \n",
      "Epoch:  44\n",
      "54/361.0 loss: 0.6788986444473266 \n",
      "Epoch:  44\n",
      "55/361.0 loss: 0.6786556584494454 \n",
      "Epoch:  44\n",
      "56/361.0 loss: 0.6792708049740708 \n",
      "Epoch:  44\n",
      "57/361.0 loss: 0.678940165659477 \n",
      "Epoch:  44\n",
      "58/361.0 loss: 0.6803754184205654 \n",
      "Epoch:  44\n",
      "59/361.0 loss: 0.6802793542544047 \n",
      "Epoch:  44\n",
      "60/361.0 loss: 0.6789125184543797 \n",
      "Epoch:  44\n",
      "61/361.0 loss: 0.6805137395858765 \n",
      "Epoch:  44\n",
      "62/361.0 loss: 0.6793871219196017 \n",
      "Epoch:  44\n",
      "63/361.0 loss: 0.6803240589797497 \n",
      "Epoch:  44\n",
      "64/361.0 loss: 0.6809663900962243 \n",
      "Epoch:  44\n",
      "65/361.0 loss: 0.6815071340763208 \n",
      "Epoch:  44\n",
      "66/361.0 loss: 0.6827183152312664 \n",
      "Epoch:  44\n",
      "67/361.0 loss: 0.6818946433417937 \n",
      "Epoch:  44\n",
      "68/361.0 loss: 0.6806185746538467 \n",
      "Epoch:  44\n",
      "69/361.0 loss: 0.6816380722182137 \n",
      "Epoch:  44\n",
      "70/361.0 loss: 0.6807463731564266 \n",
      "Epoch:  44\n",
      "71/361.0 loss: 0.6813911605212424 \n",
      "Epoch:  44\n",
      "72/361.0 loss: 0.6806668059466636 \n",
      "Epoch:  44\n",
      "73/361.0 loss: 0.6795549948473234 \n",
      "Epoch:  44\n",
      "74/361.0 loss: 0.6791362293561299 \n",
      "Epoch:  44\n",
      "75/361.0 loss: 0.677984923908585 \n",
      "Epoch:  44\n",
      "76/361.0 loss: 0.6799952519404424 \n",
      "Epoch:  44\n",
      "77/361.0 loss: 0.680647224952013 \n",
      "Epoch:  44\n",
      "78/361.0 loss: 0.6798933472814439 \n",
      "Epoch:  44\n",
      "79/361.0 loss: 0.6788313567638398 \n",
      "Epoch:  44\n",
      "80/361.0 loss: 0.6780879460735085 \n",
      "Epoch:  44\n",
      "81/361.0 loss: 0.6796070184649491 \n",
      "Epoch:  44\n",
      "82/361.0 loss: 0.6811144861830286 \n",
      "Epoch:  44\n",
      "83/361.0 loss: 0.6804030544701076 \n",
      "Epoch:  44\n",
      "84/361.0 loss: 0.6817319561453427 \n",
      "Epoch:  44\n",
      "85/361.0 loss: 0.6805524729018988 \n",
      "Epoch:  44\n",
      "86/361.0 loss: 0.6799965918749228 \n",
      "Epoch:  44\n",
      "87/361.0 loss: 0.6789076003161344 \n",
      "Epoch:  44\n",
      "88/361.0 loss: 0.6780308639065603 \n",
      "Epoch:  44\n",
      "89/361.0 loss: 0.6774714317586686 \n",
      "Epoch:  44\n",
      "90/361.0 loss: 0.6763826150160569 \n",
      "Epoch:  44\n",
      "91/361.0 loss: 0.6753893183625262 \n",
      "Epoch:  44\n",
      "92/361.0 loss: 0.6761459765895721 \n",
      "Epoch:  44\n",
      "93/361.0 loss: 0.6771676527692917 \n",
      "Epoch:  44\n",
      "94/361.0 loss: 0.6761367477868733 \n",
      "Epoch:  44\n",
      "95/361.0 loss: 0.6752777000268301 \n",
      "Epoch:  44\n",
      "96/361.0 loss: 0.6746608129481679 \n",
      "Epoch:  44\n",
      "97/361.0 loss: 0.6756319233349392 \n",
      "Epoch:  44\n",
      "98/361.0 loss: 0.6767319519110401 \n",
      "Epoch:  44\n",
      "99/361.0 loss: 0.6757524102926254 \n",
      "Epoch:  44\n",
      "100/361.0 loss: 0.675092091654787 \n",
      "Epoch:  44\n",
      "101/361.0 loss: 0.6765059267773348 \n",
      "Epoch:  44\n",
      "102/361.0 loss: 0.6759148326892297 \n",
      "Epoch:  44\n",
      "103/361.0 loss: 0.6765093837793057 \n",
      "Epoch:  44\n",
      "104/361.0 loss: 0.6758236340114049 \n",
      "Epoch:  44\n",
      "105/361.0 loss: 0.6750910141558017 \n",
      "Epoch:  44\n",
      "106/361.0 loss: 0.6739156931360192 \n",
      "Epoch:  44\n",
      "107/361.0 loss: 0.6753783844135426 \n",
      "Epoch:  44\n",
      "108/361.0 loss: 0.6760787619363278 \n",
      "Epoch:  44\n",
      "109/361.0 loss: 0.6772256433963776 \n",
      "Epoch:  44\n",
      "110/361.0 loss: 0.6785067464854266 \n",
      "Epoch:  44\n",
      "111/361.0 loss: 0.6778845260185855 \n",
      "Epoch:  44\n",
      "112/361.0 loss: 0.6767018500682527 \n",
      "Epoch:  44\n",
      "113/361.0 loss: 0.6762320007148542 \n",
      "Epoch:  44\n",
      "114/361.0 loss: 0.6775414772655652 \n",
      "Epoch:  44\n",
      "115/361.0 loss: 0.6785466809724939 \n",
      "Epoch:  44\n",
      "116/361.0 loss: 0.680348918478713 \n",
      "Epoch:  44\n",
      "117/361.0 loss: 0.6796625322204525 \n",
      "Epoch:  44\n",
      "118/361.0 loss: 0.6806823340784601 \n",
      "Epoch:  44\n",
      "119/361.0 loss: 0.6801848714550336 \n",
      "Epoch:  44\n",
      "120/361.0 loss: 0.6795597899058634 \n",
      "Epoch:  44\n",
      "121/361.0 loss: 0.6791664054159259 \n",
      "Epoch:  44\n",
      "122/361.0 loss: 0.679985781510671 \n",
      "Epoch:  44\n",
      "123/361.0 loss: 0.6808648960244271 \n",
      "Epoch:  44\n",
      "124/361.0 loss: 0.6802044978141785 \n",
      "Epoch:  44\n",
      "125/361.0 loss: 0.6812464855020008 \n",
      "Epoch:  44\n",
      "126/361.0 loss: 0.6818572479908861 \n",
      "Epoch:  44\n",
      "127/361.0 loss: 0.6831178474240005 \n",
      "Epoch:  44\n",
      "128/361.0 loss: 0.6843755795050037 \n",
      "Epoch:  44\n",
      "129/361.0 loss: 0.6837518999209771 \n",
      "Epoch:  44\n",
      "130/361.0 loss: 0.6827199923173162 \n",
      "Epoch:  44\n",
      "131/361.0 loss: 0.6839530860835855 \n",
      "Epoch:  44\n",
      "132/361.0 loss: 0.6851078419757068 \n",
      "Epoch:  44\n",
      "133/361.0 loss: 0.684551815933256 \n",
      "Epoch:  44\n",
      "134/361.0 loss: 0.68531478466811 \n",
      "Epoch:  44\n",
      "135/361.0 loss: 0.6852677617879475 \n",
      "Epoch:  44\n",
      "136/361.0 loss: 0.6858724138162432 \n",
      "Epoch:  44\n",
      "137/361.0 loss: 0.6872661571571792 \n",
      "Epoch:  44\n",
      "138/361.0 loss: 0.6867804458673051 \n",
      "Epoch:  44\n",
      "139/361.0 loss: 0.6869685449770518 \n",
      "Epoch:  44\n",
      "140/361.0 loss: 0.6867990675547444 \n",
      "Epoch:  44\n",
      "141/361.0 loss: 0.686551572151587 \n",
      "Epoch:  44\n",
      "142/361.0 loss: 0.6860361378509682 \n",
      "Epoch:  44\n",
      "143/361.0 loss: 0.6857160160111057 \n",
      "Epoch:  44\n",
      "144/361.0 loss: 0.6862062298018357 \n",
      "Epoch:  44\n",
      "145/361.0 loss: 0.686881423404772 \n",
      "Epoch:  44\n",
      "146/361.0 loss: 0.6864077623198632 \n",
      "Epoch:  44\n",
      "147/361.0 loss: 0.6854428069011586 \n",
      "Epoch:  44\n",
      "148/361.0 loss: 0.6848890053345853 \n",
      "Epoch:  44\n",
      "149/361.0 loss: 0.6841720771789551 \n",
      "Epoch:  44\n",
      "150/361.0 loss: 0.6844557614515949 \n",
      "Epoch:  44\n",
      "151/361.0 loss: 0.6841816376698645 \n",
      "Epoch:  44\n",
      "152/361.0 loss: 0.6834616762360716 \n",
      "Epoch:  44\n",
      "153/361.0 loss: 0.6830277791270962 \n",
      "Epoch:  44\n",
      "154/361.0 loss: 0.6834024098611647 \n",
      "Epoch:  44\n",
      "155/361.0 loss: 0.683159935932893 \n",
      "Epoch:  44\n",
      "156/361.0 loss: 0.6837181023731354 \n",
      "Epoch:  44\n",
      "157/361.0 loss: 0.6839423255075382 \n",
      "Epoch:  44\n",
      "158/361.0 loss: 0.6834054735471617 \n",
      "Epoch:  44\n",
      "159/361.0 loss: 0.6843782093375921 \n",
      "Epoch:  44\n",
      "160/361.0 loss: 0.6850457765300821 \n",
      "Epoch:  44\n",
      "161/361.0 loss: 0.6846952806284399 \n",
      "Epoch:  44\n",
      "162/361.0 loss: 0.6852266492287805 \n",
      "Epoch:  44\n",
      "163/361.0 loss: 0.6845380573011026 \n",
      "Epoch:  44\n",
      "164/361.0 loss: 0.684064620552641 \n",
      "Epoch:  44\n",
      "165/361.0 loss: 0.6843146742826485 \n",
      "Epoch:  44\n",
      "166/361.0 loss: 0.6839656212372694 \n",
      "Epoch:  44\n",
      "167/361.0 loss: 0.684595005498046 \n",
      "Epoch:  44\n",
      "168/361.0 loss: 0.685249125816413 \n",
      "Epoch:  44\n",
      "169/361.0 loss: 0.6856534424950095 \n",
      "Epoch:  44\n",
      "170/361.0 loss: 0.6857073917026408 \n",
      "Epoch:  44\n",
      "171/361.0 loss: 0.6852451860904694 \n",
      "Epoch:  44\n",
      "172/361.0 loss: 0.6850570150882522 \n",
      "Epoch:  44\n",
      "173/361.0 loss: 0.6849517325560252 \n",
      "Epoch:  44\n",
      "174/361.0 loss: 0.6854071729523795 \n",
      "Epoch:  44\n",
      "175/361.0 loss: 0.6859172846783291 \n",
      "Epoch:  44\n",
      "176/361.0 loss: 0.6854356507123527 \n",
      "Epoch:  44\n",
      "177/361.0 loss: 0.6856775287162052 \n",
      "Epoch:  44\n",
      "178/361.0 loss: 0.686116143644855 \n",
      "Epoch:  44\n",
      "179/361.0 loss: 0.6867969198359384 \n",
      "Epoch:  44\n",
      "180/361.0 loss: 0.6864075598137155 \n",
      "Epoch:  44\n",
      "181/361.0 loss: 0.6867883968484271 \n",
      "Epoch:  44\n",
      "182/361.0 loss: 0.6866455185608785 \n",
      "Epoch:  44\n",
      "183/361.0 loss: 0.6873911875097648 \n",
      "Epoch:  44\n",
      "184/361.0 loss: 0.6870500119956764 \n",
      "Epoch:  44\n",
      "185/361.0 loss: 0.6871192913542512 \n",
      "Epoch:  44\n",
      "186/361.0 loss: 0.6873163574519642 \n",
      "Epoch:  44\n",
      "187/361.0 loss: 0.6868903167704319 \n",
      "Epoch:  44\n",
      "188/361.0 loss: 0.6875777821692209 \n",
      "Epoch:  44\n",
      "189/361.0 loss: 0.6873356496032915 \n",
      "Epoch:  44\n",
      "190/361.0 loss: 0.6882880607824675 \n",
      "Epoch:  44\n",
      "191/361.0 loss: 0.6889139004051685 \n",
      "Epoch:  44\n",
      "192/361.0 loss: 0.6890149422260146 \n",
      "Epoch:  44\n",
      "193/361.0 loss: 0.6893556873822949 \n",
      "Epoch:  44\n",
      "194/361.0 loss: 0.6897081469878172 \n",
      "Epoch:  44\n",
      "195/361.0 loss: 0.6895619576074639 \n",
      "Epoch:  44\n",
      "196/361.0 loss: 0.6897901538664919 \n",
      "Epoch:  44\n",
      "197/361.0 loss: 0.689891884122232 \n",
      "Epoch:  44\n",
      "198/361.0 loss: 0.6901829155845258 \n",
      "Epoch:  44\n",
      "199/361.0 loss: 0.6897572416067124 \n",
      "Epoch:  44\n",
      "200/361.0 loss: 0.6904440934385233 \n",
      "Epoch:  44\n",
      "201/361.0 loss: 0.6904120855402238 \n",
      "Epoch:  44\n",
      "202/361.0 loss: 0.68986196001175 \n",
      "Epoch:  44\n",
      "203/361.0 loss: 0.6897687666556415 \n",
      "Epoch:  44\n",
      "204/361.0 loss: 0.6893326285408764 \n",
      "Epoch:  44\n",
      "205/361.0 loss: 0.6890461045561485 \n",
      "Epoch:  44\n",
      "206/361.0 loss: 0.6890216400657875 \n",
      "Epoch:  44\n",
      "207/361.0 loss: 0.6888161126810771 \n",
      "Epoch:  44\n",
      "208/361.0 loss: 0.6889210554401269 \n",
      "Epoch:  44\n",
      "209/361.0 loss: 0.6890002483413333 \n",
      "Epoch:  44\n",
      "210/361.0 loss: 0.6887996434035459 \n",
      "Epoch:  44\n",
      "211/361.0 loss: 0.6886164385755107 \n",
      "Epoch:  44\n",
      "212/361.0 loss: 0.6887219243206328 \n",
      "Epoch:  44\n",
      "213/361.0 loss: 0.6886006543569476 \n",
      "Epoch:  44\n",
      "214/361.0 loss: 0.6883632856746053 \n",
      "Epoch:  44\n",
      "215/361.0 loss: 0.688345010081927 \n",
      "Epoch:  44\n",
      "216/361.0 loss: 0.6884694970148499 \n",
      "Epoch:  44\n",
      "217/361.0 loss: 0.688828032497966 \n",
      "Epoch:  44\n",
      "218/361.0 loss: 0.6885022646215953 \n",
      "Epoch:  44\n",
      "219/361.0 loss: 0.6886077645150098 \n",
      "Epoch:  44\n",
      "220/361.0 loss: 0.6881453135973727 \n",
      "Epoch:  44\n",
      "221/361.0 loss: 0.688066849837432 \n",
      "Epoch:  44\n",
      "222/361.0 loss: 0.6883183685653412 \n",
      "Epoch:  44\n",
      "223/361.0 loss: 0.6883266621402332 \n",
      "Epoch:  44\n",
      "224/361.0 loss: 0.6879579875204298 \n",
      "Epoch:  44\n",
      "225/361.0 loss: 0.6878502767170425 \n",
      "Epoch:  44\n",
      "226/361.0 loss: 0.6876284002207449 \n",
      "Epoch:  44\n",
      "227/361.0 loss: 0.6876902541047648 \n",
      "Epoch:  44\n",
      "228/361.0 loss: 0.6877034996274257 \n",
      "Epoch:  44\n",
      "229/361.0 loss: 0.6877997564232867 \n",
      "Epoch:  44\n",
      "230/361.0 loss: 0.6879737828717087 \n",
      "Epoch:  44\n",
      "231/361.0 loss: 0.6877527987134868 \n",
      "Epoch:  44\n",
      "232/361.0 loss: 0.687550549855048 \n",
      "Epoch:  44\n",
      "233/361.0 loss: 0.6874731763815268 \n",
      "Epoch:  44\n",
      "234/361.0 loss: 0.6875848752387026 \n",
      "Epoch:  44\n",
      "235/361.0 loss: 0.6873413134934538 \n",
      "Epoch:  44\n",
      "236/361.0 loss: 0.686885262340433 \n",
      "Epoch:  44\n",
      "237/361.0 loss: 0.6866608590138059 \n",
      "Epoch:  44\n",
      "238/361.0 loss: 0.6868166202780592 \n",
      "Epoch:  44\n",
      "239/361.0 loss: 0.6866279204686483 \n",
      "Epoch:  44\n",
      "240/361.0 loss: 0.6863318145027794 \n",
      "Epoch:  44\n",
      "241/361.0 loss: 0.6862110512808335 \n",
      "Epoch:  44\n",
      "242/361.0 loss: 0.6863130836329833 \n",
      "Epoch:  44\n",
      "243/361.0 loss: 0.6865786128356809 \n",
      "Epoch:  44\n",
      "244/361.0 loss: 0.686467861642643 \n",
      "Epoch:  44\n",
      "245/361.0 loss: 0.6859993229552013 \n",
      "Epoch:  44\n",
      "246/361.0 loss: 0.685652861952299 \n",
      "Epoch:  44\n",
      "247/361.0 loss: 0.6858121815227693 \n",
      "Epoch:  44\n",
      "248/361.0 loss: 0.6861045571216139 \n",
      "Epoch:  44\n",
      "249/361.0 loss: 0.6857144331932068 \n",
      "Epoch:  44\n",
      "250/361.0 loss: 0.6857728255222518 \n",
      "Epoch:  44\n",
      "251/361.0 loss: 0.6855657152713291 \n",
      "Epoch:  44\n",
      "252/361.0 loss: 0.6861479310650128 \n",
      "Epoch:  44\n",
      "253/361.0 loss: 0.6868388840532679 \n",
      "Epoch:  44\n",
      "254/361.0 loss: 0.6870194996104521 \n",
      "Epoch:  44\n",
      "255/361.0 loss: 0.6873475487809628 \n",
      "Epoch:  44\n",
      "256/361.0 loss: 0.6875310832424386 \n",
      "Epoch:  44\n",
      "257/361.0 loss: 0.6877288233864215 \n",
      "Epoch:  44\n",
      "258/361.0 loss: 0.6877427282940927 \n",
      "Epoch:  44\n",
      "259/361.0 loss: 0.6873260711248105 \n",
      "Epoch:  44\n",
      "260/361.0 loss: 0.686958060867485 \n",
      "Epoch:  44\n",
      "261/361.0 loss: 0.6874398429885166 \n",
      "Epoch:  44\n",
      "262/361.0 loss: 0.6871630003243798 \n",
      "Epoch:  44\n",
      "263/361.0 loss: 0.6866723450295853 \n",
      "Epoch:  44\n",
      "264/361.0 loss: 0.6862594154645811 \n",
      "Epoch:  44\n",
      "265/361.0 loss: 0.6859951418145258 \n",
      "Epoch:  44\n",
      "266/361.0 loss: 0.6856346360306614 \n",
      "Epoch:  44\n",
      "267/361.0 loss: 0.6852806468508137 \n",
      "Epoch:  44\n",
      "268/361.0 loss: 0.6850469927805507 \n",
      "Epoch:  44\n",
      "269/361.0 loss: 0.6850285388805248 \n",
      "Epoch:  44\n",
      "270/361.0 loss: 0.6847145621187133 \n",
      "Epoch:  44\n",
      "271/361.0 loss: 0.6843313167200369 \n",
      "Epoch:  44\n",
      "272/361.0 loss: 0.6843200897995806 \n",
      "Epoch:  44\n",
      "273/361.0 loss: 0.6846959532177361 \n",
      "Epoch:  44\n",
      "274/361.0 loss: 0.6844157086719166 \n",
      "Epoch:  44\n",
      "275/361.0 loss: 0.6847893612972205 \n",
      "Epoch:  44\n",
      "276/361.0 loss: 0.6852008039770574 \n",
      "Epoch:  44\n",
      "277/361.0 loss: 0.6855122337667204 \n",
      "Epoch:  44\n",
      "278/361.0 loss: 0.6858130678481098 \n",
      "Epoch:  44\n",
      "279/361.0 loss: 0.6863272251827376 \n",
      "Epoch:  44\n",
      "280/361.0 loss: 0.6862671614965934 \n",
      "Epoch:  44\n",
      "281/361.0 loss: 0.6865743561416653 \n",
      "Epoch:  44\n",
      "282/361.0 loss: 0.6861195357865243 \n",
      "Epoch:  44\n",
      "283/361.0 loss: 0.6858929706291413 \n",
      "Epoch:  44\n",
      "284/361.0 loss: 0.6858745294704772 \n",
      "Epoch:  44\n",
      "285/361.0 loss: 0.6858548230224556 \n",
      "Epoch:  44\n",
      "286/361.0 loss: 0.6862468250121805 \n",
      "Epoch:  44\n",
      "287/361.0 loss: 0.6864890458269252 \n",
      "Epoch:  44\n",
      "288/361.0 loss: 0.6863482113940493 \n",
      "Epoch:  44\n",
      "289/361.0 loss: 0.6862399070427335 \n",
      "Epoch:  44\n",
      "290/361.0 loss: 0.6865645374629096 \n",
      "Epoch:  44\n",
      "291/361.0 loss: 0.6864174300268905 \n",
      "Epoch:  44\n",
      "292/361.0 loss: 0.6867612459960651 \n",
      "Epoch:  44\n",
      "293/361.0 loss: 0.6871018890215426 \n",
      "Epoch:  44\n",
      "294/361.0 loss: 0.6871757147675853 \n",
      "Epoch:  44\n",
      "295/361.0 loss: 0.6868629489798803 \n",
      "Epoch:  44\n",
      "296/361.0 loss: 0.6862614128726099 \n",
      "Epoch:  44\n",
      "297/361.0 loss: 0.6864638818590433 \n",
      "Epoch:  44\n",
      "298/361.0 loss: 0.6862624738128688 \n",
      "Epoch:  44\n",
      "299/361.0 loss: 0.6860708854595821 \n",
      "Epoch:  44\n",
      "300/361.0 loss: 0.6858100257442639 \n",
      "Epoch:  44\n",
      "301/361.0 loss: 0.6856889736573428 \n",
      "Epoch:  44\n",
      "302/361.0 loss: 0.6856306866057241 \n",
      "Epoch:  44\n",
      "303/361.0 loss: 0.6854643478597465 \n",
      "Epoch:  44\n",
      "304/361.0 loss: 0.6855343627147987 \n",
      "Epoch:  44\n",
      "305/361.0 loss: 0.6857791410552131 \n",
      "Epoch:  44\n",
      "306/361.0 loss: 0.6854478213996763 \n",
      "Epoch:  44\n",
      "307/361.0 loss: 0.6850625729406035 \n",
      "Epoch:  44\n",
      "308/361.0 loss: 0.685301035353281 \n",
      "Epoch:  44\n",
      "309/361.0 loss: 0.6857854652789331 \n",
      "Epoch:  44\n",
      "310/361.0 loss: 0.6852885616937251 \n",
      "Epoch:  44\n",
      "311/361.0 loss: 0.6857856689737394 \n",
      "Epoch:  44\n",
      "312/361.0 loss: 0.6854970003850163 \n",
      "Epoch:  44\n",
      "313/361.0 loss: 0.6853349034193974 \n",
      "Epoch:  44\n",
      "314/361.0 loss: 0.6854549235767788 \n",
      "Epoch:  44\n",
      "315/361.0 loss: 0.6858315522534938 \n",
      "Epoch:  44\n",
      "316/361.0 loss: 0.6863323745291315 \n",
      "Epoch:  44\n",
      "317/361.0 loss: 0.6860464187163227 \n",
      "Epoch:  44\n",
      "318/361.0 loss: 0.6869256161970778 \n",
      "Epoch:  44\n",
      "319/361.0 loss: 0.6872374637052416 \n",
      "Epoch:  44\n",
      "320/361.0 loss: 0.6875634817319496 \n",
      "Epoch:  44\n",
      "321/361.0 loss: 0.6878800584662775 \n",
      "Epoch:  44\n",
      "322/361.0 loss: 0.6881377237500051 \n",
      "Epoch:  44\n",
      "323/361.0 loss: 0.6882707653222261 \n",
      "Epoch:  44\n",
      "324/361.0 loss: 0.6885980831659757 \n",
      "Epoch:  44\n",
      "325/361.0 loss: 0.6888401978220676 \n",
      "Epoch:  44\n",
      "326/361.0 loss: 0.688979801234849 \n",
      "Epoch:  44\n",
      "327/361.0 loss: 0.6891584567180494 \n",
      "Epoch:  44\n",
      "328/361.0 loss: 0.6889754858060448 \n",
      "Epoch:  44\n",
      "329/361.0 loss: 0.6888874312241872 \n",
      "Epoch:  44\n",
      "330/361.0 loss: 0.6891240205649523 \n",
      "Epoch:  44\n",
      "331/361.0 loss: 0.6888061900095768 \n",
      "Epoch:  44\n",
      "332/361.0 loss: 0.6892459075730126 \n",
      "Epoch:  44\n",
      "333/361.0 loss: 0.6893325335608271 \n",
      "Epoch:  44\n",
      "334/361.0 loss: 0.6896107045572195 \n",
      "Epoch:  44\n",
      "335/361.0 loss: 0.690139035561255 \n",
      "Epoch:  44\n",
      "336/361.0 loss: 0.6904562345598148 \n",
      "Epoch:  44\n",
      "337/361.0 loss: 0.6908313480354625 \n",
      "Epoch:  44\n",
      "338/361.0 loss: 0.6910396156761147 \n",
      "Epoch:  44\n",
      "339/361.0 loss: 0.6909802924184238 \n",
      "Epoch:  44\n",
      "340/361.0 loss: 0.6907053822296456 \n",
      "Epoch:  44\n",
      "341/361.0 loss: 0.6904322712393532 \n",
      "Epoch:  44\n",
      "342/361.0 loss: 0.6907715760931676 \n",
      "Epoch:  44\n",
      "343/361.0 loss: 0.6906956555538399 \n",
      "Epoch:  44\n",
      "344/361.0 loss: 0.6908851661543916 \n",
      "Epoch:  44\n",
      "345/361.0 loss: 0.6907376584979151 \n",
      "Epoch:  44\n",
      "346/361.0 loss: 0.6908728892590196 \n",
      "Epoch:  44\n",
      "347/361.0 loss: 0.6906670068187275 \n",
      "Epoch:  44\n",
      "348/361.0 loss: 0.6908892422145964 \n",
      "Epoch:  44\n",
      "349/361.0 loss: 0.6910188504627772 \n",
      "Epoch:  44\n",
      "350/361.0 loss: 0.6911106522266681 \n",
      "Epoch:  44\n",
      "351/361.0 loss: 0.6909819907424125 \n",
      "Epoch:  44\n",
      "352/361.0 loss: 0.6909053889617703 \n",
      "Epoch:  44\n",
      "353/361.0 loss: 0.6908355995086627 \n",
      "Epoch:  44\n",
      "354/361.0 loss: 0.690935222028007 \n",
      "Epoch:  44\n",
      "355/361.0 loss: 0.6907715449172459 \n",
      "Epoch:  44\n",
      "356/361.0 loss: 0.6907771880887136 \n",
      "Epoch:  44\n",
      "357/361.0 loss: 0.6906264890505615 \n",
      "Epoch:  44\n",
      "358/361.0 loss: 0.6905739046737012 \n",
      "Epoch:  44\n",
      "359/361.0 loss: 0.6907611098554399 \n",
      "Epoch:  44\n",
      "360/361.0 loss: 0.6910009618611217 \n",
      "Epoch:  45\n",
      "0/361.0 loss: 0.7072569131851196 \n",
      "Epoch:  45\n",
      "1/361.0 loss: 0.7049008905887604 \n",
      "Epoch:  45\n",
      "2/361.0 loss: 0.6695188482602438 \n",
      "Epoch:  45\n",
      "3/361.0 loss: 0.6610821038484573 \n",
      "Epoch:  45\n",
      "4/361.0 loss: 0.6562541961669922 \n",
      "Epoch:  45\n",
      "5/361.0 loss: 0.6713861922423044 \n",
      "Epoch:  45\n",
      "6/361.0 loss: 0.6746860572269985 \n",
      "Epoch:  45\n",
      "7/361.0 loss: 0.6825149804353714 \n",
      "Epoch:  45\n",
      "8/361.0 loss: 0.6769424676895142 \n",
      "Epoch:  45\n",
      "9/361.0 loss: 0.6808389067649842 \n",
      "Epoch:  45\n",
      "10/361.0 loss: 0.6825221722776239 \n",
      "Epoch:  45\n",
      "11/361.0 loss: 0.6787352710962296 \n",
      "Epoch:  45\n",
      "12/361.0 loss: 0.6765281924834619 \n",
      "Epoch:  45\n",
      "13/361.0 loss: 0.6758246081215995 \n",
      "Epoch:  45\n",
      "14/361.0 loss: 0.6744145750999451 \n",
      "Epoch:  45\n",
      "15/361.0 loss: 0.677959281951189 \n",
      "Epoch:  45\n",
      "16/361.0 loss: 0.6828210704466876 \n",
      "Epoch:  45\n",
      "17/361.0 loss: 0.6819920970333947 \n",
      "Epoch:  45\n",
      "18/361.0 loss: 0.6882317819093403 \n",
      "Epoch:  45\n",
      "19/361.0 loss: 0.6909246295690536 \n",
      "Epoch:  45\n",
      "20/361.0 loss: 0.6967976831254505 \n",
      "Epoch:  45\n",
      "21/361.0 loss: 0.6948488219217821 \n",
      "Epoch:  45\n",
      "22/361.0 loss: 0.6956373764121014 \n",
      "Epoch:  45\n",
      "23/361.0 loss: 0.6920509139696757 \n",
      "Epoch:  45\n",
      "24/361.0 loss: 0.6900842666625977 \n",
      "Epoch:  45\n",
      "25/361.0 loss: 0.6914919935739957 \n",
      "Epoch:  45\n",
      "26/361.0 loss: 0.6928149572125187 \n",
      "Epoch:  45\n",
      "27/361.0 loss: 0.6913294643163681 \n",
      "Epoch:  45\n",
      "28/361.0 loss: 0.6914621776547926 \n",
      "Epoch:  45\n",
      "29/361.0 loss: 0.6931826015313466 \n",
      "Epoch:  45\n",
      "30/361.0 loss: 0.6942165263237492 \n",
      "Epoch:  45\n",
      "31/361.0 loss: 0.6955719087272882 \n",
      "Epoch:  45\n",
      "32/361.0 loss: 0.6970884474841031 \n",
      "Epoch:  45\n",
      "33/361.0 loss: 0.6969849134192747 \n",
      "Epoch:  45\n",
      "34/361.0 loss: 0.696401275907244 \n",
      "Epoch:  45\n",
      "35/361.0 loss: 0.6947672648562325 \n",
      "Epoch:  45\n",
      "36/361.0 loss: 0.6937409429936796 \n",
      "Epoch:  45\n",
      "37/361.0 loss: 0.6940646736245406 \n",
      "Epoch:  45\n",
      "38/361.0 loss: 0.6948342017638378 \n",
      "Epoch:  45\n",
      "39/361.0 loss: 0.6937753826379776 \n",
      "Epoch:  45\n",
      "40/361.0 loss: 0.6954471367161449 \n",
      "Epoch:  45\n",
      "41/361.0 loss: 0.6965721987542652 \n",
      "Epoch:  45\n",
      "42/361.0 loss: 0.6958485786304918 \n",
      "Epoch:  45\n",
      "43/361.0 loss: 0.6969833197918806 \n",
      "Epoch:  45\n",
      "44/361.0 loss: 0.6959699948628744 \n",
      "Epoch:  45\n",
      "45/361.0 loss: 0.6973455431668655 \n",
      "Epoch:  45\n",
      "46/361.0 loss: 0.6985554809265948 \n",
      "Epoch:  45\n",
      "47/361.0 loss: 0.6982563597460588 \n",
      "Epoch:  45\n",
      "48/361.0 loss: 0.6988584265416983 \n",
      "Epoch:  45\n",
      "49/361.0 loss: 0.7006974232196808 \n",
      "Epoch:  45\n",
      "50/361.0 loss: 0.6987119691044676 \n",
      "Epoch:  45\n",
      "51/361.0 loss: 0.6988775363335242 \n",
      "Epoch:  45\n",
      "52/361.0 loss: 0.6989547272898117 \n",
      "Epoch:  45\n",
      "53/361.0 loss: 0.6974014065883778 \n",
      "Epoch:  45\n",
      "54/361.0 loss: 0.6972560275684704 \n",
      "Epoch:  45\n",
      "55/361.0 loss: 0.6959210176553045 \n",
      "Epoch:  45\n",
      "56/361.0 loss: 0.6965168766808092 \n",
      "Epoch:  45\n",
      "57/361.0 loss: 0.6974624868096977 \n",
      "Epoch:  45\n",
      "58/361.0 loss: 0.6971200330782745 \n",
      "Epoch:  45\n",
      "59/361.0 loss: 0.6962561696767807 \n",
      "Epoch:  45\n",
      "60/361.0 loss: 0.6965765669697621 \n",
      "Epoch:  45\n",
      "61/361.0 loss: 0.6967958250353413 \n",
      "Epoch:  45\n",
      "62/361.0 loss: 0.6980835170972914 \n",
      "Epoch:  45\n",
      "63/361.0 loss: 0.6980616915971041 \n",
      "Epoch:  45\n",
      "64/361.0 loss: 0.697754572905027 \n",
      "Epoch:  45\n",
      "65/361.0 loss: 0.6974455813566843 \n",
      "Epoch:  45\n",
      "66/361.0 loss: 0.6973675578387816 \n",
      "Epoch:  45\n",
      "67/361.0 loss: 0.6964858787901261 \n",
      "Epoch:  45\n",
      "68/361.0 loss: 0.6984117661697277 \n",
      "Epoch:  45\n",
      "69/361.0 loss: 0.6980678336960929 \n",
      "Epoch:  45\n",
      "70/361.0 loss: 0.6999485652211687 \n",
      "Epoch:  45\n",
      "71/361.0 loss: 0.7006283361050818 \n",
      "Epoch:  45\n",
      "72/361.0 loss: 0.7004285405759942 \n",
      "Epoch:  45\n",
      "73/361.0 loss: 0.7019779166659793 \n",
      "Epoch:  45\n",
      "74/361.0 loss: 0.7035214408238729 \n",
      "Epoch:  45\n",
      "75/361.0 loss: 0.7036163736330835 \n",
      "Epoch:  45\n",
      "76/361.0 loss: 0.7040081836960532 \n",
      "Epoch:  45\n",
      "77/361.0 loss: 0.7033593807464991 \n",
      "Epoch:  45\n",
      "78/361.0 loss: 0.7030337234086628 \n",
      "Epoch:  45\n",
      "79/361.0 loss: 0.7034608140587807 \n",
      "Epoch:  45\n",
      "80/361.0 loss: 0.7042747265026893 \n",
      "Epoch:  45\n",
      "81/361.0 loss: 0.7041842428649344 \n",
      "Epoch:  45\n",
      "82/361.0 loss: 0.7039335262344544 \n",
      "Epoch:  45\n",
      "83/361.0 loss: 0.7051962507622582 \n",
      "Epoch:  45\n",
      "84/361.0 loss: 0.7045564356972189 \n",
      "Epoch:  45\n",
      "85/361.0 loss: 0.7039341074089671 \n",
      "Epoch:  45\n",
      "86/361.0 loss: 0.7046553910463705 \n",
      "Epoch:  45\n",
      "87/361.0 loss: 0.704715600067919 \n",
      "Epoch:  45\n",
      "88/361.0 loss: 0.70496846249934 \n",
      "Epoch:  45\n",
      "89/361.0 loss: 0.7044009884198507 \n",
      "Epoch:  45\n",
      "90/361.0 loss: 0.703957043506287 \n",
      "Epoch:  45\n",
      "91/361.0 loss: 0.7041611269764279 \n",
      "Epoch:  45\n",
      "92/361.0 loss: 0.7042207628168086 \n",
      "Epoch:  45\n",
      "93/361.0 loss: 0.704789714610323 \n",
      "Epoch:  45\n",
      "94/361.0 loss: 0.704684401185889 \n",
      "Epoch:  45\n",
      "95/361.0 loss: 0.7047730560104052 \n",
      "Epoch:  45\n",
      "96/361.0 loss: 0.7040416026852795 \n",
      "Epoch:  45\n",
      "97/361.0 loss: 0.7034722651754107 \n",
      "Epoch:  45\n",
      "98/361.0 loss: 0.7035517572152494 \n",
      "Epoch:  45\n",
      "99/361.0 loss: 0.7028655254840851 \n",
      "Epoch:  45\n",
      "100/361.0 loss: 0.7031055795084132 \n",
      "Epoch:  45\n",
      "101/361.0 loss: 0.7028127797678405 \n",
      "Epoch:  45\n",
      "102/361.0 loss: 0.7028535529247766 \n",
      "Epoch:  45\n",
      "103/361.0 loss: 0.7017857197385567 \n",
      "Epoch:  45\n",
      "104/361.0 loss: 0.70162391549065 \n",
      "Epoch:  45\n",
      "105/361.0 loss: 0.7018923219644798 \n",
      "Epoch:  45\n",
      "106/361.0 loss: 0.7010431674039252 \n",
      "Epoch:  45\n",
      "107/361.0 loss: 0.7012706696987152 \n",
      "Epoch:  45\n",
      "108/361.0 loss: 0.700832243359417 \n",
      "Epoch:  45\n",
      "109/361.0 loss: 0.700520585341887 \n",
      "Epoch:  45\n",
      "110/361.0 loss: 0.7004781596295468 \n",
      "Epoch:  45\n",
      "111/361.0 loss: 0.6998333004968507 \n",
      "Epoch:  45\n",
      "112/361.0 loss: 0.7000910492069954 \n",
      "Epoch:  45\n",
      "113/361.0 loss: 0.69974943472628 \n",
      "Epoch:  45\n",
      "114/361.0 loss: 0.6996393359225729 \n",
      "Epoch:  45\n",
      "115/361.0 loss: 0.6995554371126766 \n",
      "Epoch:  45\n",
      "116/361.0 loss: 0.6994823008520991 \n",
      "Epoch:  45\n",
      "117/361.0 loss: 0.6998672066098552 \n",
      "Epoch:  45\n",
      "118/361.0 loss: 0.6996957329140991 \n",
      "Epoch:  45\n",
      "119/361.0 loss: 0.6996828471620877 \n",
      "Epoch:  45\n",
      "120/361.0 loss: 0.6997959589170031 \n",
      "Epoch:  45\n",
      "121/361.0 loss: 0.6996230253430663 \n",
      "Epoch:  45\n",
      "122/361.0 loss: 0.699473926691505 \n",
      "Epoch:  45\n",
      "123/361.0 loss: 0.6993748156293746 \n",
      "Epoch:  45\n",
      "124/361.0 loss: 0.6999054641723633 \n",
      "Epoch:  45\n",
      "125/361.0 loss: 0.6997791131337484 \n",
      "Epoch:  45\n",
      "126/361.0 loss: 0.7001206949939878 \n",
      "Epoch:  45\n",
      "127/361.0 loss: 0.7008713143877685 \n",
      "Epoch:  45\n",
      "128/361.0 loss: 0.7001484119614889 \n",
      "Epoch:  45\n",
      "129/361.0 loss: 0.7002845218548408 \n",
      "Epoch:  45\n",
      "130/361.0 loss: 0.7001755806325957 \n",
      "Epoch:  45\n",
      "131/361.0 loss: 0.6999098821119829 \n",
      "Epoch:  45\n",
      "132/361.0 loss: 0.700043761640563 \n",
      "Epoch:  45\n",
      "133/361.0 loss: 0.6996241549947368 \n",
      "Epoch:  45\n",
      "134/361.0 loss: 0.6995819943922538 \n",
      "Epoch:  45\n",
      "135/361.0 loss: 0.6992061217041576 \n",
      "Epoch:  45\n",
      "136/361.0 loss: 0.6986676002070852 \n",
      "Epoch:  45\n",
      "137/361.0 loss: 0.6983776831108591 \n",
      "Epoch:  45\n",
      "138/361.0 loss: 0.6984218796380133 \n",
      "Epoch:  45\n",
      "139/361.0 loss: 0.6979375175067357 \n",
      "Epoch:  45\n",
      "140/361.0 loss: 0.6983540273727254 \n",
      "Epoch:  45\n",
      "141/361.0 loss: 0.6984229138199712 \n",
      "Epoch:  45\n",
      "142/361.0 loss: 0.6978397256844527 \n",
      "Epoch:  45\n",
      "143/361.0 loss: 0.6969876198305024 \n",
      "Epoch:  45\n",
      "144/361.0 loss: 0.6975532116561101 \n",
      "Epoch:  45\n",
      "145/361.0 loss: 0.697334496125783 \n",
      "Epoch:  45\n",
      "146/361.0 loss: 0.697561079142045 \n",
      "Epoch:  45\n",
      "147/361.0 loss: 0.69736587880431 \n",
      "Epoch:  45\n",
      "148/361.0 loss: 0.6970963070056583 \n",
      "Epoch:  45\n",
      "149/361.0 loss: 0.6973529771963756 \n",
      "Epoch:  45\n",
      "150/361.0 loss: 0.6965616882242114 \n",
      "Epoch:  45\n",
      "151/361.0 loss: 0.6959532275795937 \n",
      "Epoch:  45\n",
      "152/361.0 loss: 0.6957790493186004 \n",
      "Epoch:  45\n",
      "153/361.0 loss: 0.6959979867006277 \n",
      "Epoch:  45\n",
      "154/361.0 loss: 0.6959684191211577 \n",
      "Epoch:  45\n",
      "155/361.0 loss: 0.6960803488126168 \n",
      "Epoch:  45\n",
      "156/361.0 loss: 0.6969379084125445 \n",
      "Epoch:  45\n",
      "157/361.0 loss: 0.6976349116126194 \n",
      "Epoch:  45\n",
      "158/361.0 loss: 0.6977503715821032 \n",
      "Epoch:  45\n",
      "159/361.0 loss: 0.6979418467730284 \n",
      "Epoch:  45\n",
      "160/361.0 loss: 0.6975419051158502 \n",
      "Epoch:  45\n",
      "161/361.0 loss: 0.6976865633034411 \n",
      "Epoch:  45\n",
      "162/361.0 loss: 0.6979968997598426 \n",
      "Epoch:  45\n",
      "163/361.0 loss: 0.6981526903989839 \n",
      "Epoch:  45\n",
      "164/361.0 loss: 0.698145858446757 \n",
      "Epoch:  45\n",
      "165/361.0 loss: 0.6982340439256415 \n",
      "Epoch:  45\n",
      "166/361.0 loss: 0.6977592927967003 \n",
      "Epoch:  45\n",
      "167/361.0 loss: 0.6973726522354853 \n",
      "Epoch:  45\n",
      "168/361.0 loss: 0.6973683079318888 \n",
      "Epoch:  45\n",
      "169/361.0 loss: 0.6973804326618419 \n",
      "Epoch:  45\n",
      "170/361.0 loss: 0.6974424458386606 \n",
      "Epoch:  45\n",
      "171/361.0 loss: 0.6979473759961683 \n",
      "Epoch:  45\n",
      "172/361.0 loss: 0.698288136824018 \n",
      "Epoch:  45\n",
      "173/361.0 loss: 0.698575299019101 \n",
      "Epoch:  45\n",
      "174/361.0 loss: 0.6981559559277126 \n",
      "Epoch:  45\n",
      "175/361.0 loss: 0.6981509073891423 \n",
      "Epoch:  45\n",
      "176/361.0 loss: 0.6980368494987488 \n",
      "Epoch:  45\n",
      "177/361.0 loss: 0.6981125902593805 \n",
      "Epoch:  45\n",
      "178/361.0 loss: 0.697693261687316 \n",
      "Epoch:  45\n",
      "179/361.0 loss: 0.6974527951743867 \n",
      "Epoch:  45\n",
      "180/361.0 loss: 0.6976281127876999 \n",
      "Epoch:  45\n",
      "181/361.0 loss: 0.6971422833400768 \n",
      "Epoch:  45\n",
      "182/361.0 loss: 0.6973299931307309 \n",
      "Epoch:  45\n",
      "183/361.0 loss: 0.6972472291925679 \n",
      "Epoch:  45\n",
      "184/361.0 loss: 0.6973405106647594 \n",
      "Epoch:  45\n",
      "185/361.0 loss: 0.6973879584061202 \n",
      "Epoch:  45\n",
      "186/361.0 loss: 0.697475160188216 \n",
      "Epoch:  45\n",
      "187/361.0 loss: 0.6974757066432465 \n",
      "Epoch:  45\n",
      "188/361.0 loss: 0.6968805979168604 \n",
      "Epoch:  45\n",
      "189/361.0 loss: 0.6967156360023901 \n",
      "Epoch:  45\n",
      "190/361.0 loss: 0.6967919047590325 \n",
      "Epoch:  45\n",
      "191/361.0 loss: 0.6970221490288774 \n",
      "Epoch:  45\n",
      "192/361.0 loss: 0.6970385143176262 \n",
      "Epoch:  45\n",
      "193/361.0 loss: 0.6970455019744402 \n",
      "Epoch:  45\n",
      "194/361.0 loss: 0.6970133870075911 \n",
      "Epoch:  45\n",
      "195/361.0 loss: 0.697130950129762 \n",
      "Epoch:  45\n",
      "196/361.0 loss: 0.697314777047501 \n",
      "Epoch:  45\n",
      "197/361.0 loss: 0.6970534047695122 \n",
      "Epoch:  45\n",
      "198/361.0 loss: 0.6969210340749079 \n",
      "Epoch:  45\n",
      "199/361.0 loss: 0.696645379960537 \n",
      "Epoch:  45\n",
      "200/361.0 loss: 0.6969665407541379 \n",
      "Epoch:  45\n",
      "201/361.0 loss: 0.6971203864801048 \n",
      "Epoch:  45\n",
      "202/361.0 loss: 0.6974601143686642 \n",
      "Epoch:  45\n",
      "203/361.0 loss: 0.6970482348811393 \n",
      "Epoch:  45\n",
      "204/361.0 loss: 0.6969847251729268 \n",
      "Epoch:  45\n",
      "205/361.0 loss: 0.6969532769860574 \n",
      "Epoch:  45\n",
      "206/361.0 loss: 0.6967016115856631 \n",
      "Epoch:  45\n",
      "207/361.0 loss: 0.6966049696963567 \n",
      "Epoch:  45\n",
      "208/361.0 loss: 0.6972744433503402 \n",
      "Epoch:  45\n",
      "209/361.0 loss: 0.6973637841996693 \n",
      "Epoch:  45\n",
      "210/361.0 loss: 0.6970641590407675 \n",
      "Epoch:  45\n",
      "211/361.0 loss: 0.6969067547118889 \n",
      "Epoch:  45\n",
      "212/361.0 loss: 0.6970312662527595 \n",
      "Epoch:  45\n",
      "213/361.0 loss: 0.6969393193721771 \n",
      "Epoch:  45\n",
      "214/361.0 loss: 0.6969481820283934 \n",
      "Epoch:  45\n",
      "215/361.0 loss: 0.6968074496145602 \n",
      "Epoch:  45\n",
      "216/361.0 loss: 0.6967178717736275 \n",
      "Epoch:  45\n",
      "217/361.0 loss: 0.6968221339063907 \n",
      "Epoch:  45\n",
      "218/361.0 loss: 0.6974658225769321 \n",
      "Epoch:  45\n",
      "219/361.0 loss: 0.6975407158786601 \n",
      "Epoch:  45\n",
      "220/361.0 loss: 0.6974618623698998 \n",
      "Epoch:  45\n",
      "221/361.0 loss: 0.6976321293964042 \n",
      "Epoch:  45\n",
      "222/361.0 loss: 0.6978977180917166 \n",
      "Epoch:  45\n",
      "223/361.0 loss: 0.6976226517664534 \n",
      "Epoch:  45\n",
      "224/361.0 loss: 0.6976917235056559 \n",
      "Epoch:  45\n",
      "225/361.0 loss: 0.6977810482535742 \n",
      "Epoch:  45\n",
      "226/361.0 loss: 0.6976114558753463 \n",
      "Epoch:  45\n",
      "227/361.0 loss: 0.6974364477291441 \n",
      "Epoch:  45\n",
      "228/361.0 loss: 0.6976141450707048 \n",
      "Epoch:  45\n",
      "229/361.0 loss: 0.6974217829496964 \n",
      "Epoch:  45\n",
      "230/361.0 loss: 0.6978174726684372 \n",
      "Epoch:  45\n",
      "231/361.0 loss: 0.6976069707808823 \n",
      "Epoch:  45\n",
      "232/361.0 loss: 0.6977630989234335 \n",
      "Epoch:  45\n",
      "233/361.0 loss: 0.6975336910313011 \n",
      "Epoch:  45\n",
      "234/361.0 loss: 0.6975603372492689 \n",
      "Epoch:  45\n",
      "235/361.0 loss: 0.6979206421617734 \n",
      "Epoch:  45\n",
      "236/361.0 loss: 0.6977029090692223 \n",
      "Epoch:  45\n",
      "237/361.0 loss: 0.6974843136903619 \n",
      "Epoch:  45\n",
      "238/361.0 loss: 0.6974196498862869 \n",
      "Epoch:  45\n",
      "239/361.0 loss: 0.6969905763864517 \n",
      "Epoch:  45\n",
      "240/361.0 loss: 0.6964994995425846 \n",
      "Epoch:  45\n",
      "241/361.0 loss: 0.6961748255185845 \n",
      "Epoch:  45\n",
      "242/361.0 loss: 0.6961446191057746 \n",
      "Epoch:  45\n",
      "243/361.0 loss: 0.6963857844716212 \n",
      "Epoch:  45\n",
      "244/361.0 loss: 0.6964234291290751 \n",
      "Epoch:  45\n",
      "245/361.0 loss: 0.6964210916340836 \n",
      "Epoch:  45\n",
      "246/361.0 loss: 0.6959953978959366 \n",
      "Epoch:  45\n",
      "247/361.0 loss: 0.6957049607749908 \n",
      "Epoch:  45\n",
      "248/361.0 loss: 0.6954090784352467 \n",
      "Epoch:  45\n",
      "249/361.0 loss: 0.6951069762706756 \n",
      "Epoch:  45\n",
      "250/361.0 loss: 0.6948967787374063 \n",
      "Epoch:  45\n",
      "251/361.0 loss: 0.6950927660578773 \n",
      "Epoch:  45\n",
      "252/361.0 loss: 0.6948732314373665 \n",
      "Epoch:  45\n",
      "253/361.0 loss: 0.6946852819656762 \n",
      "Epoch:  45\n",
      "254/361.0 loss: 0.6945600479256873 \n",
      "Epoch:  45\n",
      "255/361.0 loss: 0.6943914038129151 \n",
      "Epoch:  45\n",
      "256/361.0 loss: 0.6947984681519089 \n",
      "Epoch:  45\n",
      "257/361.0 loss: 0.6951329564863398 \n",
      "Epoch:  45\n",
      "258/361.0 loss: 0.6953930900824116 \n",
      "Epoch:  45\n",
      "259/361.0 loss: 0.6951680949101081 \n",
      "Epoch:  45\n",
      "260/361.0 loss: 0.6953156014968609 \n",
      "Epoch:  45\n",
      "261/361.0 loss: 0.694882562142292 \n",
      "Epoch:  45\n",
      "262/361.0 loss: 0.6950853231288634 \n",
      "Epoch:  45\n",
      "263/361.0 loss: 0.6947436892625057 \n",
      "Epoch:  45\n",
      "264/361.0 loss: 0.6945696331420035 \n",
      "Epoch:  45\n",
      "265/361.0 loss: 0.6942931404687408 \n",
      "Epoch:  45\n",
      "266/361.0 loss: 0.6939916434359461 \n",
      "Epoch:  45\n",
      "267/361.0 loss: 0.6942084845322282 \n",
      "Epoch:  45\n",
      "268/361.0 loss: 0.6945145218788913 \n",
      "Epoch:  45\n",
      "269/361.0 loss: 0.6948582627155163 \n",
      "Epoch:  45\n",
      "270/361.0 loss: 0.6946866402326914 \n",
      "Epoch:  45\n",
      "271/361.0 loss: 0.694725617985515 \n",
      "Epoch:  45\n",
      "272/361.0 loss: 0.694924635109884 \n",
      "Epoch:  45\n",
      "273/361.0 loss: 0.6951024682417403 \n",
      "Epoch:  45\n",
      "274/361.0 loss: 0.6949173003976995 \n",
      "Epoch:  45\n",
      "275/361.0 loss: 0.6947627827741097 \n",
      "Epoch:  45\n",
      "276/361.0 loss: 0.694499491999726 \n",
      "Epoch:  45\n",
      "277/361.0 loss: 0.6946086345387877 \n",
      "Epoch:  45\n",
      "278/361.0 loss: 0.6944624634199245 \n",
      "Epoch:  45\n",
      "279/361.0 loss: 0.6945109148110662 \n",
      "Epoch:  45\n",
      "280/361.0 loss: 0.6947938239871395 \n",
      "Epoch:  45\n",
      "281/361.0 loss: 0.694746306179263 \n",
      "Epoch:  45\n",
      "282/361.0 loss: 0.6948960549839815 \n",
      "Epoch:  45\n",
      "283/361.0 loss: 0.6949350833892822 \n",
      "Epoch:  45\n",
      "284/361.0 loss: 0.6949656333839684 \n",
      "Epoch:  45\n",
      "285/361.0 loss: 0.6953862682505921 \n",
      "Epoch:  45\n",
      "286/361.0 loss: 0.6954897432377114 \n",
      "Epoch:  45\n",
      "287/361.0 loss: 0.6954077887866232 \n",
      "Epoch:  45\n",
      "288/361.0 loss: 0.6952844404431775 \n",
      "Epoch:  45\n",
      "289/361.0 loss: 0.6952027781256314 \n",
      "Epoch:  45\n",
      "290/361.0 loss: 0.6952479870868302 \n",
      "Epoch:  45\n",
      "291/361.0 loss: 0.6951790004968643 \n",
      "Epoch:  45\n",
      "292/361.0 loss: 0.694961264271785 \n",
      "Epoch:  45\n",
      "293/361.0 loss: 0.6949617392351838 \n",
      "Epoch:  45\n",
      "294/361.0 loss: 0.6949539511890734 \n",
      "Epoch:  45\n",
      "295/361.0 loss: 0.6944703866501112 \n",
      "Epoch:  45\n",
      "296/361.0 loss: 0.6943769356618426 \n",
      "Epoch:  45\n",
      "297/361.0 loss: 0.6945139461715749 \n",
      "Epoch:  45\n",
      "298/361.0 loss: 0.6944312925721491 \n",
      "Epoch:  45\n",
      "299/361.0 loss: 0.6943125989039739 \n",
      "Epoch:  45\n",
      "300/361.0 loss: 0.6941297586970155 \n",
      "Epoch:  45\n",
      "301/361.0 loss: 0.6941568622525954 \n",
      "Epoch:  45\n",
      "302/361.0 loss: 0.6944087409343657 \n",
      "Epoch:  45\n",
      "303/361.0 loss: 0.694427240639925 \n",
      "Epoch:  45\n",
      "304/361.0 loss: 0.6945054087482515 \n",
      "Epoch:  45\n",
      "305/361.0 loss: 0.694532095996383 \n",
      "Epoch:  45\n",
      "306/361.0 loss: 0.6945287779410422 \n",
      "Epoch:  45\n",
      "307/361.0 loss: 0.6944123814245323 \n",
      "Epoch:  45\n",
      "308/361.0 loss: 0.6942776177307549 \n",
      "Epoch:  45\n",
      "309/361.0 loss: 0.6940342247486114 \n",
      "Epoch:  45\n",
      "310/361.0 loss: 0.6940484596985329 \n",
      "Epoch:  45\n",
      "311/361.0 loss: 0.6940343658893536 \n",
      "Epoch:  45\n",
      "312/361.0 loss: 0.6937553993048379 \n",
      "Epoch:  45\n",
      "313/361.0 loss: 0.6941024721807735 \n",
      "Epoch:  45\n",
      "314/361.0 loss: 0.6940092328994993 \n",
      "Epoch:  45\n",
      "315/361.0 loss: 0.6938285273087176 \n",
      "Epoch:  45\n",
      "316/361.0 loss: 0.6936604158735425 \n",
      "Epoch:  45\n",
      "317/361.0 loss: 0.693311666917501 \n",
      "Epoch:  45\n",
      "318/361.0 loss: 0.692998462149342 \n",
      "Epoch:  45\n",
      "319/361.0 loss: 0.6932279851287604 \n",
      "Epoch:  45\n",
      "320/361.0 loss: 0.6931332182661395 \n",
      "Epoch:  45\n",
      "321/361.0 loss: 0.6931322485393618 \n",
      "Epoch:  45\n",
      "322/361.0 loss: 0.6929897723183174 \n",
      "Epoch:  45\n",
      "323/361.0 loss: 0.6929859769197158 \n",
      "Epoch:  45\n",
      "324/361.0 loss: 0.6928061531140254 \n",
      "Epoch:  45\n",
      "325/361.0 loss: 0.6928178360857116 \n",
      "Epoch:  45\n",
      "326/361.0 loss: 0.6932195240933596 \n",
      "Epoch:  45\n",
      "327/361.0 loss: 0.692968916965694 \n",
      "Epoch:  45\n",
      "328/361.0 loss: 0.6925839609650493 \n",
      "Epoch:  45\n",
      "329/361.0 loss: 0.6924307989351677 \n",
      "Epoch:  45\n",
      "330/361.0 loss: 0.692124878351782 \n",
      "Epoch:  45\n",
      "331/361.0 loss: 0.6923537394368505 \n",
      "Epoch:  45\n",
      "332/361.0 loss: 0.6924311629644744 \n",
      "Epoch:  45\n",
      "333/361.0 loss: 0.6922077002996456 \n",
      "Epoch:  45\n",
      "334/361.0 loss: 0.6923629091746771 \n",
      "Epoch:  45\n",
      "335/361.0 loss: 0.6924955718928859 \n",
      "Epoch:  45\n",
      "336/361.0 loss: 0.6923803819746929 \n",
      "Epoch:  45\n",
      "337/361.0 loss: 0.6927996302497458 \n",
      "Epoch:  45\n",
      "338/361.0 loss: 0.6931506207207311 \n",
      "Epoch:  45\n",
      "339/361.0 loss: 0.6930947203846539 \n",
      "Epoch:  45\n",
      "340/361.0 loss: 0.6929357653139624 \n",
      "Epoch:  45\n",
      "341/361.0 loss: 0.6925324159756041 \n",
      "Epoch:  45\n",
      "342/361.0 loss: 0.6924624199769935 \n",
      "Epoch:  45\n",
      "343/361.0 loss: 0.6924310596876366 \n",
      "Epoch:  45\n",
      "344/361.0 loss: 0.6924705641857092 \n",
      "Epoch:  45\n",
      "345/361.0 loss: 0.6926034289288383 \n",
      "Epoch:  45\n",
      "346/361.0 loss: 0.6930242594793138 \n",
      "Epoch:  45\n",
      "347/361.0 loss: 0.6928019910708241 \n",
      "Epoch:  45\n",
      "348/361.0 loss: 0.6926569250388268 \n",
      "Epoch:  45\n",
      "349/361.0 loss: 0.6928854152134487 \n",
      "Epoch:  45\n",
      "350/361.0 loss: 0.6930109495111341 \n",
      "Epoch:  45\n",
      "351/361.0 loss: 0.6927004441280257 \n",
      "Epoch:  45\n",
      "352/361.0 loss: 0.6927933407572782 \n",
      "Epoch:  45\n",
      "353/361.0 loss: 0.6928188294003912 \n",
      "Epoch:  45\n",
      "354/361.0 loss: 0.692770591420187 \n",
      "Epoch:  45\n",
      "355/361.0 loss: 0.6926132931133334 \n",
      "Epoch:  45\n",
      "356/361.0 loss: 0.6923311055541372 \n",
      "Epoch:  45\n",
      "357/361.0 loss: 0.6924534165326444 \n",
      "Epoch:  45\n",
      "358/361.0 loss: 0.6922035212304267 \n",
      "Epoch:  45\n",
      "359/361.0 loss: 0.6921308350231913 \n",
      "Epoch:  45\n",
      "360/361.0 loss: 0.6919584061300326 \n",
      "Epoch:  46\n",
      "0/361.0 loss: 0.7145804166793823 \n",
      "Epoch:  46\n",
      "1/361.0 loss: 0.6822245419025421 \n",
      "Epoch:  46\n",
      "2/361.0 loss: 0.6370726625124613 \n",
      "Epoch:  46\n",
      "3/361.0 loss: 0.6647865325212479 \n",
      "Epoch:  46\n",
      "4/361.0 loss: 0.6540844321250916 \n",
      "Epoch:  46\n",
      "5/361.0 loss: 0.6502177317937216 \n",
      "Epoch:  46\n",
      "6/361.0 loss: 0.6788096683365958 \n",
      "Epoch:  46\n",
      "7/361.0 loss: 0.6666324734687805 \n",
      "Epoch:  46\n",
      "8/361.0 loss: 0.6602368818389045 \n",
      "Epoch:  46\n",
      "9/361.0 loss: 0.666551285982132 \n",
      "Epoch:  46\n",
      "10/361.0 loss: 0.6637678146362305 \n",
      "Epoch:  46\n",
      "11/361.0 loss: 0.6717936893304189 \n",
      "Epoch:  46\n",
      "12/361.0 loss: 0.6798013036067669 \n",
      "Epoch:  46\n",
      "13/361.0 loss: 0.6917432716914585 \n",
      "Epoch:  46\n",
      "14/361.0 loss: 0.6844306349754333 \n",
      "Epoch:  46\n",
      "15/361.0 loss: 0.6867022998631 \n",
      "Epoch:  46\n",
      "16/361.0 loss: 0.6915584066334892 \n",
      "Epoch:  46\n",
      "17/361.0 loss: 0.6854793992307451 \n",
      "Epoch:  46\n",
      "18/361.0 loss: 0.6838878550027546 \n",
      "Epoch:  46\n",
      "19/361.0 loss: 0.6795609563589096 \n",
      "Epoch:  46\n",
      "20/361.0 loss: 0.6768019312903994 \n",
      "Epoch:  46\n",
      "21/361.0 loss: 0.673876244913448 \n",
      "Epoch:  46\n",
      "22/361.0 loss: 0.6773932524349379 \n",
      "Epoch:  46\n",
      "23/361.0 loss: 0.6779255891839663 \n",
      "Epoch:  46\n",
      "24/361.0 loss: 0.6778238201141358 \n",
      "Epoch:  46\n",
      "25/361.0 loss: 0.6807767748832703 \n",
      "Epoch:  46\n",
      "26/361.0 loss: 0.6776529771310312 \n",
      "Epoch:  46\n",
      "27/361.0 loss: 0.6791373512574604 \n",
      "Epoch:  46\n",
      "28/361.0 loss: 0.6840554331911022 \n",
      "Epoch:  46\n",
      "29/361.0 loss: 0.6834694385528565 \n",
      "Epoch:  46\n",
      "30/361.0 loss: 0.6807673073584034 \n",
      "Epoch:  46\n",
      "31/361.0 loss: 0.6842163726687431 \n",
      "Epoch:  46\n",
      "32/361.0 loss: 0.6812672705361338 \n",
      "Epoch:  46\n",
      "33/361.0 loss: 0.6846582416225883 \n",
      "Epoch:  46\n",
      "34/361.0 loss: 0.6809354475566319 \n",
      "Epoch:  46\n",
      "35/361.0 loss: 0.6774905588891771 \n",
      "Epoch:  46\n",
      "36/361.0 loss: 0.67658212539312 \n",
      "Epoch:  46\n",
      "37/361.0 loss: 0.6770271282447012 \n",
      "Epoch:  46\n",
      "38/361.0 loss: 0.6807047159243853 \n",
      "Epoch:  46\n",
      "39/361.0 loss: 0.67927787899971 \n",
      "Epoch:  46\n",
      "40/361.0 loss: 0.6829562448873753 \n",
      "Epoch:  46\n",
      "41/361.0 loss: 0.6795008608273098 \n",
      "Epoch:  46\n",
      "42/361.0 loss: 0.6778055318566256 \n",
      "Epoch:  46\n",
      "43/361.0 loss: 0.6764735701409254 \n",
      "Epoch:  46\n",
      "44/361.0 loss: 0.6803149660428365 \n",
      "Epoch:  46\n",
      "45/361.0 loss: 0.6783855661101963 \n",
      "Epoch:  46\n",
      "46/361.0 loss: 0.6808822573499477 \n",
      "Epoch:  46\n",
      "47/361.0 loss: 0.6838068502644697 \n",
      "Epoch:  46\n",
      "48/361.0 loss: 0.6822741919634293 \n",
      "Epoch:  46\n",
      "49/361.0 loss: 0.6823933696746827 \n",
      "Epoch:  46\n",
      "50/361.0 loss: 0.6841964803489984 \n",
      "Epoch:  46\n",
      "51/361.0 loss: 0.6871749781645261 \n",
      "Epoch:  46\n",
      "52/361.0 loss: 0.6857764091131822 \n",
      "Epoch:  46\n",
      "53/361.0 loss: 0.6846481252599645 \n",
      "Epoch:  46\n",
      "54/361.0 loss: 0.6862299951640043 \n",
      "Epoch:  46\n",
      "55/361.0 loss: 0.6853418584380832 \n",
      "Epoch:  46\n",
      "56/361.0 loss: 0.6830828733611525 \n",
      "Epoch:  46\n",
      "57/361.0 loss: 0.6811577369426859 \n",
      "Epoch:  46\n",
      "58/361.0 loss: 0.6802188158035278 \n",
      "Epoch:  46\n",
      "59/361.0 loss: 0.6779047846794128 \n",
      "Epoch:  46\n",
      "60/361.0 loss: 0.678829059249065 \n",
      "Epoch:  46\n",
      "61/361.0 loss: 0.6776255494163882 \n",
      "Epoch:  46\n",
      "62/361.0 loss: 0.6767074673894852 \n",
      "Epoch:  46\n",
      "63/361.0 loss: 0.679685608483851 \n",
      "Epoch:  46\n",
      "64/361.0 loss: 0.6801878287242009 \n",
      "Epoch:  46\n",
      "65/361.0 loss: 0.6821010022452383 \n",
      "Epoch:  46\n",
      "66/361.0 loss: 0.6842128687830114 \n",
      "Epoch:  46\n",
      "67/361.0 loss: 0.6831119814339806 \n",
      "Epoch:  46\n",
      "68/361.0 loss: 0.6818543862605441 \n",
      "Epoch:  46\n",
      "69/361.0 loss: 0.6811481390680586 \n",
      "Epoch:  46\n",
      "70/361.0 loss: 0.6801037897526379 \n",
      "Epoch:  46\n",
      "71/361.0 loss: 0.6790040226446258 \n",
      "Epoch:  46\n",
      "72/361.0 loss: 0.6804929032717666 \n",
      "Epoch:  46\n",
      "73/361.0 loss: 0.6829005946984162 \n",
      "Epoch:  46\n",
      "74/361.0 loss: 0.6807150506973266 \n",
      "Epoch:  46\n",
      "75/361.0 loss: 0.6798178875132611 \n",
      "Epoch:  46\n",
      "76/361.0 loss: 0.6821163265736072 \n",
      "Epoch:  46\n",
      "77/361.0 loss: 0.6838992795883081 \n",
      "Epoch:  46\n",
      "78/361.0 loss: 0.6839831546892093 \n",
      "Epoch:  46\n",
      "79/361.0 loss: 0.6843621253967285 \n",
      "Epoch:  46\n",
      "80/361.0 loss: 0.6850451738746078 \n",
      "Epoch:  46\n",
      "81/361.0 loss: 0.6839379159415641 \n",
      "Epoch:  46\n",
      "82/361.0 loss: 0.6858210692922753 \n",
      "Epoch:  46\n",
      "83/361.0 loss: 0.6861642265603656 \n",
      "Epoch:  46\n",
      "84/361.0 loss: 0.6874023886287913 \n",
      "Epoch:  46\n",
      "85/361.0 loss: 0.687866794508557 \n",
      "Epoch:  46\n",
      "86/361.0 loss: 0.6882098693957274 \n",
      "Epoch:  46\n",
      "87/361.0 loss: 0.6870402686975219 \n",
      "Epoch:  46\n",
      "88/361.0 loss: 0.6865575434116835 \n",
      "Epoch:  46\n",
      "89/361.0 loss: 0.6864165286223094 \n",
      "Epoch:  46\n",
      "90/361.0 loss: 0.6876574289667737 \n",
      "Epoch:  46\n",
      "91/361.0 loss: 0.6860530998395837 \n",
      "Epoch:  46\n",
      "92/361.0 loss: 0.6868398292090303 \n",
      "Epoch:  46\n",
      "93/361.0 loss: 0.6858195757612269 \n",
      "Epoch:  46\n",
      "94/361.0 loss: 0.6856032164473282 \n",
      "Epoch:  46\n",
      "95/361.0 loss: 0.685113649815321 \n",
      "Epoch:  46\n",
      "96/361.0 loss: 0.6859521632341995 \n",
      "Epoch:  46\n",
      "97/361.0 loss: 0.6862499738226131 \n",
      "Epoch:  46\n",
      "98/361.0 loss: 0.6846690755901914 \n",
      "Epoch:  46\n",
      "99/361.0 loss: 0.6858282548189163 \n",
      "Epoch:  46\n",
      "100/361.0 loss: 0.6859408038677556 \n",
      "Epoch:  46\n",
      "101/361.0 loss: 0.6847537393663444 \n",
      "Epoch:  46\n",
      "102/361.0 loss: 0.685762760708633 \n",
      "Epoch:  46\n",
      "103/361.0 loss: 0.686967691549888 \n",
      "Epoch:  46\n",
      "104/361.0 loss: 0.6873124287241981 \n",
      "Epoch:  46\n",
      "105/361.0 loss: 0.6878373088701716 \n",
      "Epoch:  46\n",
      "106/361.0 loss: 0.6864532895177324 \n",
      "Epoch:  46\n",
      "107/361.0 loss: 0.6858240393576799 \n",
      "Epoch:  46\n",
      "108/361.0 loss: 0.684519263582492 \n",
      "Epoch:  46\n",
      "109/361.0 loss: 0.6837878985838457 \n",
      "Epoch:  46\n",
      "110/361.0 loss: 0.6847259590217659 \n",
      "Epoch:  46\n",
      "111/361.0 loss: 0.6834147215953895 \n",
      "Epoch:  46\n",
      "112/361.0 loss: 0.682802844891506 \n",
      "Epoch:  46\n",
      "113/361.0 loss: 0.6817507393527449 \n",
      "Epoch:  46\n",
      "114/361.0 loss: 0.6826446289601533 \n",
      "Epoch:  46\n",
      "115/361.0 loss: 0.6838057303223116 \n",
      "Epoch:  46\n",
      "116/361.0 loss: 0.6845802848155682 \n",
      "Epoch:  46\n",
      "117/361.0 loss: 0.6841562137765399 \n",
      "Epoch:  46\n",
      "118/361.0 loss: 0.6844510636409792 \n",
      "Epoch:  46\n",
      "119/361.0 loss: 0.6845475375652313 \n",
      "Epoch:  46\n",
      "120/361.0 loss: 0.6855859145645268 \n",
      "Epoch:  46\n",
      "121/361.0 loss: 0.6861089082037817 \n",
      "Epoch:  46\n",
      "122/361.0 loss: 0.6856018726418658 \n",
      "Epoch:  46\n",
      "123/361.0 loss: 0.6852675008196984 \n",
      "Epoch:  46\n",
      "124/361.0 loss: 0.6840092463493347 \n",
      "Epoch:  46\n",
      "125/361.0 loss: 0.6848818976727743 \n",
      "Epoch:  46\n",
      "126/361.0 loss: 0.6850170155209819 \n",
      "Epoch:  46\n",
      "127/361.0 loss: 0.6871350714936852 \n",
      "Epoch:  46\n",
      "128/361.0 loss: 0.6862107293550358 \n",
      "Epoch:  46\n",
      "129/361.0 loss: 0.6859723237844614 \n",
      "Epoch:  46\n",
      "130/361.0 loss: 0.6853247753536428 \n",
      "Epoch:  46\n",
      "131/361.0 loss: 0.6846387074752287 \n",
      "Epoch:  46\n",
      "132/361.0 loss: 0.6850257937173198 \n",
      "Epoch:  46\n",
      "133/361.0 loss: 0.6856684969432318 \n",
      "Epoch:  46\n",
      "134/361.0 loss: 0.6861194169079816 \n",
      "Epoch:  46\n",
      "135/361.0 loss: 0.6874565328745281 \n",
      "Epoch:  46\n",
      "136/361.0 loss: 0.6880488882969765 \n",
      "Epoch:  46\n",
      "137/361.0 loss: 0.6887613984121792 \n",
      "Epoch:  46\n",
      "138/361.0 loss: 0.6892925016314005 \n",
      "Epoch:  46\n",
      "139/361.0 loss: 0.6895222272191729 \n",
      "Epoch:  46\n",
      "140/361.0 loss: 0.6901224428880299 \n",
      "Epoch:  46\n",
      "141/361.0 loss: 0.6899594664573669 \n",
      "Epoch:  46\n",
      "142/361.0 loss: 0.6894861789016457 \n",
      "Epoch:  46\n",
      "143/361.0 loss: 0.6893557388749387 \n",
      "Epoch:  46\n",
      "144/361.0 loss: 0.6892848458783379 \n",
      "Epoch:  46\n",
      "145/361.0 loss: 0.6898805784852537 \n",
      "Epoch:  46\n",
      "146/361.0 loss: 0.6896432407048284 \n",
      "Epoch:  46\n",
      "147/361.0 loss: 0.6890717756909293 \n",
      "Epoch:  46\n",
      "148/361.0 loss: 0.6885938256378942 \n",
      "Epoch:  46\n",
      "149/361.0 loss: 0.6880733438332876 \n",
      "Epoch:  46\n",
      "150/361.0 loss: 0.6879632370361429 \n",
      "Epoch:  46\n",
      "151/361.0 loss: 0.6873486351810003 \n",
      "Epoch:  46\n",
      "152/361.0 loss: 0.6873356735005098 \n",
      "Epoch:  46\n",
      "153/361.0 loss: 0.6876788766353161 \n",
      "Epoch:  46\n",
      "154/361.0 loss: 0.6872728409305695 \n",
      "Epoch:  46\n",
      "155/361.0 loss: 0.6865325142175723 \n",
      "Epoch:  46\n",
      "156/361.0 loss: 0.6860740503687768 \n",
      "Epoch:  46\n",
      "157/361.0 loss: 0.6854577917086927 \n",
      "Epoch:  46\n",
      "158/361.0 loss: 0.6860168032676169 \n",
      "Epoch:  46\n",
      "159/361.0 loss: 0.6857319746166468 \n",
      "Epoch:  46\n",
      "160/361.0 loss: 0.6855678884138973 \n",
      "Epoch:  46\n",
      "161/361.0 loss: 0.6851983228583395 \n",
      "Epoch:  46\n",
      "162/361.0 loss: 0.6856669889637298 \n",
      "Epoch:  46\n",
      "163/361.0 loss: 0.6862410561340612 \n",
      "Epoch:  46\n",
      "164/361.0 loss: 0.6869963895190846 \n",
      "Epoch:  46\n",
      "165/361.0 loss: 0.6863958720701286 \n",
      "Epoch:  46\n",
      "166/361.0 loss: 0.685753283743373 \n",
      "Epoch:  46\n",
      "167/361.0 loss: 0.6869012440244356 \n",
      "Epoch:  46\n",
      "168/361.0 loss: 0.6864173542818374 \n",
      "Epoch:  46\n",
      "169/361.0 loss: 0.6869944463757908 \n",
      "Epoch:  46\n",
      "170/361.0 loss: 0.6870586488679139 \n",
      "Epoch:  46\n",
      "171/361.0 loss: 0.6870057821966881 \n",
      "Epoch:  46\n",
      "172/361.0 loss: 0.686393404627122 \n",
      "Epoch:  46\n",
      "173/361.0 loss: 0.6874371352551998 \n",
      "Epoch:  46\n",
      "174/361.0 loss: 0.6867138586725507 \n",
      "Epoch:  46\n",
      "175/361.0 loss: 0.6861438967964866 \n",
      "Epoch:  46\n",
      "176/361.0 loss: 0.6870621489939717 \n",
      "Epoch:  46\n",
      "177/361.0 loss: 0.6874010435650858 \n",
      "Epoch:  46\n",
      "178/361.0 loss: 0.6882794402831094 \n",
      "Epoch:  46\n",
      "179/361.0 loss: 0.6882643603616291 \n",
      "Epoch:  46\n",
      "180/361.0 loss: 0.687845654579816 \n",
      "Epoch:  46\n",
      "181/361.0 loss: 0.6884673686472924 \n",
      "Epoch:  46\n",
      "182/361.0 loss: 0.6889243406024786 \n",
      "Epoch:  46\n",
      "183/361.0 loss: 0.6884632700163386 \n",
      "Epoch:  46\n",
      "184/361.0 loss: 0.6882902380582449 \n",
      "Epoch:  46\n",
      "185/361.0 loss: 0.6877841388666501 \n",
      "Epoch:  46\n",
      "186/361.0 loss: 0.6883184093842531 \n",
      "Epoch:  46\n",
      "187/361.0 loss: 0.6887182555300124 \n",
      "Epoch:  46\n",
      "188/361.0 loss: 0.6894132207941126 \n",
      "Epoch:  46\n",
      "189/361.0 loss: 0.6899971591798882 \n",
      "Epoch:  46\n",
      "190/361.0 loss: 0.690141399181326 \n",
      "Epoch:  46\n",
      "191/361.0 loss: 0.690768516001602 \n",
      "Epoch:  46\n",
      "192/361.0 loss: 0.6915683514713623 \n",
      "Epoch:  46\n",
      "193/361.0 loss: 0.6917786533685074 \n",
      "Epoch:  46\n",
      "194/361.0 loss: 0.6926441828409831 \n",
      "Epoch:  46\n",
      "195/361.0 loss: 0.6928521783984437 \n",
      "Epoch:  46\n",
      "196/361.0 loss: 0.6933177137737951 \n",
      "Epoch:  46\n",
      "197/361.0 loss: 0.6929275173731525 \n",
      "Epoch:  46\n",
      "198/361.0 loss: 0.6924754069678148 \n",
      "Epoch:  46\n",
      "199/361.0 loss: 0.6921029219031334 \n",
      "Epoch:  46\n",
      "200/361.0 loss: 0.6918479201212451 \n",
      "Epoch:  46\n",
      "201/361.0 loss: 0.6917359170937302 \n",
      "Epoch:  46\n",
      "202/361.0 loss: 0.6916790428420005 \n",
      "Epoch:  46\n",
      "203/361.0 loss: 0.6920932674524831 \n",
      "Epoch:  46\n",
      "204/361.0 loss: 0.6916672439109989 \n",
      "Epoch:  46\n",
      "205/361.0 loss: 0.6912119050049087 \n",
      "Epoch:  46\n",
      "206/361.0 loss: 0.6913707046117183 \n",
      "Epoch:  46\n",
      "207/361.0 loss: 0.6915626992972997 \n",
      "Epoch:  46\n",
      "208/361.0 loss: 0.6918975029265482 \n",
      "Epoch:  46\n",
      "209/361.0 loss: 0.6921956749189467 \n",
      "Epoch:  46\n",
      "210/361.0 loss: 0.6925158661688674 \n",
      "Epoch:  46\n",
      "211/361.0 loss: 0.6922214601962071 \n",
      "Epoch:  46\n",
      "212/361.0 loss: 0.6922239093153689 \n",
      "Epoch:  46\n",
      "213/361.0 loss: 0.6931921394071846 \n",
      "Epoch:  46\n",
      "214/361.0 loss: 0.6929332461468009 \n",
      "Epoch:  46\n",
      "215/361.0 loss: 0.693296691885701 \n",
      "Epoch:  46\n",
      "216/361.0 loss: 0.6927218401486972 \n",
      "Epoch:  46\n",
      "217/361.0 loss: 0.6930965442176259 \n",
      "Epoch:  46\n",
      "218/361.0 loss: 0.6927088123478301 \n",
      "Epoch:  46\n",
      "219/361.0 loss: 0.6924190415577455 \n",
      "Epoch:  46\n",
      "220/361.0 loss: 0.6920015283299787 \n",
      "Epoch:  46\n",
      "221/361.0 loss: 0.692145934244534 \n",
      "Epoch:  46\n",
      "222/361.0 loss: 0.6925591417492238 \n",
      "Epoch:  46\n",
      "223/361.0 loss: 0.6929866493280444 \n",
      "Epoch:  46\n",
      "224/361.0 loss: 0.6932165127330356 \n",
      "Epoch:  46\n",
      "225/361.0 loss: 0.6931464495384587 \n",
      "Epoch:  46\n",
      "226/361.0 loss: 0.6932335674500151 \n",
      "Epoch:  46\n",
      "227/361.0 loss: 0.6929275409171456 \n",
      "Epoch:  46\n",
      "228/361.0 loss: 0.6931847287057269 \n",
      "Epoch:  46\n",
      "229/361.0 loss: 0.692929243263991 \n",
      "Epoch:  46\n",
      "230/361.0 loss: 0.6927175746335612 \n",
      "Epoch:  46\n",
      "231/361.0 loss: 0.6931825824852648 \n",
      "Epoch:  46\n",
      "232/361.0 loss: 0.6934581483382524 \n",
      "Epoch:  46\n",
      "233/361.0 loss: 0.6938357674158536 \n",
      "Epoch:  46\n",
      "234/361.0 loss: 0.6933515465005915 \n",
      "Epoch:  46\n",
      "235/361.0 loss: 0.6930838800587896 \n",
      "Epoch:  46\n",
      "236/361.0 loss: 0.6929400477731278 \n",
      "Epoch:  46\n",
      "237/361.0 loss: 0.6927609586415171 \n",
      "Epoch:  46\n",
      "238/361.0 loss: 0.6929077254179631 \n",
      "Epoch:  46\n",
      "239/361.0 loss: 0.6934529840946198 \n",
      "Epoch:  46\n",
      "240/361.0 loss: 0.6938745480850029 \n",
      "Epoch:  46\n",
      "241/361.0 loss: 0.6935184556098024 \n",
      "Epoch:  46\n",
      "242/361.0 loss: 0.694028056698081 \n",
      "Epoch:  46\n",
      "243/361.0 loss: 0.6939793268188101 \n",
      "Epoch:  46\n",
      "244/361.0 loss: 0.6937780771936689 \n",
      "Epoch:  46\n",
      "245/361.0 loss: 0.6937616188836292 \n",
      "Epoch:  46\n",
      "246/361.0 loss: 0.6934297820817121 \n",
      "Epoch:  46\n",
      "247/361.0 loss: 0.69385932482058 \n",
      "Epoch:  46\n",
      "248/361.0 loss: 0.6941633933040512 \n",
      "Epoch:  46\n",
      "249/361.0 loss: 0.6940501811504364 \n",
      "Epoch:  46\n",
      "250/361.0 loss: 0.6937848543265901 \n",
      "Epoch:  46\n",
      "251/361.0 loss: 0.694056866187898 \n",
      "Epoch:  46\n",
      "252/361.0 loss: 0.6947681149946371 \n",
      "Epoch:  46\n",
      "253/361.0 loss: 0.6947342746370421 \n",
      "Epoch:  46\n",
      "254/361.0 loss: 0.6950236047015471 \n",
      "Epoch:  46\n",
      "255/361.0 loss: 0.6950300561729819 \n",
      "Epoch:  46\n",
      "256/361.0 loss: 0.6958365043777436 \n",
      "Epoch:  46\n",
      "257/361.0 loss: 0.6958286071470542 \n",
      "Epoch:  46\n",
      "258/361.0 loss: 0.6959111384443335 \n",
      "Epoch:  46\n",
      "259/361.0 loss: 0.6961094402349912 \n",
      "Epoch:  46\n",
      "260/361.0 loss: 0.6963345999918679 \n",
      "Epoch:  46\n",
      "261/361.0 loss: 0.6962771263286358 \n",
      "Epoch:  46\n",
      "262/361.0 loss: 0.6960185281224124 \n",
      "Epoch:  46\n",
      "263/361.0 loss: 0.6961447761365862 \n",
      "Epoch:  46\n",
      "264/361.0 loss: 0.6965867903997314 \n",
      "Epoch:  46\n",
      "265/361.0 loss: 0.6964345686417773 \n",
      "Epoch:  46\n",
      "266/361.0 loss: 0.6963243281350153 \n",
      "Epoch:  46\n",
      "267/361.0 loss: 0.6964132970393594 \n",
      "Epoch:  46\n",
      "268/361.0 loss: 0.6964866485737513 \n",
      "Epoch:  46\n",
      "269/361.0 loss: 0.6962434768676757 \n",
      "Epoch:  46\n",
      "270/361.0 loss: 0.6962663940398016 \n",
      "Epoch:  46\n",
      "271/361.0 loss: 0.6962586952482953 \n",
      "Epoch:  46\n",
      "272/361.0 loss: 0.6960048909152384 \n",
      "Epoch:  46\n",
      "273/361.0 loss: 0.6962036620961488 \n",
      "Epoch:  46\n",
      "274/361.0 loss: 0.6967019029097123 \n",
      "Epoch:  46\n",
      "275/361.0 loss: 0.6967921371477238 \n",
      "Epoch:  46\n",
      "276/361.0 loss: 0.6968867593723944 \n",
      "Epoch:  46\n",
      "277/361.0 loss: 0.6968636257614164 \n",
      "Epoch:  46\n",
      "278/361.0 loss: 0.6969054550680208 \n",
      "Epoch:  46\n",
      "279/361.0 loss: 0.69662190420287 \n",
      "Epoch:  46\n",
      "280/361.0 loss: 0.696522368655086 \n",
      "Epoch:  46\n",
      "281/361.0 loss: 0.6965095022468702 \n",
      "Epoch:  46\n",
      "282/361.0 loss: 0.6962917758803485 \n",
      "Epoch:  46\n",
      "283/361.0 loss: 0.6964690080830749 \n",
      "Epoch:  46\n",
      "284/361.0 loss: 0.6969789069995546 \n",
      "Epoch:  46\n",
      "285/361.0 loss: 0.6969200185128859 \n",
      "Epoch:  46\n",
      "286/361.0 loss: 0.6972879773648358 \n",
      "Epoch:  46\n",
      "287/361.0 loss: 0.6973569612536166 \n",
      "Epoch:  46\n",
      "288/361.0 loss: 0.6973842064814584 \n",
      "Epoch:  46\n",
      "289/361.0 loss: 0.6971757395514127 \n",
      "Epoch:  46\n",
      "290/361.0 loss: 0.6971533902731958 \n",
      "Epoch:  46\n",
      "291/361.0 loss: 0.6968468552174634 \n",
      "Epoch:  46\n",
      "292/361.0 loss: 0.6967580460851103 \n",
      "Epoch:  46\n",
      "293/361.0 loss: 0.6968230331430629 \n",
      "Epoch:  46\n",
      "294/361.0 loss: 0.6965426281347114 \n",
      "Epoch:  46\n",
      "295/361.0 loss: 0.6967184370433962 \n",
      "Epoch:  46\n",
      "296/361.0 loss: 0.6964988453621014 \n",
      "Epoch:  46\n",
      "297/361.0 loss: 0.6961737875170355 \n",
      "Epoch:  46\n",
      "298/361.0 loss: 0.6962265348354709 \n",
      "Epoch:  46\n",
      "299/361.0 loss: 0.6961069826285045 \n",
      "Epoch:  46\n",
      "300/361.0 loss: 0.6963190026457523 \n",
      "Epoch:  46\n",
      "301/361.0 loss: 0.6965353921154477 \n",
      "Epoch:  46\n",
      "302/361.0 loss: 0.6965161070178444 \n",
      "Epoch:  46\n",
      "303/361.0 loss: 0.6969254097264064 \n",
      "Epoch:  46\n",
      "304/361.0 loss: 0.6971087995122691 \n",
      "Epoch:  46\n",
      "305/361.0 loss: 0.6971149506911732 \n",
      "Epoch:  46\n",
      "306/361.0 loss: 0.6973883198992825 \n",
      "Epoch:  46\n",
      "307/361.0 loss: 0.6971891979118446 \n",
      "Epoch:  46\n",
      "308/361.0 loss: 0.6972444377670782 \n",
      "Epoch:  46\n",
      "309/361.0 loss: 0.6971694111824036 \n",
      "Epoch:  46\n",
      "310/361.0 loss: 0.6968606882923286 \n",
      "Epoch:  46\n",
      "311/361.0 loss: 0.6972200412016648 \n",
      "Epoch:  46\n",
      "312/361.0 loss: 0.697558262858528 \n",
      "Epoch:  46\n",
      "313/361.0 loss: 0.6975022702460076 \n",
      "Epoch:  46\n",
      "314/361.0 loss: 0.6971911203293574 \n",
      "Epoch:  46\n",
      "315/361.0 loss: 0.6973738485499273 \n",
      "Epoch:  46\n",
      "316/361.0 loss: 0.6974859561077804 \n",
      "Epoch:  46\n",
      "317/361.0 loss: 0.6970849764422051 \n",
      "Epoch:  46\n",
      "318/361.0 loss: 0.6972967332059686 \n",
      "Epoch:  46\n",
      "319/361.0 loss: 0.6974108219146729 \n",
      "Epoch:  46\n",
      "320/361.0 loss: 0.6973859879458062 \n",
      "Epoch:  46\n",
      "321/361.0 loss: 0.6972362436122775 \n",
      "Epoch:  46\n",
      "322/361.0 loss: 0.6977669700011381 \n",
      "Epoch:  46\n",
      "323/361.0 loss: 0.6975572475312669 \n",
      "Epoch:  46\n",
      "324/361.0 loss: 0.6976949746792133 \n",
      "Epoch:  46\n",
      "325/361.0 loss: 0.6977594233363684 \n",
      "Epoch:  46\n",
      "326/361.0 loss: 0.6976486333284174 \n",
      "Epoch:  46\n",
      "327/361.0 loss: 0.6975582427367931 \n",
      "Epoch:  46\n",
      "328/361.0 loss: 0.6978119899799033 \n",
      "Epoch:  46\n",
      "329/361.0 loss: 0.6978070907520525 \n",
      "Epoch:  46\n",
      "330/361.0 loss: 0.6979481529253126 \n",
      "Epoch:  46\n",
      "331/361.0 loss: 0.6979896993522184 \n",
      "Epoch:  46\n",
      "332/361.0 loss: 0.6981132440380864 \n",
      "Epoch:  46\n",
      "333/361.0 loss: 0.6980568009936167 \n",
      "Epoch:  46\n",
      "334/361.0 loss: 0.6980845159559107 \n",
      "Epoch:  46\n",
      "335/361.0 loss: 0.6979579819100243 \n",
      "Epoch:  46\n",
      "336/361.0 loss: 0.6982399835430904 \n",
      "Epoch:  46\n",
      "337/361.0 loss: 0.6981253549897459 \n",
      "Epoch:  46\n",
      "338/361.0 loss: 0.6981466736062086 \n",
      "Epoch:  46\n",
      "339/361.0 loss: 0.6980877741294749 \n",
      "Epoch:  46\n",
      "340/361.0 loss: 0.698122484418304 \n",
      "Epoch:  46\n",
      "341/361.0 loss: 0.6981988549232483 \n",
      "Epoch:  46\n",
      "342/361.0 loss: 0.6980330716416717 \n",
      "Epoch:  46\n",
      "343/361.0 loss: 0.6978183806289074 \n",
      "Epoch:  46\n",
      "344/361.0 loss: 0.6979097580564195 \n",
      "Epoch:  46\n",
      "345/361.0 loss: 0.6980699350723641 \n",
      "Epoch:  46\n",
      "346/361.0 loss: 0.6982734852634177 \n",
      "Epoch:  46\n",
      "347/361.0 loss: 0.698538526892662 \n",
      "Epoch:  46\n",
      "348/361.0 loss: 0.6984716479621166 \n",
      "Epoch:  46\n",
      "349/361.0 loss: 0.69882733804839 \n",
      "Epoch:  46\n",
      "350/361.0 loss: 0.6989340855185463 \n",
      "Epoch:  46\n",
      "351/361.0 loss: 0.6986619113859805 \n",
      "Epoch:  46\n",
      "352/361.0 loss: 0.69867072936158 \n",
      "Epoch:  46\n",
      "353/361.0 loss: 0.6986604939072819 \n",
      "Epoch:  46\n",
      "354/361.0 loss: 0.6985222898738485 \n",
      "Epoch:  46\n",
      "355/361.0 loss: 0.6983202809698126 \n",
      "Epoch:  46\n",
      "356/361.0 loss: 0.698599446387518 \n",
      "Epoch:  46\n",
      "357/361.0 loss: 0.6986603793485204 \n",
      "Epoch:  46\n",
      "358/361.0 loss: 0.6985919538646688 \n",
      "Epoch:  46\n",
      "359/361.0 loss: 0.6983620398574405 \n",
      "Epoch:  46\n",
      "360/361.0 loss: 0.6983386973264805 \n",
      "Epoch:  47\n",
      "0/361.0 loss: 0.7584804892539978 \n",
      "Epoch:  47\n",
      "1/361.0 loss: 0.7520171105861664 \n",
      "Epoch:  47\n",
      "2/361.0 loss: 0.7233861287434896 \n",
      "Epoch:  47\n",
      "3/361.0 loss: 0.7276988178491592 \n",
      "Epoch:  47\n",
      "4/361.0 loss: 0.748720669746399 \n",
      "Epoch:  47\n",
      "5/361.0 loss: 0.7441972494125366 \n",
      "Epoch:  47\n",
      "6/361.0 loss: 0.7409565023013523 \n",
      "Epoch:  47\n",
      "7/361.0 loss: 0.7210341170430183 \n",
      "Epoch:  47\n",
      "8/361.0 loss: 0.7232464883062575 \n",
      "Epoch:  47\n",
      "9/361.0 loss: 0.7180654883384705 \n",
      "Epoch:  47\n",
      "10/361.0 loss: 0.7057936625047163 \n",
      "Epoch:  47\n",
      "11/361.0 loss: 0.7055021723111471 \n",
      "Epoch:  47\n",
      "12/361.0 loss: 0.7015170317429763 \n",
      "Epoch:  47\n",
      "13/361.0 loss: 0.7042661820139203 \n",
      "Epoch:  47\n",
      "14/361.0 loss: 0.6986985882123311 \n",
      "Epoch:  47\n",
      "15/361.0 loss: 0.698704294860363 \n",
      "Epoch:  47\n",
      "16/361.0 loss: 0.6991724652402541 \n",
      "Epoch:  47\n",
      "17/361.0 loss: 0.7024327251646254 \n",
      "Epoch:  47\n",
      "18/361.0 loss: 0.7025151315488314 \n",
      "Epoch:  47\n",
      "19/361.0 loss: 0.7029788732528687 \n",
      "Epoch:  47\n",
      "20/361.0 loss: 0.7087013607933408 \n",
      "Epoch:  47\n",
      "21/361.0 loss: 0.7109334035353227 \n",
      "Epoch:  47\n",
      "22/361.0 loss: 0.7133506225503009 \n",
      "Epoch:  47\n",
      "23/361.0 loss: 0.7129969547192255 \n",
      "Epoch:  47\n",
      "24/361.0 loss: 0.7096838188171387 \n",
      "Epoch:  47\n",
      "25/361.0 loss: 0.7079389897676615 \n",
      "Epoch:  47\n",
      "26/361.0 loss: 0.7051873913517704 \n",
      "Epoch:  47\n",
      "27/361.0 loss: 0.703221008181572 \n",
      "Epoch:  47\n",
      "28/361.0 loss: 0.701502799987793 \n",
      "Epoch:  47\n",
      "29/361.0 loss: 0.7008889595667521 \n",
      "Epoch:  47\n",
      "30/361.0 loss: 0.7016830828882032 \n",
      "Epoch:  47\n",
      "31/361.0 loss: 0.7002557143568993 \n",
      "Epoch:  47\n",
      "32/361.0 loss: 0.6996988112276251 \n",
      "Epoch:  47\n",
      "33/361.0 loss: 0.7006372511386871 \n",
      "Epoch:  47\n",
      "34/361.0 loss: 0.7023612209728786 \n",
      "Epoch:  47\n",
      "35/361.0 loss: 0.7002967960304685 \n",
      "Epoch:  47\n",
      "36/361.0 loss: 0.6985226354083499 \n",
      "Epoch:  47\n",
      "37/361.0 loss: 0.6956776945214522 \n",
      "Epoch:  47\n",
      "38/361.0 loss: 0.693619177891658 \n",
      "Epoch:  47\n",
      "39/361.0 loss: 0.6926714926958084 \n",
      "Epoch:  47\n",
      "40/361.0 loss: 0.693270726901729 \n",
      "Epoch:  47\n",
      "41/361.0 loss: 0.6914678187597365 \n",
      "Epoch:  47\n",
      "42/361.0 loss: 0.692599798357764 \n",
      "Epoch:  47\n",
      "43/361.0 loss: 0.6921264664693312 \n",
      "Epoch:  47\n",
      "44/361.0 loss: 0.6930251876513164 \n",
      "Epoch:  47\n",
      "45/361.0 loss: 0.6937889741814655 \n",
      "Epoch:  47\n",
      "46/361.0 loss: 0.6931002723409775 \n",
      "Epoch:  47\n",
      "47/361.0 loss: 0.6957360381881396 \n",
      "Epoch:  47\n",
      "48/361.0 loss: 0.6953234818516946 \n",
      "Epoch:  47\n",
      "49/361.0 loss: 0.697656489610672 \n",
      "Epoch:  47\n",
      "50/361.0 loss: 0.698246138937333 \n",
      "Epoch:  47\n",
      "51/361.0 loss: 0.7000883703048413 \n",
      "Epoch:  47\n",
      "52/361.0 loss: 0.6991328585822627 \n",
      "Epoch:  47\n",
      "53/361.0 loss: 0.7000601799399765 \n",
      "Epoch:  47\n",
      "54/361.0 loss: 0.6999520822004839 \n",
      "Epoch:  47\n",
      "55/361.0 loss: 0.6994108419333186 \n",
      "Epoch:  47\n",
      "56/361.0 loss: 0.6979615813807437 \n",
      "Epoch:  47\n",
      "57/361.0 loss: 0.6966822609819215 \n",
      "Epoch:  47\n",
      "58/361.0 loss: 0.6963629874132448 \n",
      "Epoch:  47\n",
      "59/361.0 loss: 0.6956348448991776 \n",
      "Epoch:  47\n",
      "60/361.0 loss: 0.6944034978991649 \n",
      "Epoch:  47\n",
      "61/361.0 loss: 0.6961559230281461 \n",
      "Epoch:  47\n",
      "62/361.0 loss: 0.6967028426745582 \n",
      "Epoch:  47\n",
      "63/361.0 loss: 0.6964957201853395 \n",
      "Epoch:  47\n",
      "64/361.0 loss: 0.6970239098255451 \n",
      "Epoch:  47\n",
      "65/361.0 loss: 0.6964550451798872 \n",
      "Epoch:  47\n",
      "66/361.0 loss: 0.6951346183890728 \n",
      "Epoch:  47\n",
      "67/361.0 loss: 0.6941283450407141 \n",
      "Epoch:  47\n",
      "68/361.0 loss: 0.6955138669497725 \n",
      "Epoch:  47\n",
      "69/361.0 loss: 0.6949360115187508 \n",
      "Epoch:  47\n",
      "70/361.0 loss: 0.6960623012462133 \n",
      "Epoch:  47\n",
      "71/361.0 loss: 0.6974198313222991 \n",
      "Epoch:  47\n",
      "72/361.0 loss: 0.6983777064166657 \n",
      "Epoch:  47\n",
      "73/361.0 loss: 0.6978805379287617 \n",
      "Epoch:  47\n",
      "74/361.0 loss: 0.6970774499575297 \n",
      "Epoch:  47\n",
      "75/361.0 loss: 0.6976583686314131 \n",
      "Epoch:  47\n",
      "76/361.0 loss: 0.6987843165149936 \n",
      "Epoch:  47\n",
      "77/361.0 loss: 0.6973909934361776 \n",
      "Epoch:  47\n",
      "78/361.0 loss: 0.6985672516158864 \n",
      "Epoch:  47\n",
      "79/361.0 loss: 0.6990082196891307 \n",
      "Epoch:  47\n",
      "80/361.0 loss: 0.698177977108661 \n",
      "Epoch:  47\n",
      "81/361.0 loss: 0.6978501343145603 \n",
      "Epoch:  47\n",
      "82/361.0 loss: 0.6975949456892818 \n",
      "Epoch:  47\n",
      "83/361.0 loss: 0.6983156140361514 \n",
      "Epoch:  47\n",
      "84/361.0 loss: 0.6995293547125424 \n",
      "Epoch:  47\n",
      "85/361.0 loss: 0.7004660458065742 \n",
      "Epoch:  47\n",
      "86/361.0 loss: 0.6995596111505881 \n",
      "Epoch:  47\n",
      "87/361.0 loss: 0.6986553066156127 \n",
      "Epoch:  47\n",
      "88/361.0 loss: 0.697683700684751 \n",
      "Epoch:  47\n",
      "89/361.0 loss: 0.6966206822130415 \n",
      "Epoch:  47\n",
      "90/361.0 loss: 0.6976687895072685 \n",
      "Epoch:  47\n",
      "91/361.0 loss: 0.6964748566565306 \n",
      "Epoch:  47\n",
      "92/361.0 loss: 0.6958796119177213 \n",
      "Epoch:  47\n",
      "93/361.0 loss: 0.696614220421365 \n",
      "Epoch:  47\n",
      "94/361.0 loss: 0.6967806113393683 \n",
      "Epoch:  47\n",
      "95/361.0 loss: 0.695427693426609 \n",
      "Epoch:  47\n",
      "96/361.0 loss: 0.6963091590969833 \n",
      "Epoch:  47\n",
      "97/361.0 loss: 0.6948532231000005 \n",
      "Epoch:  47\n",
      "98/361.0 loss: 0.6938401033179928 \n",
      "Epoch:  47\n",
      "99/361.0 loss: 0.6947524470090866 \n",
      "Epoch:  47\n",
      "100/361.0 loss: 0.6940883964595228 \n",
      "Epoch:  47\n",
      "101/361.0 loss: 0.6958786605619917 \n",
      "Epoch:  47\n",
      "102/361.0 loss: 0.695830397814223 \n",
      "Epoch:  47\n",
      "103/361.0 loss: 0.6952219124023731 \n",
      "Epoch:  47\n",
      "104/361.0 loss: 0.694828166280474 \n",
      "Epoch:  47\n",
      "105/361.0 loss: 0.6941114253592942 \n",
      "Epoch:  47\n",
      "106/361.0 loss: 0.6936027936846296 \n",
      "Epoch:  47\n",
      "107/361.0 loss: 0.6941637054637626 \n",
      "Epoch:  47\n",
      "108/361.0 loss: 0.694844766494331 \n",
      "Epoch:  47\n",
      "109/361.0 loss: 0.6941560994495045 \n",
      "Epoch:  47\n",
      "110/361.0 loss: 0.694363822271158 \n",
      "Epoch:  47\n",
      "111/361.0 loss: 0.6949469473745141 \n",
      "Epoch:  47\n",
      "112/361.0 loss: 0.6955172920649031 \n",
      "Epoch:  47\n",
      "113/361.0 loss: 0.6951720834824077 \n",
      "Epoch:  47\n",
      "114/361.0 loss: 0.6957131624221802 \n",
      "Epoch:  47\n",
      "115/361.0 loss: 0.695635039744706 \n",
      "Epoch:  47\n",
      "116/361.0 loss: 0.6949643074956715 \n",
      "Epoch:  47\n",
      "117/361.0 loss: 0.6938129016908549 \n",
      "Epoch:  47\n",
      "118/361.0 loss: 0.6946699108396258 \n",
      "Epoch:  47\n",
      "119/361.0 loss: 0.6952832301457723 \n",
      "Epoch:  47\n",
      "120/361.0 loss: 0.6947676982761415 \n",
      "Epoch:  47\n",
      "121/361.0 loss: 0.6954960422437699 \n",
      "Epoch:  47\n",
      "122/361.0 loss: 0.6961613118163938 \n",
      "Epoch:  47\n",
      "123/361.0 loss: 0.6956352264650406 \n",
      "Epoch:  47\n",
      "124/361.0 loss: 0.6963976941108704 \n",
      "Epoch:  47\n",
      "125/361.0 loss: 0.6958527002069685 \n",
      "Epoch:  47\n",
      "126/361.0 loss: 0.6956652515516506 \n",
      "Epoch:  47\n",
      "127/361.0 loss: 0.6961031747050583 \n",
      "Epoch:  47\n",
      "128/361.0 loss: 0.6957849259524382 \n",
      "Epoch:  47\n",
      "129/361.0 loss: 0.695422922189419 \n",
      "Epoch:  47\n",
      "130/361.0 loss: 0.6947925523037218 \n",
      "Epoch:  47\n",
      "131/361.0 loss: 0.6941278296889681 \n",
      "Epoch:  47\n",
      "132/361.0 loss: 0.6944793198341713 \n",
      "Epoch:  47\n",
      "133/361.0 loss: 0.6948137376735459 \n",
      "Epoch:  47\n",
      "134/361.0 loss: 0.6955495882917333 \n",
      "Epoch:  47\n",
      "135/361.0 loss: 0.6965321525931358 \n",
      "Epoch:  47\n",
      "136/361.0 loss: 0.6970203479711157 \n",
      "Epoch:  47\n",
      "137/361.0 loss: 0.6977419887763866 \n",
      "Epoch:  47\n",
      "138/361.0 loss: 0.697150513422575 \n",
      "Epoch:  47\n",
      "139/361.0 loss: 0.696458488702774 \n",
      "Epoch:  47\n",
      "140/361.0 loss: 0.6959951236738381 \n",
      "Epoch:  47\n",
      "141/361.0 loss: 0.6954465185252714 \n",
      "Epoch:  47\n",
      "142/361.0 loss: 0.6957913887250674 \n",
      "Epoch:  47\n",
      "143/361.0 loss: 0.695799295273092 \n",
      "Epoch:  47\n",
      "144/361.0 loss: 0.6949643233726764 \n",
      "Epoch:  47\n",
      "145/361.0 loss: 0.6955188394409336 \n",
      "Epoch:  47\n",
      "146/361.0 loss: 0.6950123338472276 \n",
      "Epoch:  47\n",
      "147/361.0 loss: 0.6947568840271717 \n",
      "Epoch:  47\n",
      "148/361.0 loss: 0.6947534748371815 \n",
      "Epoch:  47\n",
      "149/361.0 loss: 0.6950035707155864 \n",
      "Epoch:  47\n",
      "150/361.0 loss: 0.6957070756432236 \n",
      "Epoch:  47\n",
      "151/361.0 loss: 0.695910987493239 \n",
      "Epoch:  47\n",
      "152/361.0 loss: 0.6957319086673213 \n",
      "Epoch:  47\n",
      "153/361.0 loss: 0.6953251888225604 \n",
      "Epoch:  47\n",
      "154/361.0 loss: 0.6953899998818674 \n",
      "Epoch:  47\n",
      "155/361.0 loss: 0.6959382249758794 \n",
      "Epoch:  47\n",
      "156/361.0 loss: 0.6962337474914113 \n",
      "Epoch:  47\n",
      "157/361.0 loss: 0.6964512161816223 \n",
      "Epoch:  47\n",
      "158/361.0 loss: 0.6961762781413097 \n",
      "Epoch:  47\n",
      "159/361.0 loss: 0.695636386051774 \n",
      "Epoch:  47\n",
      "160/361.0 loss: 0.6961644776859639 \n",
      "Epoch:  47\n",
      "161/361.0 loss: 0.696399720730605 \n",
      "Epoch:  47\n",
      "162/361.0 loss: 0.6961990514415904 \n",
      "Epoch:  47\n",
      "163/361.0 loss: 0.6970211100287553 \n",
      "Epoch:  47\n",
      "164/361.0 loss: 0.6976520798423074 \n",
      "Epoch:  47\n",
      "165/361.0 loss: 0.6980263673397432 \n",
      "Epoch:  47\n",
      "166/361.0 loss: 0.6978842926596454 \n",
      "Epoch:  47\n",
      "167/361.0 loss: 0.6973219112980933 \n",
      "Epoch:  47\n",
      "168/361.0 loss: 0.6972690570283924 \n",
      "Epoch:  47\n",
      "169/361.0 loss: 0.6976451302275938 \n",
      "Epoch:  47\n",
      "170/361.0 loss: 0.6972835203360396 \n",
      "Epoch:  47\n",
      "171/361.0 loss: 0.6972922755535259 \n",
      "Epoch:  47\n",
      "172/361.0 loss: 0.6981519384880286 \n",
      "Epoch:  47\n",
      "173/361.0 loss: 0.6982445257833634 \n",
      "Epoch:  47\n",
      "174/361.0 loss: 0.6984843955721174 \n",
      "Epoch:  47\n",
      "175/361.0 loss: 0.6983306851576675 \n",
      "Epoch:  47\n",
      "176/361.0 loss: 0.698301096757253 \n",
      "Epoch:  47\n",
      "177/361.0 loss: 0.6978473402141185 \n",
      "Epoch:  47\n",
      "178/361.0 loss: 0.6981940182893636 \n",
      "Epoch:  47\n",
      "179/361.0 loss: 0.6977726280689239 \n",
      "Epoch:  47\n",
      "180/361.0 loss: 0.6972782052024293 \n",
      "Epoch:  47\n",
      "181/361.0 loss: 0.6972075288112347 \n",
      "Epoch:  47\n",
      "182/361.0 loss: 0.6975375068643705 \n",
      "Epoch:  47\n",
      "183/361.0 loss: 0.6970515238202136 \n",
      "Epoch:  47\n",
      "184/361.0 loss: 0.6973322314185065 \n",
      "Epoch:  47\n",
      "185/361.0 loss: 0.697563709110342 \n",
      "Epoch:  47\n",
      "186/361.0 loss: 0.697642917620307 \n",
      "Epoch:  47\n",
      "187/361.0 loss: 0.6978577575150956 \n",
      "Epoch:  47\n",
      "188/361.0 loss: 0.6978473890395391 \n",
      "Epoch:  47\n",
      "189/361.0 loss: 0.6976847949780915 \n",
      "Epoch:  47\n",
      "190/361.0 loss: 0.6978041217589254 \n",
      "Epoch:  47\n",
      "191/361.0 loss: 0.6978707437713941 \n",
      "Epoch:  47\n",
      "192/361.0 loss: 0.697811752094506 \n",
      "Epoch:  47\n",
      "193/361.0 loss: 0.697750196014483 \n",
      "Epoch:  47\n",
      "194/361.0 loss: 0.6977267754383576 \n",
      "Epoch:  47\n",
      "195/361.0 loss: 0.697960090576386 \n",
      "Epoch:  47\n",
      "196/361.0 loss: 0.6979687676817028 \n",
      "Epoch:  47\n",
      "197/361.0 loss: 0.6977700512818615 \n",
      "Epoch:  47\n",
      "198/361.0 loss: 0.6974877703129946 \n",
      "Epoch:  47\n",
      "199/361.0 loss: 0.6978754678368568 \n",
      "Epoch:  47\n",
      "200/361.0 loss: 0.6980463468020235 \n",
      "Epoch:  47\n",
      "201/361.0 loss: 0.6978002169934829 \n",
      "Epoch:  47\n",
      "202/361.0 loss: 0.6976983209548913 \n",
      "Epoch:  47\n",
      "203/361.0 loss: 0.6975476353191862 \n",
      "Epoch:  47\n",
      "204/361.0 loss: 0.6974281659940395 \n",
      "Epoch:  47\n",
      "205/361.0 loss: 0.6975602759319601 \n",
      "Epoch:  47\n",
      "206/361.0 loss: 0.697471002737681 \n",
      "Epoch:  47\n",
      "207/361.0 loss: 0.6976416781544685 \n",
      "Epoch:  47\n",
      "208/361.0 loss: 0.6975645776570699 \n",
      "Epoch:  47\n",
      "209/361.0 loss: 0.6978055584998358 \n",
      "Epoch:  47\n",
      "210/361.0 loss: 0.6980571012361355 \n",
      "Epoch:  47\n",
      "211/361.0 loss: 0.6981272073286884 \n",
      "Epoch:  47\n",
      "212/361.0 loss: 0.6979207203421794 \n",
      "Epoch:  47\n",
      "213/361.0 loss: 0.697749404985214 \n",
      "Epoch:  47\n",
      "214/361.0 loss: 0.6978943824768067 \n",
      "Epoch:  47\n",
      "215/361.0 loss: 0.6975209166606268 \n",
      "Epoch:  47\n",
      "216/361.0 loss: 0.6973628563814999 \n",
      "Epoch:  47\n",
      "217/361.0 loss: 0.6976092435898037 \n",
      "Epoch:  47\n",
      "218/361.0 loss: 0.6975328750806312 \n",
      "Epoch:  47\n",
      "219/361.0 loss: 0.6974448038773103 \n",
      "Epoch:  47\n",
      "220/361.0 loss: 0.6971858961010411 \n",
      "Epoch:  47\n",
      "221/361.0 loss: 0.6976667798317231 \n",
      "Epoch:  47\n",
      "222/361.0 loss: 0.697463318371452 \n",
      "Epoch:  47\n",
      "223/361.0 loss: 0.697360767849854 \n",
      "Epoch:  47\n",
      "224/361.0 loss: 0.6978285474247402 \n",
      "Epoch:  47\n",
      "225/361.0 loss: 0.6983012868239816 \n",
      "Epoch:  47\n",
      "226/361.0 loss: 0.6982006236320025 \n",
      "Epoch:  47\n",
      "227/361.0 loss: 0.6980285851056116 \n",
      "Epoch:  47\n",
      "228/361.0 loss: 0.6978544564226309 \n",
      "Epoch:  47\n",
      "229/361.0 loss: 0.6975951671600342 \n",
      "Epoch:  47\n",
      "230/361.0 loss: 0.6974217473686516 \n",
      "Epoch:  47\n",
      "231/361.0 loss: 0.697366028510291 \n",
      "Epoch:  47\n",
      "232/361.0 loss: 0.6977051025808113 \n",
      "Epoch:  47\n",
      "233/361.0 loss: 0.6975374336426075 \n",
      "Epoch:  47\n",
      "234/361.0 loss: 0.697637000743379 \n",
      "Epoch:  47\n",
      "235/361.0 loss: 0.6972702537047661 \n",
      "Epoch:  47\n",
      "236/361.0 loss: 0.6971279241867709 \n",
      "Epoch:  47\n",
      "237/361.0 loss: 0.6970805891421663 \n",
      "Epoch:  47\n",
      "238/361.0 loss: 0.6969012024512351 \n",
      "Epoch:  47\n",
      "239/361.0 loss: 0.6965556564430396 \n",
      "Epoch:  47\n",
      "240/361.0 loss: 0.6963247743384967 \n",
      "Epoch:  47\n",
      "241/361.0 loss: 0.696737692868414 \n",
      "Epoch:  47\n",
      "242/361.0 loss: 0.6964289626957457 \n",
      "Epoch:  47\n",
      "243/361.0 loss: 0.6967670248180139 \n",
      "Epoch:  47\n",
      "244/361.0 loss: 0.6970107903285903 \n",
      "Epoch:  47\n",
      "245/361.0 loss: 0.6970921451967906 \n",
      "Epoch:  47\n",
      "246/361.0 loss: 0.6966223475421488 \n",
      "Epoch:  47\n",
      "247/361.0 loss: 0.6970241886954154 \n",
      "Epoch:  47\n",
      "248/361.0 loss: 0.6972941495328543 \n",
      "Epoch:  47\n",
      "249/361.0 loss: 0.697592844247818 \n",
      "Epoch:  47\n",
      "250/361.0 loss: 0.6980023680930119 \n",
      "Epoch:  47\n",
      "251/361.0 loss: 0.6976689677389841 \n",
      "Epoch:  47\n",
      "252/361.0 loss: 0.6972900299215505 \n",
      "Epoch:  47\n",
      "253/361.0 loss: 0.6969007584523028 \n",
      "Epoch:  47\n",
      "254/361.0 loss: 0.696571549948524 \n",
      "Epoch:  47\n",
      "255/361.0 loss: 0.6963136177510023 \n",
      "Epoch:  47\n",
      "256/361.0 loss: 0.6964621636654152 \n",
      "Epoch:  47\n",
      "257/361.0 loss: 0.6961104042770326 \n",
      "Epoch:  47\n",
      "258/361.0 loss: 0.6964205116839022 \n",
      "Epoch:  47\n",
      "259/361.0 loss: 0.6961400169592638 \n",
      "Epoch:  47\n",
      "260/361.0 loss: 0.6964513339758833 \n",
      "Epoch:  47\n",
      "261/361.0 loss: 0.6962001250900385 \n",
      "Epoch:  47\n",
      "262/361.0 loss: 0.6959361939375844 \n",
      "Epoch:  47\n",
      "263/361.0 loss: 0.6961664458115896 \n",
      "Epoch:  47\n",
      "264/361.0 loss: 0.6960009968505716 \n",
      "Epoch:  47\n",
      "265/361.0 loss: 0.6962469567481736 \n",
      "Epoch:  47\n",
      "266/361.0 loss: 0.6958706441443511 \n",
      "Epoch:  47\n",
      "267/361.0 loss: 0.6964335784093657 \n",
      "Epoch:  47\n",
      "268/361.0 loss: 0.6962081105292508 \n",
      "Epoch:  47\n",
      "269/361.0 loss: 0.6959379222657945 \n",
      "Epoch:  47\n",
      "270/361.0 loss: 0.6957033397526758 \n",
      "Epoch:  47\n",
      "271/361.0 loss: 0.6953265594647211 \n",
      "Epoch:  47\n",
      "272/361.0 loss: 0.6950170201259654 \n",
      "Epoch:  47\n",
      "273/361.0 loss: 0.6954053283607873 \n",
      "Epoch:  47\n",
      "274/361.0 loss: 0.6955305912277915 \n",
      "Epoch:  47\n",
      "275/361.0 loss: 0.6956915356542753 \n",
      "Epoch:  47\n",
      "276/361.0 loss: 0.6958847159943425 \n",
      "Epoch:  47\n",
      "277/361.0 loss: 0.6963399571480511 \n",
      "Epoch:  47\n",
      "278/361.0 loss: 0.6965839871368955 \n",
      "Epoch:  47\n",
      "279/361.0 loss: 0.6971779721123832 \n",
      "Epoch:  47\n",
      "280/361.0 loss: 0.6974259589490517 \n",
      "Epoch:  47\n",
      "281/361.0 loss: 0.6976725993849707 \n",
      "Epoch:  47\n",
      "282/361.0 loss: 0.6978958781953414 \n",
      "Epoch:  47\n",
      "283/361.0 loss: 0.6977128015017845 \n",
      "Epoch:  47\n",
      "284/361.0 loss: 0.697475650854278 \n",
      "Epoch:  47\n",
      "285/361.0 loss: 0.6974594140803063 \n",
      "Epoch:  47\n",
      "286/361.0 loss: 0.6970126873940126 \n",
      "Epoch:  47\n",
      "287/361.0 loss: 0.6967630055215623 \n",
      "Epoch:  47\n",
      "288/361.0 loss: 0.6967300844852488 \n",
      "Epoch:  47\n",
      "289/361.0 loss: 0.6971204196584636 \n",
      "Epoch:  47\n",
      "290/361.0 loss: 0.6969094266186875 \n",
      "Epoch:  47\n",
      "291/361.0 loss: 0.6970096442797412 \n",
      "Epoch:  47\n",
      "292/361.0 loss: 0.6968549156351708 \n",
      "Epoch:  47\n",
      "293/361.0 loss: 0.6966320616858346 \n",
      "Epoch:  47\n",
      "294/361.0 loss: 0.6967379889245761 \n",
      "Epoch:  47\n",
      "295/361.0 loss: 0.6962873458459571 \n",
      "Epoch:  47\n",
      "296/361.0 loss: 0.6965855705216276 \n",
      "Epoch:  47\n",
      "297/361.0 loss: 0.6963729042334844 \n",
      "Epoch:  47\n",
      "298/361.0 loss: 0.6961992464735356 \n",
      "Epoch:  47\n",
      "299/361.0 loss: 0.6960490580399831 \n",
      "Epoch:  47\n",
      "300/361.0 loss: 0.6957193682360094 \n",
      "Epoch:  47\n",
      "301/361.0 loss: 0.6954578376368971 \n",
      "Epoch:  47\n",
      "302/361.0 loss: 0.6951016529951946 \n",
      "Epoch:  47\n",
      "303/361.0 loss: 0.6954506457244095 \n",
      "Epoch:  47\n",
      "304/361.0 loss: 0.6952708467108304 \n",
      "Epoch:  47\n",
      "305/361.0 loss: 0.6953621107378817 \n",
      "Epoch:  47\n",
      "306/361.0 loss: 0.695121727277091 \n",
      "Epoch:  47\n",
      "307/361.0 loss: 0.6954058352615926 \n",
      "Epoch:  47\n",
      "308/361.0 loss: 0.6955104896551583 \n",
      "Epoch:  47\n",
      "309/361.0 loss: 0.6951958323678663 \n",
      "Epoch:  47\n",
      "310/361.0 loss: 0.695625302492614 \n",
      "Epoch:  47\n",
      "311/361.0 loss: 0.6958227619910852 \n",
      "Epoch:  47\n",
      "312/361.0 loss: 0.6955696203457281 \n",
      "Epoch:  47\n",
      "313/361.0 loss: 0.6959881192180002 \n",
      "Epoch:  47\n",
      "314/361.0 loss: 0.6963063363044981 \n",
      "Epoch:  47\n",
      "315/361.0 loss: 0.6966904703574844 \n",
      "Epoch:  47\n",
      "316/361.0 loss: 0.6968782942753861 \n",
      "Epoch:  47\n",
      "317/361.0 loss: 0.6970326109502301 \n",
      "Epoch:  47\n",
      "318/361.0 loss: 0.6969475181872569 \n",
      "Epoch:  47\n",
      "319/361.0 loss: 0.6972091570496559 \n",
      "Epoch:  47\n",
      "320/361.0 loss: 0.6971001701191578 \n",
      "Epoch:  47\n",
      "321/361.0 loss: 0.6974209626639112 \n",
      "Epoch:  47\n",
      "322/361.0 loss: 0.6972695201543093 \n",
      "Epoch:  47\n",
      "323/361.0 loss: 0.6970796189558359 \n",
      "Epoch:  47\n",
      "324/361.0 loss: 0.6972223019599915 \n",
      "Epoch:  47\n",
      "325/361.0 loss: 0.6974799139368022 \n",
      "Epoch:  47\n",
      "326/361.0 loss: 0.697650242289272 \n",
      "Epoch:  47\n",
      "327/361.0 loss: 0.6979031181190072 \n",
      "Epoch:  47\n",
      "328/361.0 loss: 0.6975074026359975 \n",
      "Epoch:  47\n",
      "329/361.0 loss: 0.697280501054995 \n",
      "Epoch:  47\n",
      "330/361.0 loss: 0.6973505828675907 \n",
      "Epoch:  47\n",
      "331/361.0 loss: 0.6973812750664102 \n",
      "Epoch:  47\n",
      "332/361.0 loss: 0.6971626809767416 \n",
      "Epoch:  47\n",
      "333/361.0 loss: 0.6974954456983212 \n",
      "Epoch:  47\n",
      "334/361.0 loss: 0.6973018708513744 \n",
      "Epoch:  47\n",
      "335/361.0 loss: 0.6972059744099776 \n",
      "Epoch:  47\n",
      "336/361.0 loss: 0.6971146533326509 \n",
      "Epoch:  47\n",
      "337/361.0 loss: 0.6970730658466294 \n",
      "Epoch:  47\n",
      "338/361.0 loss: 0.6973577563741565 \n",
      "Epoch:  47\n",
      "339/361.0 loss: 0.6971175411168267 \n",
      "Epoch:  47\n",
      "340/361.0 loss: 0.6970857654498819 \n",
      "Epoch:  47\n",
      "341/361.0 loss: 0.6971995393086595 \n",
      "Epoch:  47\n",
      "342/361.0 loss: 0.6971690974499671 \n",
      "Epoch:  47\n",
      "343/361.0 loss: 0.6972230414665023 \n",
      "Epoch:  47\n",
      "344/361.0 loss: 0.6972530268240666 \n",
      "Epoch:  47\n",
      "345/361.0 loss: 0.6971647219161767 \n",
      "Epoch:  47\n",
      "346/361.0 loss: 0.697336922976744 \n",
      "Epoch:  47\n",
      "347/361.0 loss: 0.6971547735491018 \n",
      "Epoch:  47\n",
      "348/361.0 loss: 0.6973573562067354 \n",
      "Epoch:  47\n",
      "349/361.0 loss: 0.6971354837077005 \n",
      "Epoch:  47\n",
      "350/361.0 loss: 0.6973396536291834 \n",
      "Epoch:  47\n",
      "351/361.0 loss: 0.6971210979602553 \n",
      "Epoch:  47\n",
      "352/361.0 loss: 0.697220198324652 \n",
      "Epoch:  47\n",
      "353/361.0 loss: 0.6970738574946668 \n",
      "Epoch:  47\n",
      "354/361.0 loss: 0.6969428708855535 \n",
      "Epoch:  47\n",
      "355/361.0 loss: 0.6971778164753754 \n",
      "Epoch:  47\n",
      "356/361.0 loss: 0.6973695758344078 \n",
      "Epoch:  47\n",
      "357/361.0 loss: 0.6971541936171122 \n",
      "Epoch:  47\n",
      "358/361.0 loss: 0.6971870194238541 \n",
      "Epoch:  47\n",
      "359/361.0 loss: 0.6969372403290537 \n",
      "Epoch:  47\n",
      "360/361.0 loss: 0.6968301909451999 \n",
      "Epoch:  48\n",
      "0/361.0 loss: 0.7492775917053223 \n",
      "Epoch:  48\n",
      "1/361.0 loss: 0.739921361207962 \n",
      "Epoch:  48\n",
      "2/361.0 loss: 0.7420865098635355 \n",
      "Epoch:  48\n",
      "3/361.0 loss: 0.7282130718231201 \n",
      "Epoch:  48\n",
      "4/361.0 loss: 0.7064673781394959 \n",
      "Epoch:  48\n",
      "5/361.0 loss: 0.7096692025661469 \n",
      "Epoch:  48\n",
      "6/361.0 loss: 0.7009701388222831 \n",
      "Epoch:  48\n",
      "7/361.0 loss: 0.6932418271899223 \n",
      "Epoch:  48\n",
      "8/361.0 loss: 0.6980541149775187 \n",
      "Epoch:  48\n",
      "9/361.0 loss: 0.6955886065959931 \n",
      "Epoch:  48\n",
      "10/361.0 loss: 0.691431078043851 \n",
      "Epoch:  48\n",
      "11/361.0 loss: 0.68785693248113 \n",
      "Epoch:  48\n",
      "12/361.0 loss: 0.6865288110879751 \n",
      "Epoch:  48\n",
      "13/361.0 loss: 0.6905296402318137 \n",
      "Epoch:  48\n",
      "14/361.0 loss: 0.6859067559242249 \n",
      "Epoch:  48\n",
      "15/361.0 loss: 0.6810863949358463 \n",
      "Epoch:  48\n",
      "16/361.0 loss: 0.6782774995355045 \n",
      "Epoch:  48\n",
      "17/361.0 loss: 0.6788683036963145 \n",
      "Epoch:  48\n",
      "18/361.0 loss: 0.6778139221040826 \n",
      "Epoch:  48\n",
      "19/361.0 loss: 0.6806620806455612 \n",
      "Epoch:  48\n",
      "20/361.0 loss: 0.6848263910838536 \n",
      "Epoch:  48\n",
      "21/361.0 loss: 0.6824840740724043 \n",
      "Epoch:  48\n",
      "22/361.0 loss: 0.6827268108077671 \n",
      "Epoch:  48\n",
      "23/361.0 loss: 0.6793351943294207 \n",
      "Epoch:  48\n",
      "24/361.0 loss: 0.676912567615509 \n",
      "Epoch:  48\n",
      "25/361.0 loss: 0.6764852610918192 \n",
      "Epoch:  48\n",
      "26/361.0 loss: 0.6734396197177746 \n",
      "Epoch:  48\n",
      "27/361.0 loss: 0.6778454269681659 \n",
      "Epoch:  48\n",
      "28/361.0 loss: 0.6797253448387672 \n",
      "Epoch:  48\n",
      "29/361.0 loss: 0.6808296819527944 \n",
      "Epoch:  48\n",
      "30/361.0 loss: 0.6827450625358089 \n",
      "Epoch:  48\n",
      "31/361.0 loss: 0.6857912130653858 \n",
      "Epoch:  48\n",
      "32/361.0 loss: 0.6836882125247609 \n",
      "Epoch:  48\n",
      "33/361.0 loss: 0.6846503019332886 \n",
      "Epoch:  48\n",
      "34/361.0 loss: 0.683246920789991 \n",
      "Epoch:  48\n",
      "35/361.0 loss: 0.6830907828278012 \n",
      "Epoch:  48\n",
      "36/361.0 loss: 0.6815076953655964 \n",
      "Epoch:  48\n",
      "37/361.0 loss: 0.6829192638397217 \n",
      "Epoch:  48\n",
      "38/361.0 loss: 0.6853498373276148 \n",
      "Epoch:  48\n",
      "39/361.0 loss: 0.6862133145332336 \n",
      "Epoch:  48\n",
      "40/361.0 loss: 0.6883132981091011 \n",
      "Epoch:  48\n",
      "41/361.0 loss: 0.6862904401052565 \n",
      "Epoch:  48\n",
      "42/361.0 loss: 0.687301589999088 \n",
      "Epoch:  48\n",
      "43/361.0 loss: 0.6876035007563505 \n",
      "Epoch:  48\n",
      "44/361.0 loss: 0.6884017030398051 \n",
      "Epoch:  48\n",
      "45/361.0 loss: 0.6893222008062445 \n",
      "Epoch:  48\n",
      "46/361.0 loss: 0.68949955701828 \n",
      "Epoch:  48\n",
      "47/361.0 loss: 0.688681727896134 \n",
      "Epoch:  48\n",
      "48/361.0 loss: 0.6887202202057352 \n",
      "Epoch:  48\n",
      "49/361.0 loss: 0.688800231218338 \n",
      "Epoch:  48\n",
      "50/361.0 loss: 0.6880357464154562 \n",
      "Epoch:  48\n",
      "51/361.0 loss: 0.6888482456023877 \n",
      "Epoch:  48\n",
      "52/361.0 loss: 0.6895215511322021 \n",
      "Epoch:  48\n",
      "53/361.0 loss: 0.6904379405357219 \n",
      "Epoch:  48\n",
      "54/361.0 loss: 0.6896986484527587 \n",
      "Epoch:  48\n",
      "55/361.0 loss: 0.6893758337412562 \n",
      "Epoch:  48\n",
      "56/361.0 loss: 0.6888317612179539 \n",
      "Epoch:  48\n",
      "57/361.0 loss: 0.68821189218554 \n",
      "Epoch:  48\n",
      "58/361.0 loss: 0.6883527858782623 \n",
      "Epoch:  48\n",
      "59/361.0 loss: 0.6890055209398269 \n",
      "Epoch:  48\n",
      "60/361.0 loss: 0.6891008791376333 \n",
      "Epoch:  48\n",
      "61/361.0 loss: 0.6882346512809876 \n",
      "Epoch:  48\n",
      "62/361.0 loss: 0.687669851477184 \n",
      "Epoch:  48\n",
      "63/361.0 loss: 0.6884546494111419 \n",
      "Epoch:  48\n",
      "64/361.0 loss: 0.6900777789262625 \n",
      "Epoch:  48\n",
      "65/361.0 loss: 0.690723512208823 \n",
      "Epoch:  48\n",
      "66/361.0 loss: 0.6905091342641346 \n",
      "Epoch:  48\n",
      "67/361.0 loss: 0.6898850272683537 \n",
      "Epoch:  48\n",
      "68/361.0 loss: 0.6910950161408687 \n",
      "Epoch:  48\n",
      "69/361.0 loss: 0.692131450346538 \n",
      "Epoch:  48\n",
      "70/361.0 loss: 0.692864587609197 \n",
      "Epoch:  48\n",
      "71/361.0 loss: 0.6923326096600957 \n",
      "Epoch:  48\n",
      "72/361.0 loss: 0.6914397061687626 \n",
      "Epoch:  48\n",
      "73/361.0 loss: 0.6906546144872099 \n",
      "Epoch:  48\n",
      "74/361.0 loss: 0.6908917133013407 \n",
      "Epoch:  48\n",
      "75/361.0 loss: 0.6919629518923006 \n",
      "Epoch:  48\n",
      "76/361.0 loss: 0.6914277665026776 \n",
      "Epoch:  48\n",
      "77/361.0 loss: 0.6910249033035376 \n",
      "Epoch:  48\n",
      "78/361.0 loss: 0.690332535701462 \n",
      "Epoch:  48\n",
      "79/361.0 loss: 0.6907542951405048 \n",
      "Epoch:  48\n",
      "80/361.0 loss: 0.6905374806604268 \n",
      "Epoch:  48\n",
      "81/361.0 loss: 0.6911116947488087 \n",
      "Epoch:  48\n",
      "82/361.0 loss: 0.6915898330240364 \n",
      "Epoch:  48\n",
      "83/361.0 loss: 0.6921396227109999 \n",
      "Epoch:  48\n",
      "84/361.0 loss: 0.6913782161824843 \n",
      "Epoch:  48\n",
      "85/361.0 loss: 0.6908579288527023 \n",
      "Epoch:  48\n",
      "86/361.0 loss: 0.6909551346439055 \n",
      "Epoch:  48\n",
      "87/361.0 loss: 0.691271382976662 \n",
      "Epoch:  48\n",
      "88/361.0 loss: 0.6913941562845466 \n",
      "Epoch:  48\n",
      "89/361.0 loss: 0.6908973389201694 \n",
      "Epoch:  48\n",
      "90/361.0 loss: 0.6912468003702688 \n",
      "Epoch:  48\n",
      "91/361.0 loss: 0.6911200770865316 \n",
      "Epoch:  48\n",
      "92/361.0 loss: 0.6908985837813346 \n",
      "Epoch:  48\n",
      "93/361.0 loss: 0.6911321415546092 \n",
      "Epoch:  48\n",
      "94/361.0 loss: 0.6906675194439135 \n",
      "Epoch:  48\n",
      "95/361.0 loss: 0.6909798098107179 \n",
      "Epoch:  48\n",
      "96/361.0 loss: 0.6912315020856169 \n",
      "Epoch:  48\n",
      "97/361.0 loss: 0.6915724374810044 \n",
      "Epoch:  48\n",
      "98/361.0 loss: 0.6908573737048139 \n",
      "Epoch:  48\n",
      "99/361.0 loss: 0.6914471220970154 \n",
      "Epoch:  48\n",
      "100/361.0 loss: 0.6917338347671056 \n",
      "Epoch:  48\n",
      "101/361.0 loss: 0.6916191092893189 \n",
      "Epoch:  48\n",
      "102/361.0 loss: 0.6912629372865251 \n",
      "Epoch:  48\n",
      "103/361.0 loss: 0.6909706271611727 \n",
      "Epoch:  48\n",
      "104/361.0 loss: 0.6909447346414839 \n",
      "Epoch:  48\n",
      "105/361.0 loss: 0.6908517699196653 \n",
      "Epoch:  48\n",
      "106/361.0 loss: 0.6912674385810567 \n",
      "Epoch:  48\n",
      "107/361.0 loss: 0.6912744933808291 \n",
      "Epoch:  48\n",
      "108/361.0 loss: 0.6910211148611997 \n",
      "Epoch:  48\n",
      "109/361.0 loss: 0.6904249765656211 \n",
      "Epoch:  48\n",
      "110/361.0 loss: 0.6902354697923403 \n",
      "Epoch:  48\n",
      "111/361.0 loss: 0.6902486634041581 \n",
      "Epoch:  48\n",
      "112/361.0 loss: 0.6904332168334353 \n",
      "Epoch:  48\n",
      "113/361.0 loss: 0.6901900946048268 \n",
      "Epoch:  48\n",
      "114/361.0 loss: 0.6910304846970932 \n",
      "Epoch:  48\n",
      "115/361.0 loss: 0.6905059989156395 \n",
      "Epoch:  48\n",
      "116/361.0 loss: 0.6907582456230098 \n",
      "Epoch:  48\n",
      "117/361.0 loss: 0.6909994402174222 \n",
      "Epoch:  48\n",
      "118/361.0 loss: 0.690888172939044 \n",
      "Epoch:  48\n",
      "119/361.0 loss: 0.690963423748811 \n",
      "Epoch:  48\n",
      "120/361.0 loss: 0.6909591688597498 \n",
      "Epoch:  48\n",
      "121/361.0 loss: 0.6913422346115112 \n",
      "Epoch:  48\n",
      "122/361.0 loss: 0.69112754643448 \n",
      "Epoch:  48\n",
      "123/361.0 loss: 0.6915459584805274 \n",
      "Epoch:  48\n",
      "124/361.0 loss: 0.6912943830490113 \n",
      "Epoch:  48\n",
      "125/361.0 loss: 0.6907742118078565 \n",
      "Epoch:  48\n",
      "126/361.0 loss: 0.6903672448293431 \n",
      "Epoch:  48\n",
      "127/361.0 loss: 0.6897910949774086 \n",
      "Epoch:  48\n",
      "128/361.0 loss: 0.6900250121604564 \n",
      "Epoch:  48\n",
      "129/361.0 loss: 0.689921313065749 \n",
      "Epoch:  48\n",
      "130/361.0 loss: 0.6901677765009058 \n",
      "Epoch:  48\n",
      "131/361.0 loss: 0.6900410318013394 \n",
      "Epoch:  48\n",
      "132/361.0 loss: 0.6900169903174379 \n",
      "Epoch:  48\n",
      "133/361.0 loss: 0.6896924754576896 \n",
      "Epoch:  48\n",
      "134/361.0 loss: 0.6891773020779645 \n",
      "Epoch:  48\n",
      "135/361.0 loss: 0.6887444327859318 \n",
      "Epoch:  48\n",
      "136/361.0 loss: 0.6888084894549238 \n",
      "Epoch:  48\n",
      "137/361.0 loss: 0.6890372815339462 \n",
      "Epoch:  48\n",
      "138/361.0 loss: 0.6886354050190329 \n",
      "Epoch:  48\n",
      "139/361.0 loss: 0.6885962562901633 \n",
      "Epoch:  48\n",
      "140/361.0 loss: 0.688559612061115 \n",
      "Epoch:  48\n",
      "141/361.0 loss: 0.6888086367660845 \n",
      "Epoch:  48\n",
      "142/361.0 loss: 0.689165017821572 \n",
      "Epoch:  48\n",
      "143/361.0 loss: 0.6893065451747842 \n",
      "Epoch:  48\n",
      "144/361.0 loss: 0.6893635581279624 \n",
      "Epoch:  48\n",
      "145/361.0 loss: 0.6896250574556115 \n",
      "Epoch:  48\n",
      "146/361.0 loss: 0.6895764753932044 \n",
      "Epoch:  48\n",
      "147/361.0 loss: 0.6897740295609912 \n",
      "Epoch:  48\n",
      "148/361.0 loss: 0.6895612702273682 \n",
      "Epoch:  48\n",
      "149/361.0 loss: 0.6890735514958699 \n",
      "Epoch:  48\n",
      "150/361.0 loss: 0.6890657828343625 \n",
      "Epoch:  48\n",
      "151/361.0 loss: 0.6889461871040495 \n",
      "Epoch:  48\n",
      "152/361.0 loss: 0.68894984441645 \n",
      "Epoch:  48\n",
      "153/361.0 loss: 0.6892396234846735 \n",
      "Epoch:  48\n",
      "154/361.0 loss: 0.6890786509360036 \n",
      "Epoch:  48\n",
      "155/361.0 loss: 0.6892144676202383 \n",
      "Epoch:  48\n",
      "156/361.0 loss: 0.6891123075394114 \n",
      "Epoch:  48\n",
      "157/361.0 loss: 0.6889649920071228 \n",
      "Epoch:  48\n",
      "158/361.0 loss: 0.688655323577377 \n",
      "Epoch:  48\n",
      "159/361.0 loss: 0.6887846026569605 \n",
      "Epoch:  48\n",
      "160/361.0 loss: 0.6890867941127801 \n",
      "Epoch:  48\n",
      "161/361.0 loss: 0.688996813915394 \n",
      "Epoch:  48\n",
      "162/361.0 loss: 0.6889304474818926 \n",
      "Epoch:  48\n",
      "163/361.0 loss: 0.6890540875312758 \n",
      "Epoch:  48\n",
      "164/361.0 loss: 0.6892196322932388 \n",
      "Epoch:  48\n",
      "165/361.0 loss: 0.6895620183772352 \n",
      "Epoch:  48\n",
      "166/361.0 loss: 0.68941503334902 \n",
      "Epoch:  48\n",
      "167/361.0 loss: 0.6890343676010767 \n",
      "Epoch:  48\n",
      "168/361.0 loss: 0.6891763076274353 \n",
      "Epoch:  48\n",
      "169/361.0 loss: 0.6892966954147115 \n",
      "Epoch:  48\n",
      "170/361.0 loss: 0.6895884529888978 \n",
      "Epoch:  48\n",
      "171/361.0 loss: 0.6890295639980671 \n",
      "Epoch:  48\n",
      "172/361.0 loss: 0.688762384687545 \n",
      "Epoch:  48\n",
      "173/361.0 loss: 0.6889442054704688 \n",
      "Epoch:  48\n",
      "174/361.0 loss: 0.6887561283792768 \n",
      "Epoch:  48\n",
      "175/361.0 loss: 0.6891305832700296 \n",
      "Epoch:  48\n",
      "176/361.0 loss: 0.689219797398411 \n",
      "Epoch:  48\n",
      "177/361.0 loss: 0.689145046673464 \n",
      "Epoch:  48\n",
      "178/361.0 loss: 0.6890819192598652 \n",
      "Epoch:  48\n",
      "179/361.0 loss: 0.6892137133412891 \n",
      "Epoch:  48\n",
      "180/361.0 loss: 0.6889982141183885 \n",
      "Epoch:  48\n",
      "181/361.0 loss: 0.6888571031145997 \n",
      "Epoch:  48\n",
      "182/361.0 loss: 0.6892274256612434 \n",
      "Epoch:  48\n",
      "183/361.0 loss: 0.6888655417639277 \n",
      "Epoch:  48\n",
      "184/361.0 loss: 0.6889682077072762 \n",
      "Epoch:  48\n",
      "185/361.0 loss: 0.689253185385017 \n",
      "Epoch:  48\n",
      "186/361.0 loss: 0.6891027615669577 \n",
      "Epoch:  48\n",
      "187/361.0 loss: 0.6888194172940356 \n",
      "Epoch:  48\n",
      "188/361.0 loss: 0.6887796590567896 \n",
      "Epoch:  48\n",
      "189/361.0 loss: 0.6892264510455884 \n",
      "Epoch:  48\n",
      "190/361.0 loss: 0.6894146853092453 \n",
      "Epoch:  48\n",
      "191/361.0 loss: 0.6893549831584096 \n",
      "Epoch:  48\n",
      "192/361.0 loss: 0.6896437789492039 \n",
      "Epoch:  48\n",
      "193/361.0 loss: 0.6897428118691002 \n",
      "Epoch:  48\n",
      "194/361.0 loss: 0.6899388897113311 \n",
      "Epoch:  48\n",
      "195/361.0 loss: 0.6898269671566633 \n",
      "Epoch:  48\n",
      "196/361.0 loss: 0.6896964980260974 \n",
      "Epoch:  48\n",
      "197/361.0 loss: 0.6901499710299752 \n",
      "Epoch:  48\n",
      "198/361.0 loss: 0.6899144673467281 \n",
      "Epoch:  48\n",
      "199/361.0 loss: 0.6901334077119827 \n",
      "Epoch:  48\n",
      "200/361.0 loss: 0.6899992868081847 \n",
      "Epoch:  48\n",
      "201/361.0 loss: 0.6900731673335084 \n",
      "Epoch:  48\n",
      "202/361.0 loss: 0.6900468815136426 \n",
      "Epoch:  48\n",
      "203/361.0 loss: 0.690377700270391 \n",
      "Epoch:  48\n",
      "204/361.0 loss: 0.6900125125559365 \n",
      "Epoch:  48\n",
      "205/361.0 loss: 0.689754559866433 \n",
      "Epoch:  48\n",
      "206/361.0 loss: 0.6899180573541761 \n",
      "Epoch:  48\n",
      "207/361.0 loss: 0.6904872933832499 \n",
      "Epoch:  48\n",
      "208/361.0 loss: 0.6904562905644686 \n",
      "Epoch:  48\n",
      "209/361.0 loss: 0.6905761239074525 \n",
      "Epoch:  48\n",
      "210/361.0 loss: 0.6904604632707568 \n",
      "Epoch:  48\n",
      "211/361.0 loss: 0.6902289154394617 \n",
      "Epoch:  48\n",
      "212/361.0 loss: 0.6903111887090083 \n",
      "Epoch:  48\n",
      "213/361.0 loss: 0.6904339029967228 \n",
      "Epoch:  48\n",
      "214/361.0 loss: 0.6905743693196497 \n",
      "Epoch:  48\n",
      "215/361.0 loss: 0.6906719351256335 \n",
      "Epoch:  48\n",
      "216/361.0 loss: 0.6905691870895948 \n",
      "Epoch:  48\n",
      "217/361.0 loss: 0.6908751827314359 \n",
      "Epoch:  48\n",
      "218/361.0 loss: 0.6909242895640195 \n",
      "Epoch:  48\n",
      "219/361.0 loss: 0.6910640039227226 \n",
      "Epoch:  48\n",
      "220/361.0 loss: 0.6910240302258487 \n",
      "Epoch:  48\n",
      "221/361.0 loss: 0.690985076599293 \n",
      "Epoch:  48\n",
      "222/361.0 loss: 0.6907866605194161 \n",
      "Epoch:  48\n",
      "223/361.0 loss: 0.6907606042389359 \n",
      "Epoch:  48\n",
      "224/361.0 loss: 0.6909995108180575 \n",
      "Epoch:  48\n",
      "225/361.0 loss: 0.6912044323651136 \n",
      "Epoch:  48\n",
      "226/361.0 loss: 0.6915702806695443 \n",
      "Epoch:  48\n",
      "227/361.0 loss: 0.6914478841057995 \n",
      "Epoch:  48\n",
      "228/361.0 loss: 0.6912459455202761 \n",
      "Epoch:  48\n",
      "229/361.0 loss: 0.6910477156224458 \n",
      "Epoch:  48\n",
      "230/361.0 loss: 0.690859620189254 \n",
      "Epoch:  48\n",
      "231/361.0 loss: 0.6908619018464253 \n",
      "Epoch:  48\n",
      "232/361.0 loss: 0.6910053540197053 \n",
      "Epoch:  48\n",
      "233/361.0 loss: 0.6911990930382003 \n",
      "Epoch:  48\n",
      "234/361.0 loss: 0.6914380289138632 \n",
      "Epoch:  48\n",
      "235/361.0 loss: 0.6914268136024475 \n",
      "Epoch:  48\n",
      "236/361.0 loss: 0.6914222577453163 \n",
      "Epoch:  48\n",
      "237/361.0 loss: 0.6912432921533825 \n",
      "Epoch:  48\n",
      "238/361.0 loss: 0.6913315863290093 \n",
      "Epoch:  48\n",
      "239/361.0 loss: 0.6912035750846068 \n",
      "Epoch:  48\n",
      "240/361.0 loss: 0.691280318493665 \n",
      "Epoch:  48\n",
      "241/361.0 loss: 0.6910925448433427 \n",
      "Epoch:  48\n",
      "242/361.0 loss: 0.6909223520216138 \n",
      "Epoch:  48\n",
      "243/361.0 loss: 0.691018423584641 \n",
      "Epoch:  48\n",
      "244/361.0 loss: 0.6910478981173769 \n",
      "Epoch:  48\n",
      "245/361.0 loss: 0.6909524010933512 \n",
      "Epoch:  48\n",
      "246/361.0 loss: 0.6908793601429897 \n",
      "Epoch:  48\n",
      "247/361.0 loss: 0.6908570826053619 \n",
      "Epoch:  48\n",
      "248/361.0 loss: 0.6906245290993687 \n",
      "Epoch:  48\n",
      "249/361.0 loss: 0.6904315226078034 \n",
      "Epoch:  48\n",
      "250/361.0 loss: 0.6906652913625497 \n",
      "Epoch:  48\n",
      "251/361.0 loss: 0.6907277861757884 \n",
      "Epoch:  48\n",
      "252/361.0 loss: 0.6904949171269835 \n",
      "Epoch:  48\n",
      "253/361.0 loss: 0.6901990093114808 \n",
      "Epoch:  48\n",
      "254/361.0 loss: 0.6899534978118598 \n",
      "Epoch:  48\n",
      "255/361.0 loss: 0.6899939423892647 \n",
      "Epoch:  48\n",
      "256/361.0 loss: 0.6900498922696837 \n",
      "Epoch:  48\n",
      "257/361.0 loss: 0.6900715825631637 \n",
      "Epoch:  48\n",
      "258/361.0 loss: 0.6904055347313752 \n",
      "Epoch:  48\n",
      "259/361.0 loss: 0.6903462458115358 \n",
      "Epoch:  48\n",
      "260/361.0 loss: 0.6901831485302512 \n",
      "Epoch:  48\n",
      "261/361.0 loss: 0.6903862830336768 \n",
      "Epoch:  48\n",
      "262/361.0 loss: 0.6900842747307548 \n",
      "Epoch:  48\n",
      "263/361.0 loss: 0.6899094791574911 \n",
      "Epoch:  48\n",
      "264/361.0 loss: 0.689783065723923 \n",
      "Epoch:  48\n",
      "265/361.0 loss: 0.689987665056286 \n",
      "Epoch:  48\n",
      "266/361.0 loss: 0.6899694920925612 \n",
      "Epoch:  48\n",
      "267/361.0 loss: 0.690086441698359 \n",
      "Epoch:  48\n",
      "268/361.0 loss: 0.6899709271675593 \n",
      "Epoch:  48\n",
      "269/361.0 loss: 0.6900483727455139 \n",
      "Epoch:  48\n",
      "270/361.0 loss: 0.68984565149814 \n",
      "Epoch:  48\n",
      "271/361.0 loss: 0.6899593426462483 \n",
      "Epoch:  48\n",
      "272/361.0 loss: 0.6899800466530489 \n",
      "Epoch:  48\n",
      "273/361.0 loss: 0.6899391493223009 \n",
      "Epoch:  48\n",
      "274/361.0 loss: 0.6899538618868047 \n",
      "Epoch:  48\n",
      "275/361.0 loss: 0.6897914724937384 \n",
      "Epoch:  48\n",
      "276/361.0 loss: 0.6899757299182218 \n",
      "Epoch:  48\n",
      "277/361.0 loss: 0.6899780455253107 \n",
      "Epoch:  48\n",
      "278/361.0 loss: 0.6900938913813629 \n",
      "Epoch:  48\n",
      "279/361.0 loss: 0.6898970765726907 \n",
      "Epoch:  48\n",
      "280/361.0 loss: 0.6897938007561761 \n",
      "Epoch:  48\n",
      "281/361.0 loss: 0.6900381414180107 \n",
      "Epoch:  48\n",
      "282/361.0 loss: 0.6899839220535628 \n",
      "Epoch:  48\n",
      "283/361.0 loss: 0.6898199212802968 \n",
      "Epoch:  48\n",
      "284/361.0 loss: 0.6900444823398925 \n",
      "Epoch:  48\n",
      "285/361.0 loss: 0.6899709818246481 \n",
      "Epoch:  48\n",
      "286/361.0 loss: 0.690061064962726 \n",
      "Epoch:  48\n",
      "287/361.0 loss: 0.6901390709810786 \n",
      "Epoch:  48\n",
      "288/361.0 loss: 0.6899903994118054 \n",
      "Epoch:  48\n",
      "289/361.0 loss: 0.6899292822541861 \n",
      "Epoch:  48\n",
      "290/361.0 loss: 0.6899894881494266 \n",
      "Epoch:  48\n",
      "291/361.0 loss: 0.689979929017694 \n",
      "Epoch:  48\n",
      "292/361.0 loss: 0.689738527499775 \n",
      "Epoch:  48\n",
      "293/361.0 loss: 0.6896893996365216 \n",
      "Epoch:  48\n",
      "294/361.0 loss: 0.6894008737499431 \n",
      "Epoch:  48\n",
      "295/361.0 loss: 0.6893174314015621 \n",
      "Epoch:  48\n",
      "296/361.0 loss: 0.6896109055188369 \n",
      "Epoch:  48\n",
      "297/361.0 loss: 0.6894570421052459 \n",
      "Epoch:  48\n",
      "298/361.0 loss: 0.6892216751806712 \n",
      "Epoch:  48\n",
      "299/361.0 loss: 0.6891189181804657 \n",
      "Epoch:  48\n",
      "300/361.0 loss: 0.6892653537351031 \n",
      "Epoch:  48\n",
      "301/361.0 loss: 0.689114299041546 \n",
      "Epoch:  48\n",
      "302/361.0 loss: 0.6889939455702754 \n",
      "Epoch:  48\n",
      "303/361.0 loss: 0.6891723298712781 \n",
      "Epoch:  48\n",
      "304/361.0 loss: 0.6890574711268065 \n",
      "Epoch:  48\n",
      "305/361.0 loss: 0.689105320989696 \n",
      "Epoch:  48\n",
      "306/361.0 loss: 0.6889739937425048 \n",
      "Epoch:  48\n",
      "307/361.0 loss: 0.6886558114708244 \n",
      "Epoch:  48\n",
      "308/361.0 loss: 0.6884083350499471 \n",
      "Epoch:  48\n",
      "309/361.0 loss: 0.6881858835297247 \n",
      "Epoch:  48\n",
      "310/361.0 loss: 0.6879736915278665 \n",
      "Epoch:  48\n",
      "311/361.0 loss: 0.6880299892181005 \n",
      "Epoch:  48\n",
      "312/361.0 loss: 0.6884599905044507 \n",
      "Epoch:  48\n",
      "313/361.0 loss: 0.688300702412417 \n",
      "Epoch:  48\n",
      "314/361.0 loss: 0.688536232426053 \n",
      "Epoch:  48\n",
      "315/361.0 loss: 0.6886012933299511 \n",
      "Epoch:  48\n",
      "316/361.0 loss: 0.6885818410371004 \n",
      "Epoch:  48\n",
      "317/361.0 loss: 0.688777745519794 \n",
      "Epoch:  48\n",
      "318/361.0 loss: 0.6892027174791199 \n",
      "Epoch:  48\n",
      "319/361.0 loss: 0.6893927663564682 \n",
      "Epoch:  48\n",
      "320/361.0 loss: 0.6895513237451096 \n",
      "Epoch:  48\n",
      "321/361.0 loss: 0.689809455819752 \n",
      "Epoch:  48\n",
      "322/361.0 loss: 0.6895729380864477 \n",
      "Epoch:  48\n",
      "323/361.0 loss: 0.6899059050612979 \n",
      "Epoch:  48\n",
      "324/361.0 loss: 0.6896750743572528 \n",
      "Epoch:  48\n",
      "325/361.0 loss: 0.6901269902480892 \n",
      "Epoch:  48\n",
      "326/361.0 loss: 0.6899571200029566 \n",
      "Epoch:  48\n",
      "327/361.0 loss: 0.6897746757036303 \n",
      "Epoch:  48\n",
      "328/361.0 loss: 0.6899371208753267 \n",
      "Epoch:  48\n",
      "329/361.0 loss: 0.6896302237655177 \n",
      "Epoch:  48\n",
      "330/361.0 loss: 0.689771859487378 \n",
      "Epoch:  48\n",
      "331/361.0 loss: 0.6894379947558943 \n",
      "Epoch:  48\n",
      "332/361.0 loss: 0.6892367146752618 \n",
      "Epoch:  48\n",
      "333/361.0 loss: 0.6893809245018188 \n",
      "Epoch:  48\n",
      "334/361.0 loss: 0.6891866673284502 \n",
      "Epoch:  48\n",
      "335/361.0 loss: 0.6893051468900272 \n",
      "Epoch:  48\n",
      "336/361.0 loss: 0.6892578340071953 \n",
      "Epoch:  48\n",
      "337/361.0 loss: 0.6895179307672399 \n",
      "Epoch:  48\n",
      "338/361.0 loss: 0.6896890102937862 \n",
      "Epoch:  48\n",
      "339/361.0 loss: 0.6895914791261448 \n",
      "Epoch:  48\n",
      "340/361.0 loss: 0.6897819823533559 \n",
      "Epoch:  48\n",
      "341/361.0 loss: 0.6893856926271092 \n",
      "Epoch:  48\n",
      "342/361.0 loss: 0.6895079068817829 \n",
      "Epoch:  48\n",
      "343/361.0 loss: 0.6896887653788855 \n",
      "Epoch:  48\n",
      "344/361.0 loss: 0.6894343308780504 \n",
      "Epoch:  48\n",
      "345/361.0 loss: 0.6893809299937562 \n",
      "Epoch:  48\n",
      "346/361.0 loss: 0.6892585749241392 \n",
      "Epoch:  48\n",
      "347/361.0 loss: 0.689043350432111 \n",
      "Epoch:  48\n",
      "348/361.0 loss: 0.6888405093149332 \n",
      "Epoch:  48\n",
      "349/361.0 loss: 0.6887236174515315 \n",
      "Epoch:  48\n",
      "350/361.0 loss: 0.6888659323042954 \n",
      "Epoch:  48\n",
      "351/361.0 loss: 0.6890084721486677 \n",
      "Epoch:  48\n",
      "352/361.0 loss: 0.6886746623360739 \n",
      "Epoch:  48\n",
      "353/361.0 loss: 0.688900818259029 \n",
      "Epoch:  48\n",
      "354/361.0 loss: 0.6888224381796071 \n",
      "Epoch:  48\n",
      "355/361.0 loss: 0.6887089568242598 \n",
      "Epoch:  48\n",
      "356/361.0 loss: 0.6890404120880682 \n",
      "Epoch:  48\n",
      "357/361.0 loss: 0.6888377749720099 \n",
      "Epoch:  48\n",
      "358/361.0 loss: 0.6887344312867082 \n",
      "Epoch:  48\n",
      "359/361.0 loss: 0.6888170462515619 \n",
      "Epoch:  48\n",
      "360/361.0 loss: 0.6887939633424923 \n",
      "Epoch:  49\n",
      "0/361.0 loss: 0.6402779817581177 \n",
      "Epoch:  49\n",
      "1/361.0 loss: 0.6451512575149536 \n",
      "Epoch:  49\n",
      "2/361.0 loss: 0.6757656335830688 \n",
      "Epoch:  49\n",
      "3/361.0 loss: 0.7051281780004501 \n",
      "Epoch:  49\n",
      "4/361.0 loss: 0.719458544254303 \n",
      "Epoch:  49\n",
      "5/361.0 loss: 0.739673395951589 \n",
      "Epoch:  49\n",
      "6/361.0 loss: 0.7240040983472552 \n",
      "Epoch:  49\n",
      "7/361.0 loss: 0.7387858629226685 \n",
      "Epoch:  49\n",
      "8/361.0 loss: 0.7453833156161838 \n",
      "Epoch:  49\n",
      "9/361.0 loss: 0.749243438243866 \n",
      "Epoch:  49\n",
      "10/361.0 loss: 0.7495863979512994 \n",
      "Epoch:  49\n",
      "11/361.0 loss: 0.7337318162123362 \n",
      "Epoch:  49\n",
      "12/361.0 loss: 0.7227795857649583 \n",
      "Epoch:  49\n",
      "13/361.0 loss: 0.714179447719029 \n",
      "Epoch:  49\n",
      "14/361.0 loss: 0.7176193277041117 \n",
      "Epoch:  49\n",
      "15/361.0 loss: 0.7081163562834263 \n",
      "Epoch:  49\n",
      "16/361.0 loss: 0.7058196909287396 \n",
      "Epoch:  49\n",
      "17/361.0 loss: 0.7120958401097192 \n",
      "Epoch:  49\n",
      "18/361.0 loss: 0.7075945891832051 \n",
      "Epoch:  49\n",
      "19/361.0 loss: 0.7018054604530335 \n",
      "Epoch:  49\n",
      "20/361.0 loss: 0.7062073463485354 \n",
      "Epoch:  49\n",
      "21/361.0 loss: 0.7006705863909288 \n",
      "Epoch:  49\n",
      "22/361.0 loss: 0.7047617409540259 \n",
      "Epoch:  49\n",
      "23/361.0 loss: 0.7078867306311926 \n",
      "Epoch:  49\n",
      "24/361.0 loss: 0.7039414525032044 \n",
      "Epoch:  49\n",
      "25/361.0 loss: 0.7065894626654111 \n",
      "Epoch:  49\n",
      "26/361.0 loss: 0.7071714335017734 \n",
      "Epoch:  49\n",
      "27/361.0 loss: 0.7117161005735397 \n",
      "Epoch:  49\n",
      "28/361.0 loss: 0.7075554625741367 \n",
      "Epoch:  49\n",
      "29/361.0 loss: 0.7081671953201294 \n",
      "Epoch:  49\n",
      "30/361.0 loss: 0.7035707023835951 \n",
      "Epoch:  49\n",
      "31/361.0 loss: 0.701873479411006 \n",
      "Epoch:  49\n",
      "32/361.0 loss: 0.7002332969145342 \n",
      "Epoch:  49\n",
      "33/361.0 loss: 0.698275113807005 \n",
      "Epoch:  49\n",
      "34/361.0 loss: 0.6957816345351083 \n",
      "Epoch:  49\n",
      "35/361.0 loss: 0.696155332856708 \n",
      "Epoch:  49\n",
      "36/361.0 loss: 0.6983980778101329 \n",
      "Epoch:  49\n",
      "37/361.0 loss: 0.6989239689550901 \n",
      "Epoch:  49\n",
      "38/361.0 loss: 0.6980948524597363 \n",
      "Epoch:  49\n",
      "39/361.0 loss: 0.6997727230191231 \n",
      "Epoch:  49\n",
      "40/361.0 loss: 0.7008967937492743 \n",
      "Epoch:  49\n",
      "41/361.0 loss: 0.703248625709897 \n",
      "Epoch:  49\n",
      "42/361.0 loss: 0.7029105605081071 \n",
      "Epoch:  49\n",
      "43/361.0 loss: 0.7000367492437363 \n",
      "Epoch:  49\n",
      "44/361.0 loss: 0.6989749696519639 \n",
      "Epoch:  49\n",
      "45/361.0 loss: 0.697902139114297 \n",
      "Epoch:  49\n",
      "46/361.0 loss: 0.697470153899903 \n",
      "Epoch:  49\n",
      "47/361.0 loss: 0.6996014068524042 \n",
      "Epoch:  49\n",
      "48/361.0 loss: 0.7010818075160591 \n",
      "Epoch:  49\n",
      "49/361.0 loss: 0.7023315596580505 \n",
      "Epoch:  49\n",
      "50/361.0 loss: 0.7038796579136568 \n",
      "Epoch:  49\n",
      "51/361.0 loss: 0.7059725798093356 \n",
      "Epoch:  49\n",
      "52/361.0 loss: 0.7058787975671157 \n",
      "Epoch:  49\n",
      "53/361.0 loss: 0.705662426021364 \n",
      "Epoch:  49\n",
      "54/361.0 loss: 0.7051675547253001 \n",
      "Epoch:  49\n",
      "55/361.0 loss: 0.7049251848033496 \n",
      "Epoch:  49\n",
      "56/361.0 loss: 0.7037183746956942 \n",
      "Epoch:  49\n",
      "57/361.0 loss: 0.7024440570124264 \n",
      "Epoch:  49\n",
      "58/361.0 loss: 0.7025740894220643 \n",
      "Epoch:  49\n",
      "59/361.0 loss: 0.7011257171630859 \n",
      "Epoch:  49\n",
      "60/361.0 loss: 0.7022643919850959 \n",
      "Epoch:  49\n",
      "61/361.0 loss: 0.7022720517650727 \n",
      "Epoch:  49\n",
      "62/361.0 loss: 0.7012086434969826 \n",
      "Epoch:  49\n",
      "63/361.0 loss: 0.7008817298337817 \n",
      "Epoch:  49\n",
      "64/361.0 loss: 0.6998393223835871 \n",
      "Epoch:  49\n",
      "65/361.0 loss: 0.6984710892041525 \n",
      "Epoch:  49\n",
      "66/361.0 loss: 0.6978945918937227 \n",
      "Epoch:  49\n",
      "67/361.0 loss: 0.6965365558862686 \n",
      "Epoch:  49\n",
      "68/361.0 loss: 0.6963270012883173 \n",
      "Epoch:  49\n",
      "69/361.0 loss: 0.6965272128582001 \n",
      "Epoch:  49\n",
      "70/361.0 loss: 0.6954848564846415 \n",
      "Epoch:  49\n",
      "71/361.0 loss: 0.6959822368290689 \n",
      "Epoch:  49\n",
      "72/361.0 loss: 0.6962041560917684 \n",
      "Epoch:  49\n",
      "73/361.0 loss: 0.6950369799459303 \n",
      "Epoch:  49\n",
      "74/361.0 loss: 0.6943856724103292 \n",
      "Epoch:  49\n",
      "75/361.0 loss: 0.6936616270165694 \n",
      "Epoch:  49\n",
      "76/361.0 loss: 0.6949500991152479 \n",
      "Epoch:  49\n",
      "77/361.0 loss: 0.6959832257185227 \n",
      "Epoch:  49\n",
      "78/361.0 loss: 0.6949995393994488 \n",
      "Epoch:  49\n",
      "79/361.0 loss: 0.6950667209923267 \n",
      "Epoch:  49\n",
      "80/361.0 loss: 0.6945802863733268 \n",
      "Epoch:  49\n",
      "81/361.0 loss: 0.695210700354925 \n",
      "Epoch:  49\n",
      "82/361.0 loss: 0.6960275718964726 \n",
      "Epoch:  49\n",
      "83/361.0 loss: 0.6964695709092277 \n",
      "Epoch:  49\n",
      "84/361.0 loss: 0.6968320853569928 \n",
      "Epoch:  49\n",
      "85/361.0 loss: 0.6975992661575938 \n",
      "Epoch:  49\n",
      "86/361.0 loss: 0.6969070509932507 \n",
      "Epoch:  49\n",
      "87/361.0 loss: 0.6972381276163188 \n",
      "Epoch:  49\n",
      "88/361.0 loss: 0.6974054441023408 \n",
      "Epoch:  49\n",
      "89/361.0 loss: 0.6967573689089881 \n",
      "Epoch:  49\n",
      "90/361.0 loss: 0.6972346541645763 \n",
      "Epoch:  49\n",
      "91/361.0 loss: 0.696842430078465 \n",
      "Epoch:  49\n",
      "92/361.0 loss: 0.6970714971583377 \n",
      "Epoch:  49\n",
      "93/361.0 loss: 0.6974215374348012 \n",
      "Epoch:  49\n",
      "94/361.0 loss: 0.6973134549040544 \n",
      "Epoch:  49\n",
      "95/361.0 loss: 0.6968219392001629 \n",
      "Epoch:  49\n",
      "96/361.0 loss: 0.6962881641289622 \n",
      "Epoch:  49\n",
      "97/361.0 loss: 0.6957879242848377 \n",
      "Epoch:  49\n",
      "98/361.0 loss: 0.6955135103428003 \n",
      "Epoch:  49\n",
      "99/361.0 loss: 0.6954556995630264 \n",
      "Epoch:  49\n",
      "100/361.0 loss: 0.6947979873949939 \n",
      "Epoch:  49\n",
      "101/361.0 loss: 0.6949223344232521 \n",
      "Epoch:  49\n",
      "102/361.0 loss: 0.6954712665196762 \n",
      "Epoch:  49\n",
      "103/361.0 loss: 0.6959307256799477 \n",
      "Epoch:  49\n",
      "104/361.0 loss: 0.6963195113908677 \n",
      "Epoch:  49\n",
      "105/361.0 loss: 0.6965058181645736 \n",
      "Epoch:  49\n",
      "106/361.0 loss: 0.6968027865775278 \n",
      "Epoch:  49\n",
      "107/361.0 loss: 0.6973526113563113 \n",
      "Epoch:  49\n",
      "108/361.0 loss: 0.6971606809064883 \n",
      "Epoch:  49\n",
      "109/361.0 loss: 0.6973377390341325 \n",
      "Epoch:  49\n",
      "110/361.0 loss: 0.6968626186654374 \n",
      "Epoch:  49\n",
      "111/361.0 loss: 0.696500905922481 \n",
      "Epoch:  49\n",
      "112/361.0 loss: 0.6960265045672391 \n",
      "Epoch:  49\n",
      "113/361.0 loss: 0.6961456270594346 \n",
      "Epoch:  49\n",
      "114/361.0 loss: 0.6955849937770677 \n",
      "Epoch:  49\n",
      "115/361.0 loss: 0.6956037822468527 \n",
      "Epoch:  49\n",
      "116/361.0 loss: 0.6956696612203223 \n",
      "Epoch:  49\n",
      "117/361.0 loss: 0.6954617015386032 \n",
      "Epoch:  49\n",
      "118/361.0 loss: 0.6954722194110646 \n",
      "Epoch:  49\n",
      "119/361.0 loss: 0.6962331851323446 \n",
      "Epoch:  49\n",
      "120/361.0 loss: 0.6959656043486162 \n",
      "Epoch:  49\n",
      "121/361.0 loss: 0.6956156301693838 \n",
      "Epoch:  49\n",
      "122/361.0 loss: 0.6955654553281583 \n",
      "Epoch:  49\n",
      "123/361.0 loss: 0.6959862189908181 \n",
      "Epoch:  49\n",
      "124/361.0 loss: 0.6959213824272156 \n",
      "Epoch:  49\n",
      "125/361.0 loss: 0.6959816222153012 \n",
      "Epoch:  49\n",
      "126/361.0 loss: 0.6966323664807897 \n",
      "Epoch:  49\n",
      "127/361.0 loss: 0.6967200012877584 \n",
      "Epoch:  49\n",
      "128/361.0 loss: 0.6965776626453843 \n",
      "Epoch:  49\n",
      "129/361.0 loss: 0.696499987748953 \n",
      "Epoch:  49\n",
      "130/361.0 loss: 0.6968641112778933 \n",
      "Epoch:  49\n",
      "131/361.0 loss: 0.6972054514017972 \n",
      "Epoch:  49\n",
      "132/361.0 loss: 0.696866494372375 \n",
      "Epoch:  49\n",
      "133/361.0 loss: 0.6968672106515116 \n",
      "Epoch:  49\n",
      "134/361.0 loss: 0.6972325598752057 \n",
      "Epoch:  49\n",
      "135/361.0 loss: 0.6972681555677863 \n",
      "Epoch:  49\n",
      "136/361.0 loss: 0.6969299103221754 \n",
      "Epoch:  49\n",
      "137/361.0 loss: 0.6971014250015867 \n",
      "Epoch:  49\n",
      "138/361.0 loss: 0.6971793144726924 \n",
      "Epoch:  49\n",
      "139/361.0 loss: 0.6968767485448293 \n",
      "Epoch:  49\n",
      "140/361.0 loss: 0.6968638956124056 \n",
      "Epoch:  49\n",
      "141/361.0 loss: 0.6967454552650452 \n",
      "Epoch:  49\n",
      "142/361.0 loss: 0.696598175105515 \n",
      "Epoch:  49\n",
      "143/361.0 loss: 0.6962753811644183 \n",
      "Epoch:  49\n",
      "144/361.0 loss: 0.696270187558799 \n",
      "Epoch:  49\n",
      "145/361.0 loss: 0.6961617098279196 \n",
      "Epoch:  49\n",
      "146/361.0 loss: 0.6960252324740092 \n",
      "Epoch:  49\n",
      "147/361.0 loss: 0.6960976156028541 \n",
      "Epoch:  49\n",
      "148/361.0 loss: 0.6960176033461654 \n",
      "Epoch:  49\n",
      "149/361.0 loss: 0.6964673082033793 \n",
      "Epoch:  49\n",
      "150/361.0 loss: 0.6962096592448405 \n",
      "Epoch:  49\n",
      "151/361.0 loss: 0.6959928289840096 \n",
      "Epoch:  49\n",
      "152/361.0 loss: 0.6960907029170617 \n",
      "Epoch:  49\n",
      "153/361.0 loss: 0.6966557417597089 \n",
      "Epoch:  49\n",
      "154/361.0 loss: 0.6962163263751614 \n",
      "Epoch:  49\n",
      "155/361.0 loss: 0.6964556387601755 \n",
      "Epoch:  49\n",
      "156/361.0 loss: 0.6963535900328569 \n",
      "Epoch:  49\n",
      "157/361.0 loss: 0.6963866051239304 \n",
      "Epoch:  49\n",
      "158/361.0 loss: 0.69629749262108 \n",
      "Epoch:  49\n",
      "159/361.0 loss: 0.696132181957364 \n",
      "Epoch:  49\n",
      "160/361.0 loss: 0.6960241953778711 \n",
      "Epoch:  49\n",
      "161/361.0 loss: 0.6961124178803997 \n",
      "Epoch:  49\n",
      "162/361.0 loss: 0.6961707725115349 \n",
      "Epoch:  49\n",
      "163/361.0 loss: 0.6961974501609802 \n",
      "Epoch:  49\n",
      "164/361.0 loss: 0.6959772377303153 \n",
      "Epoch:  49\n",
      "165/361.0 loss: 0.6958723592470928 \n",
      "Epoch:  49\n",
      "166/361.0 loss: 0.695834861900992 \n",
      "Epoch:  49\n",
      "167/361.0 loss: 0.6960136361774945 \n",
      "Epoch:  49\n",
      "168/361.0 loss: 0.6959380599168631 \n",
      "Epoch:  49\n",
      "169/361.0 loss: 0.696424108393052 \n",
      "Epoch:  49\n",
      "170/361.0 loss: 0.6962271817246376 \n",
      "Epoch:  49\n",
      "171/361.0 loss: 0.696661654946416 \n",
      "Epoch:  49\n",
      "172/361.0 loss: 0.6968575726354742 \n",
      "Epoch:  49\n",
      "173/361.0 loss: 0.697214280394302 \n",
      "Epoch:  49\n",
      "174/361.0 loss: 0.6969433133942741 \n",
      "Epoch:  49\n",
      "175/361.0 loss: 0.6968312182209708 \n",
      "Epoch:  49\n",
      "176/361.0 loss: 0.697153832952855 \n",
      "Epoch:  49\n",
      "177/361.0 loss: 0.6971570032366207 \n",
      "Epoch:  49\n",
      "178/361.0 loss: 0.6970348827665744 \n",
      "Epoch:  49\n",
      "179/361.0 loss: 0.6965954085191091 \n",
      "Epoch:  49\n",
      "180/361.0 loss: 0.6959270732837487 \n",
      "Epoch:  49\n",
      "181/361.0 loss: 0.6961796585020128 \n",
      "Epoch:  49\n",
      "182/361.0 loss: 0.6962300685585522 \n",
      "Epoch:  49\n",
      "183/361.0 loss: 0.6965977060406104 \n",
      "Epoch:  49\n",
      "184/361.0 loss: 0.6965352425704131 \n",
      "Epoch:  49\n",
      "185/361.0 loss: 0.6962922766644467 \n",
      "Epoch:  49\n",
      "186/361.0 loss: 0.696489200553792 \n",
      "Epoch:  49\n",
      "187/361.0 loss: 0.6961512546590034 \n",
      "Epoch:  49\n",
      "188/361.0 loss: 0.6962753297790648 \n",
      "Epoch:  49\n",
      "189/361.0 loss: 0.696691359971699 \n",
      "Epoch:  49\n",
      "190/361.0 loss: 0.6965716287727756 \n",
      "Epoch:  49\n",
      "191/361.0 loss: 0.6963427178561687 \n",
      "Epoch:  49\n",
      "192/361.0 loss: 0.6961776558599324 \n",
      "Epoch:  49\n",
      "193/361.0 loss: 0.6963679166798739 \n",
      "Epoch:  49\n",
      "194/361.0 loss: 0.6960219578865247 \n",
      "Epoch:  49\n",
      "195/361.0 loss: 0.6957954682257711 \n",
      "Epoch:  49\n",
      "196/361.0 loss: 0.695487190624179 \n",
      "Epoch:  49\n",
      "197/361.0 loss: 0.6951420812895803 \n",
      "Epoch:  49\n",
      "198/361.0 loss: 0.6958542885492794 \n",
      "Epoch:  49\n",
      "199/361.0 loss: 0.6955209270119667 \n",
      "Epoch:  49\n",
      "200/361.0 loss: 0.695323583498523 \n",
      "Epoch:  49\n",
      "201/361.0 loss: 0.6954419969922245 \n",
      "Epoch:  49\n",
      "202/361.0 loss: 0.6957645216598887 \n",
      "Epoch:  49\n",
      "203/361.0 loss: 0.6957376444456624 \n",
      "Epoch:  49\n",
      "204/361.0 loss: 0.6958377099618679 \n",
      "Epoch:  49\n",
      "205/361.0 loss: 0.695713037136689 \n",
      "Epoch:  49\n",
      "206/361.0 loss: 0.6954310222524376 \n",
      "Epoch:  49\n",
      "207/361.0 loss: 0.6958442482237632 \n",
      "Epoch:  49\n",
      "208/361.0 loss: 0.6960197892485623 \n",
      "Epoch:  49\n",
      "209/361.0 loss: 0.6960976535365695 \n",
      "Epoch:  49\n",
      "210/361.0 loss: 0.6961403000411264 \n",
      "Epoch:  49\n",
      "211/361.0 loss: 0.6964303347861992 \n",
      "Epoch:  49\n",
      "212/361.0 loss: 0.69611317143194 \n",
      "Epoch:  49\n",
      "213/361.0 loss: 0.6963066021415675 \n",
      "Epoch:  49\n",
      "214/361.0 loss: 0.6961576317631921 \n",
      "Epoch:  49\n",
      "215/361.0 loss: 0.6960197698186945 \n",
      "Epoch:  49\n",
      "216/361.0 loss: 0.6958161026651409 \n",
      "Epoch:  49\n",
      "217/361.0 loss: 0.6959673188148289 \n",
      "Epoch:  49\n",
      "218/361.0 loss: 0.6964041016417551 \n",
      "Epoch:  49\n",
      "219/361.0 loss: 0.6963198965246027 \n",
      "Epoch:  49\n",
      "220/361.0 loss: 0.6964596124256358 \n",
      "Epoch:  49\n",
      "221/361.0 loss: 0.6962779110616392 \n",
      "Epoch:  49\n",
      "222/361.0 loss: 0.6960750671245592 \n",
      "Epoch:  49\n",
      "223/361.0 loss: 0.6960795641477618 \n",
      "Epoch:  49\n",
      "224/361.0 loss: 0.6959434286753337 \n",
      "Epoch:  49\n",
      "225/361.0 loss: 0.695925972366755 \n",
      "Epoch:  49\n",
      "226/361.0 loss: 0.6962794966109523 \n",
      "Epoch:  49\n",
      "227/361.0 loss: 0.6963446720650321 \n",
      "Epoch:  49\n",
      "228/361.0 loss: 0.696252462645285 \n",
      "Epoch:  49\n",
      "229/361.0 loss: 0.6960584399492844 \n",
      "Epoch:  49\n",
      "230/361.0 loss: 0.6958691103633864 \n",
      "Epoch:  49\n",
      "231/361.0 loss: 0.6957748871425102 \n",
      "Epoch:  49\n",
      "232/361.0 loss: 0.6954498441945841 \n",
      "Epoch:  49\n",
      "233/361.0 loss: 0.6958047329870045 \n",
      "Epoch:  49\n",
      "234/361.0 loss: 0.6958814473862344 \n",
      "Epoch:  49\n",
      "235/361.0 loss: 0.6958156846842524 \n",
      "Epoch:  49\n",
      "236/361.0 loss: 0.6959455936266903 \n",
      "Epoch:  49\n",
      "237/361.0 loss: 0.6957852519860789 \n",
      "Epoch:  49\n",
      "238/361.0 loss: 0.6957761011861857 \n",
      "Epoch:  49\n",
      "239/361.0 loss: 0.6959951438009739 \n",
      "Epoch:  49\n",
      "240/361.0 loss: 0.6959065765266101 \n",
      "Epoch:  49\n",
      "241/361.0 loss: 0.6960823851183426 \n",
      "Epoch:  49\n",
      "242/361.0 loss: 0.6959080882523776 \n",
      "Epoch:  49\n",
      "243/361.0 loss: 0.6958278500642933 \n",
      "Epoch:  49\n",
      "244/361.0 loss: 0.6954980957264802 \n",
      "Epoch:  49\n",
      "245/361.0 loss: 0.6950581129488906 \n",
      "Epoch:  49\n",
      "246/361.0 loss: 0.6949348456946461 \n",
      "Epoch:  49\n",
      "247/361.0 loss: 0.6953022910221931 \n",
      "Epoch:  49\n",
      "248/361.0 loss: 0.6955690151716332 \n",
      "Epoch:  49\n",
      "249/361.0 loss: 0.6954075863361359 \n",
      "Epoch:  49\n",
      "250/361.0 loss: 0.6952287637854953 \n",
      "Epoch:  49\n",
      "251/361.0 loss: 0.6951095504420144 \n",
      "Epoch:  49\n",
      "252/361.0 loss: 0.6953469422966124 \n",
      "Epoch:  49\n",
      "253/361.0 loss: 0.6954262646164481 \n",
      "Epoch:  49\n",
      "254/361.0 loss: 0.6956201621130401 \n",
      "Epoch:  49\n",
      "255/361.0 loss: 0.6955745872110128 \n",
      "Epoch:  49\n",
      "256/361.0 loss: 0.6955217867509864 \n",
      "Epoch:  49\n",
      "257/361.0 loss: 0.6955319462820541 \n",
      "Epoch:  49\n",
      "258/361.0 loss: 0.6950537603794378 \n",
      "Epoch:  49\n",
      "259/361.0 loss: 0.6953103801378837 \n",
      "Epoch:  49\n",
      "260/361.0 loss: 0.6956070524522628 \n",
      "Epoch:  49\n",
      "261/361.0 loss: 0.6953740584031316 \n",
      "Epoch:  49\n",
      "262/361.0 loss: 0.6953267305522817 \n",
      "Epoch:  49\n",
      "263/361.0 loss: 0.6954130543903871 \n",
      "Epoch:  49\n",
      "264/361.0 loss: 0.6951663941707251 \n",
      "Epoch:  49\n",
      "265/361.0 loss: 0.694993646745395 \n",
      "Epoch:  49\n",
      "266/361.0 loss: 0.6949579173259521 \n",
      "Epoch:  49\n",
      "267/361.0 loss: 0.6945123828169125 \n",
      "Epoch:  49\n",
      "268/361.0 loss: 0.6945321014822637 \n",
      "Epoch:  49\n",
      "269/361.0 loss: 0.6945089333587222 \n",
      "Epoch:  49\n",
      "270/361.0 loss: 0.6946812667969848 \n",
      "Epoch:  49\n",
      "271/361.0 loss: 0.6949584026108769 \n",
      "Epoch:  49\n",
      "272/361.0 loss: 0.6947060393326449 \n",
      "Epoch:  49\n",
      "273/361.0 loss: 0.69453952760592 \n",
      "Epoch:  49\n",
      "274/361.0 loss: 0.6944473331624811 \n",
      "Epoch:  49\n",
      "275/361.0 loss: 0.6940825521082118 \n",
      "Epoch:  49\n",
      "276/361.0 loss: 0.6942196512050147 \n",
      "Epoch:  49\n",
      "277/361.0 loss: 0.6940360022105759 \n",
      "Epoch:  49\n",
      "278/361.0 loss: 0.6945991872886603 \n",
      "Epoch:  49\n",
      "279/361.0 loss: 0.6944078177213668 \n",
      "Epoch:  49\n",
      "280/361.0 loss: 0.6942682872887608 \n",
      "Epoch:  49\n",
      "281/361.0 loss: 0.694724180385576 \n",
      "Epoch:  49\n",
      "282/361.0 loss: 0.6945429153661424 \n",
      "Epoch:  49\n",
      "283/361.0 loss: 0.6948160558519229 \n",
      "Epoch:  49\n",
      "284/361.0 loss: 0.6945824533178095 \n",
      "Epoch:  49\n",
      "285/361.0 loss: 0.6942800823208335 \n",
      "Epoch:  49\n",
      "286/361.0 loss: 0.6941455407425087 \n",
      "Epoch:  49\n",
      "287/361.0 loss: 0.6943370859242148 \n",
      "Epoch:  49\n",
      "288/361.0 loss: 0.6946783833025236 \n",
      "Epoch:  49\n",
      "289/361.0 loss: 0.695051229411158 \n",
      "Epoch:  49\n",
      "290/361.0 loss: 0.6952326713558734 \n",
      "Epoch:  49\n",
      "291/361.0 loss: 0.695825478597863 \n",
      "Epoch:  49\n",
      "292/361.0 loss: 0.6957011645971305 \n",
      "Epoch:  49\n",
      "293/361.0 loss: 0.6959855369970102 \n",
      "Epoch:  49\n",
      "294/361.0 loss: 0.6961307264990726 \n",
      "Epoch:  49\n",
      "295/361.0 loss: 0.6964228471388688 \n",
      "Epoch:  49\n",
      "296/361.0 loss: 0.6968514024207889 \n",
      "Epoch:  49\n",
      "297/361.0 loss: 0.6966953121575733 \n",
      "Epoch:  49\n",
      "298/361.0 loss: 0.6966960711224023 \n",
      "Epoch:  49\n",
      "299/361.0 loss: 0.6969873968760173 \n",
      "Epoch:  49\n",
      "300/361.0 loss: 0.6966477579056622 \n",
      "Epoch:  49\n",
      "301/361.0 loss: 0.696327283879779 \n",
      "Epoch:  49\n",
      "302/361.0 loss: 0.6962007716937427 \n",
      "Epoch:  49\n",
      "303/361.0 loss: 0.6963942396013361 \n",
      "Epoch:  49\n",
      "304/361.0 loss: 0.696255120683889 \n",
      "Epoch:  49\n",
      "305/361.0 loss: 0.6959474312713723 \n",
      "Epoch:  49\n",
      "306/361.0 loss: 0.6960842409429022 \n",
      "Epoch:  49\n",
      "307/361.0 loss: 0.6959945453064782 \n",
      "Epoch:  49\n",
      "308/361.0 loss: 0.6958290874765143 \n",
      "Epoch:  49\n",
      "309/361.0 loss: 0.6956133963600282 \n",
      "Epoch:  49\n",
      "310/361.0 loss: 0.6954618360835256 \n",
      "Epoch:  49\n",
      "311/361.0 loss: 0.6957225052592082 \n",
      "Epoch:  49\n",
      "312/361.0 loss: 0.6956236364361578 \n",
      "Epoch:  49\n",
      "313/361.0 loss: 0.6953758134204111 \n",
      "Epoch:  49\n",
      "314/361.0 loss: 0.6955150710211859 \n",
      "Epoch:  49\n",
      "315/361.0 loss: 0.695737694071818 \n",
      "Epoch:  49\n",
      "316/361.0 loss: 0.6955654307118726 \n",
      "Epoch:  49\n",
      "317/361.0 loss: 0.6955574332918011 \n",
      "Epoch:  49\n",
      "318/361.0 loss: 0.6958907125138191 \n",
      "Epoch:  49\n",
      "319/361.0 loss: 0.6960532205179334 \n",
      "Epoch:  49\n",
      "320/361.0 loss: 0.6964325097119697 \n",
      "Epoch:  49\n",
      "321/361.0 loss: 0.6965191888142817 \n",
      "Epoch:  49\n",
      "322/361.0 loss: 0.6964708644170141 \n",
      "Epoch:  49\n",
      "323/361.0 loss: 0.6967168338136909 \n",
      "Epoch:  49\n",
      "324/361.0 loss: 0.6965896978745094 \n",
      "Epoch:  49\n",
      "325/361.0 loss: 0.696537571450684 \n",
      "Epoch:  49\n",
      "326/361.0 loss: 0.6965485295389041 \n",
      "Epoch:  49\n",
      "327/361.0 loss: 0.6962027833229159 \n",
      "Epoch:  49\n",
      "328/361.0 loss: 0.6960415360050723 \n",
      "Epoch:  49\n",
      "329/361.0 loss: 0.6961294226574175 \n",
      "Epoch:  49\n",
      "330/361.0 loss: 0.6959573331196143 \n",
      "Epoch:  49\n",
      "331/361.0 loss: 0.6958651894546417 \n",
      "Epoch:  49\n",
      "332/361.0 loss: 0.6957387380055837 \n",
      "Epoch:  49\n",
      "333/361.0 loss: 0.6955386537634684 \n",
      "Epoch:  49\n",
      "334/361.0 loss: 0.6953810344881086 \n",
      "Epoch:  49\n",
      "335/361.0 loss: 0.6956964779113021 \n",
      "Epoch:  49\n",
      "336/361.0 loss: 0.6954541577783466 \n",
      "Epoch:  49\n",
      "337/361.0 loss: 0.6951986189777329 \n",
      "Epoch:  49\n",
      "338/361.0 loss: 0.6950301914791793 \n",
      "Epoch:  49\n",
      "339/361.0 loss: 0.6951842471080668 \n",
      "Epoch:  49\n",
      "340/361.0 loss: 0.6954906834535235 \n",
      "Epoch:  49\n",
      "341/361.0 loss: 0.6951048839510533 \n",
      "Epoch:  49\n",
      "342/361.0 loss: 0.6954842741565871 \n",
      "Epoch:  49\n",
      "343/361.0 loss: 0.6955509634558544 \n",
      "Epoch:  49\n",
      "344/361.0 loss: 0.6954218124997789 \n",
      "Epoch:  49\n",
      "345/361.0 loss: 0.6956366186886165 \n",
      "Epoch:  49\n",
      "346/361.0 loss: 0.6957598034861452 \n",
      "Epoch:  49\n",
      "347/361.0 loss: 0.6959548609695215 \n",
      "Epoch:  49\n",
      "348/361.0 loss: 0.695715478634766 \n",
      "Epoch:  49\n",
      "349/361.0 loss: 0.6954725199086326 \n",
      "Epoch:  49\n",
      "350/361.0 loss: 0.6958611364717837 \n",
      "Epoch:  49\n",
      "351/361.0 loss: 0.695817946371707 \n",
      "Epoch:  49\n",
      "352/361.0 loss: 0.6956487684682138 \n",
      "Epoch:  49\n",
      "353/361.0 loss: 0.695522369132877 \n",
      "Epoch:  49\n",
      "354/361.0 loss: 0.6952121126819665 \n",
      "Epoch:  49\n",
      "355/361.0 loss: 0.6954385408859575 \n",
      "Epoch:  49\n",
      "356/361.0 loss: 0.6953491997652027 \n",
      "Epoch:  49\n",
      "357/361.0 loss: 0.6956580487709472 \n",
      "Epoch:  49\n",
      "358/361.0 loss: 0.695531531628792 \n",
      "Epoch:  49\n",
      "359/361.0 loss: 0.6952583405706617 \n",
      "Epoch:  49\n",
      "360/361.0 loss: 0.6950833137015556 \n",
      "Epoch:  50\n",
      "0/361.0 loss: 0.6073296666145325 \n",
      "Epoch:  50\n",
      "1/361.0 loss: 0.6956120431423187 \n",
      "Epoch:  50\n",
      "2/361.0 loss: 0.6701632539431254 \n",
      "Epoch:  50\n",
      "3/361.0 loss: 0.6778482645750046 \n",
      "Epoch:  50\n",
      "4/361.0 loss: 0.6712081670761109 \n",
      "Epoch:  50\n",
      "5/361.0 loss: 0.6598875025908152 \n",
      "Epoch:  50\n",
      "6/361.0 loss: 0.653788719858442 \n",
      "Epoch:  50\n",
      "7/361.0 loss: 0.643754355609417 \n",
      "Epoch:  50\n",
      "8/361.0 loss: 0.6668562756644355 \n",
      "Epoch:  50\n",
      "9/361.0 loss: 0.6571761727333069 \n",
      "Epoch:  50\n",
      "10/361.0 loss: 0.647129703651775 \n",
      "Epoch:  50\n",
      "11/361.0 loss: 0.6445718258619308 \n",
      "Epoch:  50\n",
      "12/361.0 loss: 0.6432528220690213 \n",
      "Epoch:  50\n",
      "13/361.0 loss: 0.6400098332336971 \n",
      "Epoch:  50\n",
      "14/361.0 loss: 0.6494412859280904 \n",
      "Epoch:  50\n",
      "15/361.0 loss: 0.660806130617857 \n",
      "Epoch:  50\n",
      "16/361.0 loss: 0.6713582101990195 \n",
      "Epoch:  50\n",
      "17/361.0 loss: 0.6784930759006076 \n",
      "Epoch:  50\n",
      "18/361.0 loss: 0.6874067783355713 \n",
      "Epoch:  50\n",
      "19/361.0 loss: 0.6904528498649597 \n",
      "Epoch:  50\n",
      "20/361.0 loss: 0.6965020298957825 \n",
      "Epoch:  50\n",
      "21/361.0 loss: 0.7019231698729775 \n",
      "Epoch:  50\n",
      "22/361.0 loss: 0.7032410502433777 \n",
      "Epoch:  50\n",
      "23/361.0 loss: 0.7077269951502482 \n",
      "Epoch:  50\n",
      "24/361.0 loss: 0.7111141705513 \n",
      "Epoch:  50\n",
      "25/361.0 loss: 0.7062471761153295 \n",
      "Epoch:  50\n",
      "26/361.0 loss: 0.7025416294733683 \n",
      "Epoch:  50\n",
      "27/361.0 loss: 0.7004769721201488 \n",
      "Epoch:  50\n",
      "28/361.0 loss: 0.7032180387398292 \n",
      "Epoch:  50\n",
      "29/361.0 loss: 0.6996181786060334 \n",
      "Epoch:  50\n",
      "30/361.0 loss: 0.6957377964450467 \n",
      "Epoch:  50\n",
      "31/361.0 loss: 0.6948278583586216 \n",
      "Epoch:  50\n",
      "32/361.0 loss: 0.6980410434982993 \n",
      "Epoch:  50\n",
      "33/361.0 loss: 0.6998519616968492 \n",
      "Epoch:  50\n",
      "34/361.0 loss: 0.6979173864637103 \n",
      "Epoch:  50\n",
      "35/361.0 loss: 0.6968290789259804 \n",
      "Epoch:  50\n",
      "36/361.0 loss: 0.7000679454287967 \n",
      "Epoch:  50\n",
      "37/361.0 loss: 0.7024571189754888 \n",
      "Epoch:  50\n",
      "38/361.0 loss: 0.7001930994865222 \n",
      "Epoch:  50\n",
      "39/361.0 loss: 0.6990729570388794 \n",
      "Epoch:  50\n",
      "40/361.0 loss: 0.6959521843165886 \n",
      "Epoch:  50\n",
      "41/361.0 loss: 0.6931196451187134 \n",
      "Epoch:  50\n",
      "42/361.0 loss: 0.6965359865232955 \n",
      "Epoch:  50\n",
      "43/361.0 loss: 0.6957170651717619 \n",
      "Epoch:  50\n",
      "44/361.0 loss: 0.69625809457567 \n",
      "Epoch:  50\n",
      "45/361.0 loss: 0.6971809384615525 \n",
      "Epoch:  50\n",
      "46/361.0 loss: 0.6984280322460418 \n",
      "Epoch:  50\n",
      "47/361.0 loss: 0.699420902878046 \n",
      "Epoch:  50\n",
      "48/361.0 loss: 0.6976383717692628 \n",
      "Epoch:  50\n",
      "49/361.0 loss: 0.6960925817489624 \n",
      "Epoch:  50\n",
      "50/361.0 loss: 0.693923132092345 \n",
      "Epoch:  50\n",
      "51/361.0 loss: 0.6958329471258017 \n",
      "Epoch:  50\n",
      "52/361.0 loss: 0.6942451123921376 \n",
      "Epoch:  50\n",
      "53/361.0 loss: 0.6919008780408789 \n",
      "Epoch:  50\n",
      "54/361.0 loss: 0.6904100060462952 \n",
      "Epoch:  50\n",
      "55/361.0 loss: 0.6913842899458749 \n",
      "Epoch:  50\n",
      "56/361.0 loss: 0.693239078187106 \n",
      "Epoch:  50\n",
      "57/361.0 loss: 0.6916508047745146 \n",
      "Epoch:  50\n",
      "58/361.0 loss: 0.6909602981502727 \n",
      "Epoch:  50\n",
      "59/361.0 loss: 0.6897812167803447 \n",
      "Epoch:  50\n",
      "60/361.0 loss: 0.6923857184707142 \n",
      "Epoch:  50\n",
      "61/361.0 loss: 0.6900131654354834 \n",
      "Epoch:  50\n",
      "62/361.0 loss: 0.6883015046044002 \n",
      "Epoch:  50\n",
      "63/361.0 loss: 0.6885137287899852 \n",
      "Epoch:  50\n",
      "64/361.0 loss: 0.6893555760383606 \n",
      "Epoch:  50\n",
      "65/361.0 loss: 0.68780102242123 \n",
      "Epoch:  50\n",
      "66/361.0 loss: 0.6897691230275738 \n",
      "Epoch:  50\n",
      "67/361.0 loss: 0.691276458256385 \n",
      "Epoch:  50\n",
      "68/361.0 loss: 0.6908021284186322 \n",
      "Epoch:  50\n",
      "69/361.0 loss: 0.6914765042918068 \n",
      "Epoch:  50\n",
      "70/361.0 loss: 0.693143282138126 \n",
      "Epoch:  50\n",
      "71/361.0 loss: 0.6953703794214461 \n",
      "Epoch:  50\n",
      "72/361.0 loss: 0.6943143810311408 \n",
      "Epoch:  50\n",
      "73/361.0 loss: 0.6951778063902984 \n",
      "Epoch:  50\n",
      "74/361.0 loss: 0.6964396508534749 \n",
      "Epoch:  50\n",
      "75/361.0 loss: 0.6971621654535595 \n",
      "Epoch:  50\n",
      "76/361.0 loss: 0.6986400941749672 \n",
      "Epoch:  50\n",
      "77/361.0 loss: 0.6992938090593387 \n",
      "Epoch:  50\n",
      "78/361.0 loss: 0.7004562299462813 \n",
      "Epoch:  50\n",
      "79/361.0 loss: 0.6996588073670864 \n",
      "Epoch:  50\n",
      "80/361.0 loss: 0.6989598325741144 \n",
      "Epoch:  50\n",
      "81/361.0 loss: 0.6978975977839493 \n",
      "Epoch:  50\n",
      "82/361.0 loss: 0.6978494345423687 \n",
      "Epoch:  50\n",
      "83/361.0 loss: 0.6986113460290999 \n",
      "Epoch:  50\n",
      "84/361.0 loss: 0.6976803071358625 \n",
      "Epoch:  50\n",
      "85/361.0 loss: 0.6973201369130334 \n",
      "Epoch:  50\n",
      "86/361.0 loss: 0.6972618548349402 \n",
      "Epoch:  50\n",
      "87/361.0 loss: 0.6982254954901609 \n",
      "Epoch:  50\n",
      "88/361.0 loss: 0.6971422668253437 \n",
      "Epoch:  50\n",
      "89/361.0 loss: 0.6978189375665452 \n",
      "Epoch:  50\n",
      "90/361.0 loss: 0.6971395906511244 \n",
      "Epoch:  50\n",
      "91/361.0 loss: 0.6965653390988059 \n",
      "Epoch:  50\n",
      "92/361.0 loss: 0.6966432691902242 \n",
      "Epoch:  50\n",
      "93/361.0 loss: 0.6970306882198821 \n",
      "Epoch:  50\n",
      "94/361.0 loss: 0.6964674108906797 \n",
      "Epoch:  50\n",
      "95/361.0 loss: 0.6962268861631552 \n",
      "Epoch:  50\n",
      "96/361.0 loss: 0.6964268610649502 \n",
      "Epoch:  50\n",
      "97/361.0 loss: 0.6962326381887708 \n",
      "Epoch:  50\n",
      "98/361.0 loss: 0.6956970926487085 \n",
      "Epoch:  50\n",
      "99/361.0 loss: 0.6966075265407562 \n",
      "Epoch:  50\n",
      "100/361.0 loss: 0.6964932827666255 \n",
      "Epoch:  50\n",
      "101/361.0 loss: 0.6960210800170898 \n",
      "Epoch:  50\n",
      "102/361.0 loss: 0.696210359485404 \n",
      "Epoch:  50\n",
      "103/361.0 loss: 0.6955105232504698 \n",
      "Epoch:  50\n",
      "104/361.0 loss: 0.6956213570776439 \n",
      "Epoch:  50\n",
      "105/361.0 loss: 0.6947748711648977 \n",
      "Epoch:  50\n",
      "106/361.0 loss: 0.6939461938688688 \n",
      "Epoch:  50\n",
      "107/361.0 loss: 0.6932733765354863 \n",
      "Epoch:  50\n",
      "108/361.0 loss: 0.6932964095281898 \n",
      "Epoch:  50\n",
      "109/361.0 loss: 0.6935434352267872 \n",
      "Epoch:  50\n",
      "110/361.0 loss: 0.6942783137699505 \n",
      "Epoch:  50\n",
      "111/361.0 loss: 0.6944934635290078 \n",
      "Epoch:  50\n",
      "112/361.0 loss: 0.6936459873629882 \n",
      "Epoch:  50\n",
      "113/361.0 loss: 0.6930070503761894 \n",
      "Epoch:  50\n",
      "114/361.0 loss: 0.6933315764302793 \n",
      "Epoch:  50\n",
      "115/361.0 loss: 0.6944268140299567 \n",
      "Epoch:  50\n",
      "116/361.0 loss: 0.6946249038745196 \n",
      "Epoch:  50\n",
      "117/361.0 loss: 0.6949610078738908 \n",
      "Epoch:  50\n",
      "118/361.0 loss: 0.694437751249105 \n",
      "Epoch:  50\n",
      "119/361.0 loss: 0.6951661189397176 \n",
      "Epoch:  50\n",
      "120/361.0 loss: 0.69542167107921 \n",
      "Epoch:  50\n",
      "121/361.0 loss: 0.6957126655539528 \n",
      "Epoch:  50\n",
      "122/361.0 loss: 0.6946178068959616 \n",
      "Epoch:  50\n",
      "123/361.0 loss: 0.6949021292309607 \n",
      "Epoch:  50\n",
      "124/361.0 loss: 0.6948528547286987 \n",
      "Epoch:  50\n",
      "125/361.0 loss: 0.694890391732019 \n",
      "Epoch:  50\n",
      "126/361.0 loss: 0.6941002959341515 \n",
      "Epoch:  50\n",
      "127/361.0 loss: 0.6935872905887663 \n",
      "Epoch:  50\n",
      "128/361.0 loss: 0.6930176186007123 \n",
      "Epoch:  50\n",
      "129/361.0 loss: 0.6926653357652518 \n",
      "Epoch:  50\n",
      "130/361.0 loss: 0.6928349742452606 \n",
      "Epoch:  50\n",
      "131/361.0 loss: 0.6934316524050452 \n",
      "Epoch:  50\n",
      "132/361.0 loss: 0.6937636320752308 \n",
      "Epoch:  50\n",
      "133/361.0 loss: 0.6934944898334902 \n",
      "Epoch:  50\n",
      "134/361.0 loss: 0.6929376769948888 \n",
      "Epoch:  50\n",
      "135/361.0 loss: 0.6923001965179163 \n",
      "Epoch:  50\n",
      "136/361.0 loss: 0.692173421382904 \n",
      "Epoch:  50\n",
      "137/361.0 loss: 0.6920172222282576 \n",
      "Epoch:  50\n",
      "138/361.0 loss: 0.6912713226654547 \n",
      "Epoch:  50\n",
      "139/361.0 loss: 0.6906796208449772 \n",
      "Epoch:  50\n",
      "140/361.0 loss: 0.6903145989627703 \n",
      "Epoch:  50\n",
      "141/361.0 loss: 0.6904179726687956 \n",
      "Epoch:  50\n",
      "142/361.0 loss: 0.6900655114567363 \n",
      "Epoch:  50\n",
      "143/361.0 loss: 0.690508146252897 \n",
      "Epoch:  50\n",
      "144/361.0 loss: 0.6910668060697358 \n",
      "Epoch:  50\n",
      "145/361.0 loss: 0.6914386561472122 \n",
      "Epoch:  50\n",
      "146/361.0 loss: 0.6909328293638165 \n",
      "Epoch:  50\n",
      "147/361.0 loss: 0.6913969536890855 \n",
      "Epoch:  50\n",
      "148/361.0 loss: 0.6917704971844718 \n",
      "Epoch:  50\n",
      "149/361.0 loss: 0.6919730877876282 \n",
      "Epoch:  50\n",
      "150/361.0 loss: 0.6924833213256685 \n",
      "Epoch:  50\n",
      "151/361.0 loss: 0.6915415192120954 \n",
      "Epoch:  50\n",
      "152/361.0 loss: 0.6917286604837655 \n",
      "Epoch:  50\n",
      "153/361.0 loss: 0.6909706147460194 \n",
      "Epoch:  50\n",
      "154/361.0 loss: 0.6912840177935938 \n",
      "Epoch:  50\n",
      "155/361.0 loss: 0.691631331275671 \n",
      "Epoch:  50\n",
      "156/361.0 loss: 0.692083262334204 \n",
      "Epoch:  50\n",
      "157/361.0 loss: 0.6916139620014384 \n",
      "Epoch:  50\n",
      "158/361.0 loss: 0.6910828468184801 \n",
      "Epoch:  50\n",
      "159/361.0 loss: 0.6914121899753809 \n",
      "Epoch:  50\n",
      "160/361.0 loss: 0.6912279891671601 \n",
      "Epoch:  50\n",
      "161/361.0 loss: 0.6918561546890823 \n",
      "Epoch:  50\n",
      "162/361.0 loss: 0.6923142561883283 \n",
      "Epoch:  50\n",
      "163/361.0 loss: 0.692812995212834 \n",
      "Epoch:  50\n",
      "164/361.0 loss: 0.6932905572833437 \n",
      "Epoch:  50\n",
      "165/361.0 loss: 0.6927333829632725 \n",
      "Epoch:  50\n",
      "166/361.0 loss: 0.692549300407935 \n",
      "Epoch:  50\n",
      "167/361.0 loss: 0.6923542693257332 \n",
      "Epoch:  50\n",
      "168/361.0 loss: 0.6920625846061481 \n",
      "Epoch:  50\n",
      "169/361.0 loss: 0.6919238234267515 \n",
      "Epoch:  50\n",
      "170/361.0 loss: 0.6915114368611609 \n",
      "Epoch:  50\n",
      "171/361.0 loss: 0.6919923965321031 \n",
      "Epoch:  50\n",
      "172/361.0 loss: 0.6917417211339653 \n",
      "Epoch:  50\n",
      "173/361.0 loss: 0.6923222377382475 \n",
      "Epoch:  50\n",
      "174/361.0 loss: 0.6924624892643519 \n",
      "Epoch:  50\n",
      "175/361.0 loss: 0.6924100958488204 \n",
      "Epoch:  50\n",
      "176/361.0 loss: 0.6926689161419195 \n",
      "Epoch:  50\n",
      "177/361.0 loss: 0.6923302810513572 \n",
      "Epoch:  50\n",
      "178/361.0 loss: 0.6918549088126454 \n",
      "Epoch:  50\n",
      "179/361.0 loss: 0.6917149282164043 \n",
      "Epoch:  50\n",
      "180/361.0 loss: 0.6915635769538457 \n",
      "Epoch:  50\n",
      "181/361.0 loss: 0.692255940411117 \n",
      "Epoch:  50\n",
      "182/361.0 loss: 0.6920068990337392 \n",
      "Epoch:  50\n",
      "183/361.0 loss: 0.6921686303356419 \n",
      "Epoch:  50\n",
      "184/361.0 loss: 0.6918623389424504 \n",
      "Epoch:  50\n",
      "185/361.0 loss: 0.691511167313463 \n",
      "Epoch:  50\n",
      "186/361.0 loss: 0.6912248988840032 \n",
      "Epoch:  50\n",
      "187/361.0 loss: 0.6909591555595398 \n",
      "Epoch:  50\n",
      "188/361.0 loss: 0.6912981432581705 \n",
      "Epoch:  50\n",
      "189/361.0 loss: 0.6909600050825822 \n",
      "Epoch:  50\n",
      "190/361.0 loss: 0.690441846535468 \n",
      "Epoch:  50\n",
      "191/361.0 loss: 0.6908645471557975 \n",
      "Epoch:  50\n",
      "192/361.0 loss: 0.6905173999040238 \n",
      "Epoch:  50\n",
      "193/361.0 loss: 0.6908625032483917 \n",
      "Epoch:  50\n",
      "194/361.0 loss: 0.6912604273893894 \n",
      "Epoch:  50\n",
      "195/361.0 loss: 0.691876720409004 \n",
      "Epoch:  50\n",
      "196/361.0 loss: 0.6921668691078419 \n",
      "Epoch:  50\n",
      "197/361.0 loss: 0.6928260377561203 \n",
      "Epoch:  50\n",
      "198/361.0 loss: 0.692261569464027 \n",
      "Epoch:  50\n",
      "199/361.0 loss: 0.6921679428219796 \n",
      "Epoch:  50\n",
      "200/361.0 loss: 0.691770252007157 \n",
      "Epoch:  50\n",
      "201/361.0 loss: 0.6913487285670668 \n",
      "Epoch:  50\n",
      "202/361.0 loss: 0.6911650896072388 \n",
      "Epoch:  50\n",
      "203/361.0 loss: 0.6906099705135121 \n",
      "Epoch:  50\n",
      "204/361.0 loss: 0.6903344183433346 \n",
      "Epoch:  50\n",
      "205/361.0 loss: 0.6907260548142553 \n",
      "Epoch:  50\n",
      "206/361.0 loss: 0.6910962004592454 \n",
      "Epoch:  50\n",
      "207/361.0 loss: 0.6915903369394633 \n",
      "Epoch:  50\n",
      "208/361.0 loss: 0.6911456867268211 \n",
      "Epoch:  50\n",
      "209/361.0 loss: 0.6910841791402726 \n",
      "Epoch:  50\n",
      "210/361.0 loss: 0.690834366879757 \n",
      "Epoch:  50\n",
      "211/361.0 loss: 0.6911876702083731 \n",
      "Epoch:  50\n",
      "212/361.0 loss: 0.6908445470209973 \n",
      "Epoch:  50\n",
      "213/361.0 loss: 0.6913898765483749 \n",
      "Epoch:  50\n",
      "214/361.0 loss: 0.6906446883844775 \n",
      "Epoch:  50\n",
      "215/361.0 loss: 0.6913915171667382 \n",
      "Epoch:  50\n",
      "216/361.0 loss: 0.6911201158426874 \n",
      "Epoch:  50\n",
      "217/361.0 loss: 0.6908815787472856 \n",
      "Epoch:  50\n",
      "218/361.0 loss: 0.6903631355120167 \n",
      "Epoch:  50\n",
      "219/361.0 loss: 0.6899607273665341 \n",
      "Epoch:  50\n",
      "220/361.0 loss: 0.6905712129303773 \n",
      "Epoch:  50\n",
      "221/361.0 loss: 0.6901504534321863 \n",
      "Epoch:  50\n",
      "222/361.0 loss: 0.6895389396513524 \n",
      "Epoch:  50\n",
      "223/361.0 loss: 0.6893309564994914 \n",
      "Epoch:  50\n",
      "224/361.0 loss: 0.6897600436210632 \n",
      "Epoch:  50\n",
      "225/361.0 loss: 0.6895220366726934 \n",
      "Epoch:  50\n",
      "226/361.0 loss: 0.6889514035590419 \n",
      "Epoch:  50\n",
      "227/361.0 loss: 0.6894327655696032 \n",
      "Epoch:  50\n",
      "228/361.0 loss: 0.6890392006744984 \n",
      "Epoch:  50\n",
      "229/361.0 loss: 0.6884287891180619 \n",
      "Epoch:  50\n",
      "230/361.0 loss: 0.6889628022264093 \n",
      "Epoch:  50\n",
      "231/361.0 loss: 0.6885862967063641 \n",
      "Epoch:  50\n",
      "232/361.0 loss: 0.6892855799249313 \n",
      "Epoch:  50\n",
      "233/361.0 loss: 0.6898426135890504 \n",
      "Epoch:  50\n",
      "234/361.0 loss: 0.6894942874604083 \n",
      "Epoch:  50\n",
      "235/361.0 loss: 0.6892652291867692 \n",
      "Epoch:  50\n",
      "236/361.0 loss: 0.6898150567263993 \n",
      "Epoch:  50\n",
      "237/361.0 loss: 0.6895649726150417 \n",
      "Epoch:  50\n",
      "238/361.0 loss: 0.6891095002326008 \n",
      "Epoch:  50\n",
      "239/361.0 loss: 0.6885379664599895 \n",
      "Epoch:  50\n",
      "240/361.0 loss: 0.6890726428308922 \n",
      "Epoch:  50\n",
      "241/361.0 loss: 0.6895714557367908 \n",
      "Epoch:  50\n",
      "242/361.0 loss: 0.68924171394772 \n",
      "Epoch:  50\n",
      "243/361.0 loss: 0.6896453360553647 \n",
      "Epoch:  50\n",
      "244/361.0 loss: 0.6902671490396772 \n",
      "Epoch:  50\n",
      "245/361.0 loss: 0.6908515558494785 \n",
      "Epoch:  50\n",
      "246/361.0 loss: 0.6911426661950857 \n",
      "Epoch:  50\n",
      "247/361.0 loss: 0.6917042201084476 \n",
      "Epoch:  50\n",
      "248/361.0 loss: 0.6921903677733547 \n",
      "Epoch:  50\n",
      "249/361.0 loss: 0.6924782888889313 \n",
      "Epoch:  50\n",
      "250/361.0 loss: 0.6921664146313155 \n",
      "Epoch:  50\n",
      "251/361.0 loss: 0.6918025179987862 \n",
      "Epoch:  50\n",
      "252/361.0 loss: 0.6914958951501508 \n",
      "Epoch:  50\n",
      "253/361.0 loss: 0.6912480724139476 \n",
      "Epoch:  50\n",
      "254/361.0 loss: 0.6915740106620041 \n",
      "Epoch:  50\n",
      "255/361.0 loss: 0.6912551773712039 \n",
      "Epoch:  50\n",
      "256/361.0 loss: 0.6919729674836541 \n",
      "Epoch:  50\n",
      "257/361.0 loss: 0.691444726184357 \n",
      "Epoch:  50\n",
      "258/361.0 loss: 0.691932766133754 \n",
      "Epoch:  50\n",
      "259/361.0 loss: 0.6914437488867686 \n",
      "Epoch:  50\n",
      "260/361.0 loss: 0.6917904254577169 \n",
      "Epoch:  50\n",
      "261/361.0 loss: 0.6920957244534529 \n",
      "Epoch:  50\n",
      "262/361.0 loss: 0.6922005795707268 \n",
      "Epoch:  50\n",
      "263/361.0 loss: 0.6924947836633885 \n",
      "Epoch:  50\n",
      "264/361.0 loss: 0.6922498084464164 \n",
      "Epoch:  50\n",
      "265/361.0 loss: 0.6926329391343253 \n",
      "Epoch:  50\n",
      "266/361.0 loss: 0.6923718985993318 \n",
      "Epoch:  50\n",
      "267/361.0 loss: 0.6925696950795045 \n",
      "Epoch:  50\n",
      "268/361.0 loss: 0.69280501191944 \n",
      "Epoch:  50\n",
      "269/361.0 loss: 0.6932778912561911 \n",
      "Epoch:  50\n",
      "270/361.0 loss: 0.6935174671926182 \n",
      "Epoch:  50\n",
      "271/361.0 loss: 0.6939236473511247 \n",
      "Epoch:  50\n",
      "272/361.0 loss: 0.6937198748082032 \n",
      "Epoch:  50\n",
      "273/361.0 loss: 0.6932908831721675 \n",
      "Epoch:  50\n",
      "274/361.0 loss: 0.6933964137597518 \n",
      "Epoch:  50\n",
      "275/361.0 loss: 0.6930187089719634 \n",
      "Epoch:  50\n",
      "276/361.0 loss: 0.6932501771389793 \n",
      "Epoch:  50\n",
      "277/361.0 loss: 0.6934532351631055 \n",
      "Epoch:  50\n",
      "278/361.0 loss: 0.6935839106105135 \n",
      "Epoch:  50\n",
      "279/361.0 loss: 0.6933828583785466 \n",
      "Epoch:  50\n",
      "280/361.0 loss: 0.6933480772683629 \n",
      "Epoch:  50\n",
      "281/361.0 loss: 0.6931114158731826 \n",
      "Epoch:  50\n",
      "282/361.0 loss: 0.6928268207678104 \n",
      "Epoch:  50\n",
      "283/361.0 loss: 0.6929569298952398 \n",
      "Epoch:  50\n",
      "284/361.0 loss: 0.6932047099397893 \n",
      "Epoch:  50\n",
      "285/361.0 loss: 0.693112490268854 \n",
      "Epoch:  50\n",
      "286/361.0 loss: 0.6929512416444173 \n",
      "Epoch:  50\n",
      "287/361.0 loss: 0.6932525872770283 \n",
      "Epoch:  50\n",
      "288/361.0 loss: 0.6930814898962793 \n",
      "Epoch:  50\n",
      "289/361.0 loss: 0.6932199517200733 \n",
      "Epoch:  50\n",
      "290/361.0 loss: 0.6935570573888693 \n",
      "Epoch:  50\n",
      "291/361.0 loss: 0.693654842776795 \n",
      "Epoch:  50\n",
      "292/361.0 loss: 0.6935947395022005 \n",
      "Epoch:  50\n",
      "293/361.0 loss: 0.6937956122719512 \n",
      "Epoch:  50\n",
      "294/361.0 loss: 0.6940437931125447 \n",
      "Epoch:  50\n",
      "295/361.0 loss: 0.6943018067930196 \n",
      "Epoch:  50\n",
      "296/361.0 loss: 0.6944508869639953 \n",
      "Epoch:  50\n",
      "297/361.0 loss: 0.6944095534366249 \n",
      "Epoch:  50\n",
      "298/361.0 loss: 0.6944808369894889 \n",
      "Epoch:  50\n",
      "299/361.0 loss: 0.6943532282114029 \n",
      "Epoch:  50\n",
      "300/361.0 loss: 0.6943306348648578 \n",
      "Epoch:  50\n",
      "301/361.0 loss: 0.6943942426845727 \n",
      "Epoch:  50\n",
      "302/361.0 loss: 0.6941335885831625 \n",
      "Epoch:  50\n",
      "303/361.0 loss: 0.6942534621216749 \n",
      "Epoch:  50\n",
      "304/361.0 loss: 0.6940447895253291 \n",
      "Epoch:  50\n",
      "305/361.0 loss: 0.6941801364125769 \n",
      "Epoch:  50\n",
      "306/361.0 loss: 0.6943613644143269 \n",
      "Epoch:  50\n",
      "307/361.0 loss: 0.6943132761236909 \n",
      "Epoch:  50\n",
      "308/361.0 loss: 0.6941483290835877 \n",
      "Epoch:  50\n",
      "309/361.0 loss: 0.6941425863773593 \n",
      "Epoch:  50\n",
      "310/361.0 loss: 0.6939653890309226 \n",
      "Epoch:  50\n",
      "311/361.0 loss: 0.6937343894671171 \n",
      "Epoch:  50\n",
      "312/361.0 loss: 0.6939782130832489 \n",
      "Epoch:  50\n",
      "313/361.0 loss: 0.6939802769642727 \n",
      "Epoch:  50\n",
      "314/361.0 loss: 0.6940906693064978 \n",
      "Epoch:  50\n",
      "315/361.0 loss: 0.6938793844060053 \n",
      "Epoch:  50\n",
      "316/361.0 loss: 0.6937900604885835 \n",
      "Epoch:  50\n",
      "317/361.0 loss: 0.6939147517741101 \n",
      "Epoch:  50\n",
      "318/361.0 loss: 0.6938606997642397 \n",
      "Epoch:  50\n",
      "319/361.0 loss: 0.6936957996338606 \n",
      "Epoch:  50\n",
      "320/361.0 loss: 0.6935312920641676 \n",
      "Epoch:  50\n",
      "321/361.0 loss: 0.6934711261195425 \n",
      "Epoch:  50\n",
      "322/361.0 loss: 0.6935747797275106 \n",
      "Epoch:  50\n",
      "323/361.0 loss: 0.6934424092372259 \n",
      "Epoch:  50\n",
      "324/361.0 loss: 0.6936450793192936 \n",
      "Epoch:  50\n",
      "325/361.0 loss: 0.6935360148274825 \n",
      "Epoch:  50\n",
      "326/361.0 loss: 0.6935089474788864 \n",
      "Epoch:  50\n",
      "327/361.0 loss: 0.6934001238607779 \n",
      "Epoch:  50\n",
      "328/361.0 loss: 0.6936516185661942 \n",
      "Epoch:  50\n",
      "329/361.0 loss: 0.6937835949839968 \n",
      "Epoch:  50\n",
      "330/361.0 loss: 0.693682203840273 \n",
      "Epoch:  50\n",
      "331/361.0 loss: 0.6939025481781328 \n",
      "Epoch:  50\n",
      "332/361.0 loss: 0.693992190711849 \n",
      "Epoch:  50\n",
      "333/361.0 loss: 0.6940542482687327 \n",
      "Epoch:  50\n",
      "334/361.0 loss: 0.6939440366047532 \n",
      "Epoch:  50\n",
      "335/361.0 loss: 0.6941115650392714 \n",
      "Epoch:  50\n",
      "336/361.0 loss: 0.6940486846762525 \n",
      "Epoch:  50\n",
      "337/361.0 loss: 0.6938347003516361 \n",
      "Epoch:  50\n",
      "338/361.0 loss: 0.6937174311781351 \n",
      "Epoch:  50\n",
      "339/361.0 loss: 0.6936433171524721 \n",
      "Epoch:  50\n",
      "340/361.0 loss: 0.6934502617704553 \n",
      "Epoch:  50\n",
      "341/361.0 loss: 0.6935849625464768 \n",
      "Epoch:  50\n",
      "342/361.0 loss: 0.6936969211428228 \n",
      "Epoch:  50\n",
      "343/361.0 loss: 0.6936661136704821 \n",
      "Epoch:  50\n",
      "344/361.0 loss: 0.6935529033342998 \n",
      "Epoch:  50\n",
      "345/361.0 loss: 0.6934508028402494 \n",
      "Epoch:  50\n",
      "346/361.0 loss: 0.6931419073676514 \n",
      "Epoch:  50\n",
      "347/361.0 loss: 0.6931990248033371 \n",
      "Epoch:  50\n",
      "348/361.0 loss: 0.6932992048796405 \n",
      "Epoch:  50\n",
      "349/361.0 loss: 0.693011395420347 \n",
      "Epoch:  50\n",
      "350/361.0 loss: 0.6928489697285187 \n",
      "Epoch:  50\n",
      "351/361.0 loss: 0.693002856082537 \n",
      "Epoch:  50\n",
      "352/361.0 loss: 0.6929308868332558 \n",
      "Epoch:  50\n",
      "353/361.0 loss: 0.6927301206831205 \n",
      "Epoch:  50\n",
      "354/361.0 loss: 0.6930358223512139 \n",
      "Epoch:  50\n",
      "355/361.0 loss: 0.6931674097026332 \n",
      "Epoch:  50\n",
      "356/361.0 loss: 0.6930162258842746 \n",
      "Epoch:  50\n",
      "357/361.0 loss: 0.6930225769567756 \n",
      "Epoch:  50\n",
      "358/361.0 loss: 0.6928702802047092 \n",
      "Epoch:  50\n",
      "359/361.0 loss: 0.6929887309670448 \n",
      "Epoch:  50\n",
      "360/361.0 loss: 0.6931094043472797 \n"
     ]
    }
   ],
   "source": [
    "#training(1, 50, \"fake_news_bert2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WUg0c5edsug_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
