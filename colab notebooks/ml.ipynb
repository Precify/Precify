{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scrapper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXB4SlvrYYyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive \n",
        "#drive.mount('/content/gdrive') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARN7a36TYYwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%cd /content/gdrive/My\\ Drive/Colab\\ Notebooks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTVb7JlyYsf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "server = \"stark-anchorage-45962.herokuapp.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncOjPh_D_v7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "13c1b0eb-f5f6-43b2-eece-e4d99a62bafe"
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.38.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.12.38)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.15.38)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.5)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4g-SbCc_viQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "4631d045-32c5-4821-b960-64507a04d0be"
      },
      "source": [
        "!pip install pytorch-nlp"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (1.18.2)\n",
            "Installing collected packages: pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo5XPnkf_yxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "50aa994a-8a6a-49ba-9612-77e5312c846a"
      },
      "source": [
        "!pip install gdown==3.6.0"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gdown==3.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/12/33/e9f21d0b3f85804ca570d124fb7a80c12a99948ff495cf54dfb72f18bf9e/gdown-3.6.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown==3.6.0) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown==3.6.0) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown==3.6.0) (4.38.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown==3.6.0) (3.0.4)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.6.0-cp36-none-any.whl size=5238 sha256=2aeaccd13ae2baf2aadebafcd4482f256de9caaabea420a1c372b86f5bcb6ef9\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/90/fa/25654eb65da3e6da7752db71a164e0eb8f7a6fb4335eeb46ab\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "Successfully installed gdown-3.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxLrJh94_3PL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "763f069a-9ef3-4033-a72e-cc53bd9d4d4c"
      },
      "source": [
        "#filename = \"https://drive.google.com/file/d/1mHW0zXK6gzJs0nQUle_yrWqiAHKOORUI/view\"\n",
        "#filename2 = https://drive.google.com/open?id=1-0hjozQqjknhLIm67uhKdFBJUHNfiIrD\n",
        "#fid = \"1mHW0zXK6gzJs0nQUle_yrWqiAHKOORUI\"\n",
        "fid = \"1-0hjozQqjknhLIm67uhKdFBJUHNfiIrD\"\n",
        "!gdown https://drive.google.com/uc?id={fid}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-0hjozQqjknhLIm67uhKdFBJUHNfiIrD\n",
            "To: /content/fake_news_bert2.pt\n",
            "438MB [00:06, 72.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKIdA1YUdf8f",
        "colab_type": "code",
        "outputId": "a7cee088-ba27-4463-8f3f-e9ddd7115609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "!pip install newspaper3k"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 16.8MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 2.7MB/s \n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (7.0.0)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Collecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 9.5MB/s \n",
            "\u001b[?25hCollecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.8.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/0e/9ab599d6e78f0340bb1d1e28ddeacb38c8bb7f91a1b0eae9a24e9603782f/tldextract-2.2.2-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.21.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.12.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.8)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/23/9c/6e63c23c39e53d3df41c77a3d05a49a42c4e1383a6d2a5e3233161b89dbf/requests_file-1.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (46.1.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2020.4.5.1)\n",
            "Building wheels for collected packages: feedfinder2, tinysegmenter, feedparser, jieba3k\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3357 sha256=58ac8f23155544b4b1b0426f2019fb23e3c0e9166cc0219332515632ad03d4ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13539 sha256=651f977bd0a46292b6f5b65b7d11180bf098f4bb668de323586f759a0c73cdf1\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedparser: filename=feedparser-5.2.1-cp36-none-any.whl size=44940 sha256=72e077c35ab9a2be7a5b2375bd6c7da23a277173d5e86c8e7de7b30cc3ac71d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398406 sha256=1b0422a13e0811c43370f21d29443b6017e0e35e59bb76c01030b7c6dc70aa2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "Successfully built feedfinder2 tinysegmenter feedparser jieba3k\n",
            "Installing collected packages: feedfinder2, cssselect, tinysegmenter, feedparser, jieba3k, requests-file, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-5.2.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.4.3 tinysegmenter-0.3 tldextract-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ67auEnHLg7",
        "colab_type": "code",
        "outputId": "14fa814f-1d60-4c19-d715-9c05ba0571cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLu_GXPEUuYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import urllib.request\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import bs4\n",
        "from urllib.parse import quote\n",
        "\n",
        "from newspaper import Article\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "\n",
        "import http.client\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import time\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sj9U_4g_5-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "717ddb06-81b5-4518-85fe-518fddcb585a"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import torch.nn as nn\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
        "import torch\n",
        "from torchnlp.datasets import imdb_dataset\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter \n",
        "import http.client\n",
        "import json\n",
        "\n",
        "import random\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import time\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F108LPx-dafp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_lst_all = [\"https://economictimes.indiatimes.com/news/politics-and-nation/coronavirus-cases-in-india-live-news-latest-updates-april8/liveblog/75038326.cms\", \"https://www.pharmaceutical-technology.com/special-focus/covid-19/coronavirus-covid-19-outbreak-latest-information-news-and-updates/\", \"https://www.business-standard.com/article/current-affairs/coronavirus-live-updates-covid-19-cases-in-india-global-death-toll-state-wise-delhi-maharasthra-tablighi-nizamuddin-lockdown-extension-latest-news-120040800236_1.html\", \"https://timesofindia.indiatimes.com/india/coronavirus-india-cases-live-news-updates-lockdown-in-india-likely-to-be-extended/liveblog/75074630.cms\"]\n",
        "\n",
        "url_lst_statewise = [\"https://timesofindia.indiatimes.com/india\"]\n",
        "\n",
        "url_lst_citywise = [\"https://timesofindia.indiatimes.com/city\"]\n",
        "\n",
        "keywords = [\"corona\", \"coronavirus\", \"lockdown\", \"covid-19\", \"covid19\", \"masks\", \"handwash\", \"mask\", \"infection\", \"staysafe\", \"quarantine\", \"stayathome\", \"pandemic\", \"shutdown\"]\n",
        "\n",
        "apikey = \"c8c54678d99e43d9b11a09d74e8dfa51\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DATacnmK_8_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(link_conn) :\n",
        "    try :\n",
        "        conn = http.client.HTTPSConnection(link_conn)\n",
        "    except :\n",
        "        conn = http.client.HTTPSConnection('localhost:5000')\n",
        "    headers = {'Content-type': 'application/json'}\n",
        "    conn.request('GET', '/getAllUntestedPosts', None, headers)\n",
        "    response = conn.getresponse()\n",
        "    return response.read().decode()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1k4aCnN__Pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, tokens, masks=None):\n",
        "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYEBUtRWABuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(batch_size, epoch_size, filename) :\n",
        "    '''very unethical way of loading and traing the data in same function'''\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    train_data, test_data = imdb_dataset(train=True, test=True)\n",
        "    df = pd.read_csv(\"./fake-news/fake.csv\")\n",
        "    df = df[['text', 'type']]\n",
        "    #print(len(df))\n",
        "\n",
        "    #print(Counter(df['type'].values))\n",
        "\n",
        "    df = df[df['type'].isin(['fake', 'satire'])]\n",
        "    df.dropna(inplace = True)\n",
        "    df_fake = df[df['type'] == 'fake'] \n",
        "    df_statire = df[df['type'] == 'satire'] \n",
        "    df_statire = df_statire.sample(n=len(df_fake))\n",
        "    df = df_statire.append(df_fake)\n",
        "    df = df.sample(frac=1, random_state = 24).reset_index(drop=True)\n",
        "\n",
        "    #print(Counter(df['type'].values))\n",
        "\n",
        "    train_data = df.head(19)\n",
        "    test_data = df.tail(19)\n",
        "\n",
        "    #print(train_data)\n",
        "    train_data = [{'text': text, 'type': type_data } for text in list(train_data['text']) for type_data in list(train_data['type'])]\n",
        "    test_data = [{'text': text, 'type': type_data } for text in list(test_data['text']) for type_data in list(test_data['type'])]\n",
        "\n",
        "    train_texts, train_labels = list(zip(*map(lambda d: (d['text'], d['type']), train_data)))\n",
        "    test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['type']), test_data)))\n",
        "\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], train_texts))\n",
        "    test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], test_texts))\n",
        "\n",
        "    train_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, train_tokens))\n",
        "    test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))\n",
        "\n",
        "\n",
        "\n",
        "    train_tokens_ids = pad_sequences(train_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "    test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "\n",
        "\n",
        "    train_y = np.array(train_labels) == 'fake'\n",
        "    test_y = np.array(test_labels) == 'fake'\n",
        "    \n",
        "    BATCH_SIZE = batch_size\n",
        "    EPOCHS = epoch_size\n",
        "\n",
        "\n",
        "    train_masks = [[float(i > 0) for i in ii] for ii in train_tokens_ids]\n",
        "    test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
        "    train_masks_tensor = torch.tensor(train_masks)\n",
        "    test_masks_tensor = torch.tensor(test_masks)\n",
        "\n",
        "    train_tokens_tensor = torch.tensor(train_tokens_ids)\n",
        "    train_y_tensor = torch.tensor(train_y.reshape(-1, 1)).float()\n",
        "    test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "    test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
        "    train_dataset =  torch.utils.data.TensorDataset(train_tokens_tensor, train_masks_tensor, train_y_tensor)\n",
        "    train_sampler =  torch.utils.data.RandomSampler(train_dataset)\n",
        "    train_dataloader =  torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "    test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "    test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
        "    test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    bert_clf = BertBinaryClassifier()\n",
        "    optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
        "    bert_clf = bert_clf.to(device)\n",
        "    for epoch_num in range(EPOCHS):\n",
        "        bert_clf.train()\n",
        "        train_loss = 0\n",
        "        for step_num, batch_data in enumerate(train_dataloader):\n",
        "            token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "            token_ids = token_ids.to(device)\n",
        "            masks = masks.to(device)\n",
        "            labels = labels.to(device)\n",
        "            probas = bert_clf(token_ids, masks)\n",
        "            loss_func = nn.BCELoss()\n",
        "            batch_loss = loss_func(probas, labels)\n",
        "            train_loss += batch_loss.item()\n",
        "            bert_clf.zero_grad()\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "            print('Epoch: ', epoch_num + 1)\n",
        "            print(\"\\r\" + \"{0}/{1} loss: {2} \".format(step_num, len(train_data) / BATCH_SIZE, train_loss / (step_num + 1)))\n",
        "\n",
        "    torch.save(bert_clf, filename)\n",
        "    return  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm5NGiCNAEBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testing(df, filename) :\n",
        "    \n",
        "    #input\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    l = len(df)\n",
        "    lst = []\n",
        "    if(l%2 == 1):\n",
        "        for i in range(l) :\n",
        "            if(i%2 == 1) :\n",
        "                lst.append('fake')\n",
        "            else:\n",
        "                lst.append('satire')\n",
        "    else :\n",
        "        for i in range(l) :\n",
        "            if(i%2 == 0) :\n",
        "                lst.append('fake')\n",
        "            else:\n",
        "                lst.append('satire')\n",
        "    df['type'] = lst\n",
        "    test_data = df\n",
        "    test_data1 = [{'text': text, 'type': \"\"} for text in list(test_data['text']) ]\n",
        "\n",
        "    i = 0\n",
        "    for type_data in list(test_data['type']) :\n",
        "        test_data1[i]['type'] = type_data\n",
        "        i = i + 1\n",
        "        \n",
        "    test_data = test_data1\n",
        "    test_texts, test_labels = list(zip(*map(lambda d: (d['text'], d['type']), test_data)))\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:511], test_texts))\n",
        "    test_tokens_ids = list(map(tokenizer.convert_tokens_to_ids, test_tokens))\n",
        "    test_tokens_ids = pad_sequences(test_tokens_ids, maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
        "    test_y = np.array(test_labels) == 'fake'\n",
        "    test_y = torch.from_numpy(np.array(test_y, dtype=np.uint8))\n",
        "    \n",
        "    BATCH_SIZE = 1\n",
        "    \n",
        "    test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
        "    test_masks_tensor = torch.tensor(test_masks)\n",
        "    test_tokens_tensor = torch.tensor(test_tokens_ids)\n",
        "    test_y_tensor = torch.tensor(test_y.reshape(-1, 1)).float()\n",
        "    test_dataset =  torch.utils.data.TensorDataset(test_tokens_tensor, test_masks_tensor, test_y_tensor)\n",
        "    test_sampler =  torch.utils.data.SequentialSampler(test_dataset)\n",
        "    test_dataloader =  torch.utils.data.DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "    bert_clf = BertBinaryClassifier()\n",
        "    optimizer = torch.optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
        "    bert_clf = torch.load(filename)\n",
        "    bert_clf = bert_clf.to(device)\n",
        "    bert_clf.eval()\n",
        "    bert_predicted = []\n",
        "    all_logits = []\n",
        "    lst = []\n",
        "    with torch.no_grad():\n",
        "        for step_num, batch_data in enumerate(test_dataloader):\n",
        "\n",
        "            token_ids, masks, labels = tuple(t for t in batch_data)\n",
        "            token_ids = token_ids.to(device)\n",
        "            masks = masks.to(device)\n",
        "            labels = labels.to(device)\n",
        "            logits = bert_clf(token_ids, masks)\n",
        "            logits = logits.to(device)\n",
        "            \n",
        "            loss_func = nn.BCELoss()\n",
        "            loss = loss_func(logits, labels)\n",
        "            numpy_logits = logits.cpu().detach().numpy()\n",
        "            lst.append(numpy_logits)\n",
        "\n",
        "            bert_predicted += list(numpy_logits[:, 0])\n",
        "            all_logits += list(numpy_logits[:, 0])\n",
        "\n",
        "    return lst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oue9J4MIAGhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''def fake_post(article, score, link_conn) :\n",
        "    try :\n",
        "        conn = http.client.HTTPSConnection(link_conn)\n",
        "    except :\n",
        "        conn = http.client.HTTPSConnection('localhost:5000')\n",
        "    headers = {'Content-type': 'application/json'}\n",
        "    data = article\n",
        "    if(score > 0.5) :\n",
        "      data['fake'] = \"True\"\n",
        "    else:\n",
        "      data['fake'] = \"False\"\n",
        "    data['fakeness'] = str(score)\n",
        "    json_data = json.dumps(data)\n",
        "    conn.request('POST', '/fakePost', json_data, headers)\n",
        "    response = conn.getresponse()\n",
        "    print(response.read().decode())\n",
        "    return\n",
        "  \n",
        "def true_post(article, score, link_conn) :\n",
        "    try :\n",
        "        conn = http.client.HTTPSConnection(link_conn)\n",
        "    except :\n",
        "        conn = http.client.HTTPSConnection('localhost:5000')\n",
        "    headers = {'Content-type': 'application/json'}\n",
        "    data = article\n",
        "    if(score > 0.5) :\n",
        "      data['fake'] = \"True\"\n",
        "    else:\n",
        "      data['fake'] = \"False\"\n",
        "    data['fakeness'] = str(score)\n",
        "    json_data = json.dumps(data)\n",
        "    conn.request('POST', '/testedPost', json_data, headers)\n",
        "    response = conn.getresponse()\n",
        "    print(response.read().decode())\n",
        "    return'''\n",
        "\n",
        "\n",
        "def display(article, score, link_conn) :\n",
        "    try :\n",
        "        conn = http.client.HTTPSConnection(link_conn)\n",
        "    except :\n",
        "        conn = http.client.HTTPSConnection('localhost:5000')\n",
        "    headers = {'Content-type': 'application/json'}\n",
        "    data = dict()\n",
        "    data['url'] = article['url']\n",
        "    data['fakeness'] = str(score)\n",
        "    json_data = json.dumps(data)\n",
        "    conn.request('POST', '/fakePost', json_data, headers)\n",
        "    response = conn.getresponse()\n",
        "    print(response.read().decode())\n",
        "    return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoYw2SghAIw4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cc2851f8-1057-4936-fe3b-00f13f7cdac0"
      },
      "source": [
        "def using_bert(lst_bert, filename, link_conn) :\n",
        "    lst = []\n",
        "    original = []\n",
        "    for t in lst_bert :\n",
        "        try:\n",
        "          lst.append(t['text'])\n",
        "          original.append(t)\n",
        "        except:\n",
        "          continue\n",
        "    df = pd.DataFrame(lst, columns=[\"text\"])\n",
        "    scores = testing(df, filename)\n",
        "    #scores = scores.tolist()\n",
        "    '''print(len(scores))\n",
        "    print(len(original))\n",
        "    print(len(lst))\n",
        "    print(len(lst_bert))'''\n",
        "    i = 0\n",
        "    #limit = 0\n",
        "    for article in original :\n",
        "        #limit = limit + 1\n",
        "        #if(limit == 20) :\n",
        "        #    tiime.sleep(61)\n",
        "        #    limit = 0\n",
        "        '''if(scores[i] > 0.5 ) :\n",
        "            fake_post(article, scores[i], link_conn)\n",
        "        else :\n",
        "            true_post(article, scores[i], link_conn)'''\n",
        "        #print(scores[i][0][0])\n",
        "        display(article, str(scores[i][0][0]), link_conn)\n",
        "        i = i + 1\n",
        "    return\n",
        "            \n",
        "'''def malicious_url_detector(lst_url, link_conn) :\n",
        "    lst = []\n",
        "    for t in lst_url :\n",
        "        lst.append(t['url'])\n",
        "    df = pd.DataFrame(lst, columns=[\"url\"])\n",
        "    test_data = df['url']\n",
        "    data = pd.read_csv(\"./data/url.csv\")\n",
        "    y = data[\"label\"]\n",
        "    url_list = data[\"url\"]\n",
        "    # Using Tokenizer\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    # Store vectors into X variable as Our XFeatures\n",
        "    X = vectorizer.fit_transform(url_list)\n",
        "    # Split into training and testing dataset 80:20 ratio\n",
        "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    # Model Building using logistic regression\n",
        "    logit = LogisticRegression()\n",
        "    logit.fit(X, y)\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    test_data = vectorizer.fit_transform(lst)\n",
        "    scores = logit.predict(test_data)\n",
        "    i = 0\n",
        "    limit = 0\n",
        "    for article in lst_bert :\n",
        "        limit = limit + 1\n",
        "        if(limit == 20) :\n",
        "            time.sleep(61)\n",
        "            limit = 0\n",
        "        if(scores[i] > 0.5 ) :\n",
        "            fake_post(article, scores[i], link_conn)\n",
        "        else :\n",
        "            true_post(article, scores[i], link_conn)\n",
        "        i = i + 1\n",
        "    return'''\n",
        "       "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def malicious_url_detector(lst_url, link_conn) :\\n    lst = []\\n    for t in lst_url :\\n        lst.append(t[\\'url\\'])\\n    df = pd.DataFrame(lst, columns=[\"url\"])\\n    test_data = df[\\'url\\']\\n    data = pd.read_csv(\"./data/url.csv\")\\n    y = data[\"label\"]\\n    url_list = data[\"url\"]\\n    # Using Tokenizer\\n    vectorizer = TfidfVectorizer()\\n    # Store vectors into X variable as Our XFeatures\\n    X = vectorizer.fit_transform(url_list)\\n    # Split into training and testing dataset 80:20 ratio\\n    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n    # Model Building using logistic regression\\n    logit = LogisticRegression()\\n    logit.fit(X, y)\\n    vectorizer = TfidfVectorizer()\\n    test_data = vectorizer.fit_transform(lst)\\n    scores = logit.predict(test_data)\\n    i = 0\\n    limit = 0\\n    for article in lst_bert :\\n        limit = limit + 1\\n        if(limit == 20) :\\n            time.sleep(61)\\n            limit = 0\\n        if(scores[i] > 0.5 ) :\\n            fake_post(article, scores[i], link_conn)\\n        else :\\n            true_post(article, scores[i], link_conn)\\n        i = i + 1\\n    return'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZC6VPDzlVAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def connection(conn, link, author, source, text, location) :\n",
        "    headers = {'Content-type': 'application/json'}\n",
        "    data = {'url': str(link), 'author' : str(author), 'source' : str(source), 'text' : str(text), 'location' : str(location)}\n",
        "    json_data = json.dumps(data)\n",
        "    conn.request('POST', '/addPost', json_data, headers)\n",
        "    response = conn.getresponse()\n",
        "    print(response.read().decode())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUIsT6l1lf9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def allNews() :\n",
        "    articles = []\n",
        "    urls = []\n",
        "    #response = requests.get(url_lst_all[0], allow_redirects = True)\n",
        "    #soup = BeautifulSoup(response.text)\n",
        "    '''r = requests.get(url_lst_all[0]) \n",
        "    soup = BeautifulSoup(r.content, 'html5lib') \n",
        "    #text1 = soup.findAll('h3', class_ = \"\")\n",
        "    text2 = soup.findAll('div', class_ = \"blogSysn\")\n",
        "    #text3 = soup.findAll('span')\n",
        "    for text in text2 :\n",
        "        if(len(text.text) > 50):\n",
        "            articles.append(text.text)\n",
        "            \n",
        "    r = requests.get(url_lst_all[1]) \n",
        "    soup = BeautifulSoup(r.content, 'html5lib') \n",
        "    #text1 = soup.findAll('h3')\n",
        "    text2 = soup.findAll('a')\n",
        "    text3 = soup.findAll('li', class_ = \"row\")\n",
        "    #text4 = soup.findAll('div', class_ = \"large-9 columns\")\n",
        "    for txt in text3:\n",
        "        regex = re.compile(r'[\\n\\r\\t]')\n",
        "        s = regex.sub(\" \", txt.text)\n",
        "        articles.append(s)\n",
        "    for text in text2 :\n",
        "        flag = 0\n",
        "        blog = \"\"\n",
        "        for ch in text:\n",
        "            if(isinstance(ch, bs4.element.NavigableString)) :\n",
        "                blog = blog + ch\n",
        "        if(len(blog) > 25) :\n",
        "            articles.append(blog)'''\n",
        "        \n",
        "\n",
        "    r = requests.get(url_lst_all[2]) \n",
        "    soup = BeautifulSoup(r.content, 'html5lib') \n",
        "    tags = soup.findAll('a')\n",
        "    i = 0\n",
        "    for tag in tags:\n",
        "        try :\n",
        "            if(tag['target'] == \"_blank\") :\n",
        "                if(i < 3) :\n",
        "                    i = i + 1\n",
        "                    continue\n",
        "                else :\n",
        "                    if(len(tag.text) > 50) :\n",
        "                        my_str = tag.text\n",
        "                        _RE_COMBINE_WHITESPACE = re.compile(r\"(?a:\\s+)\")\n",
        "                        _RE_STRIP_WHITESPACE = re.compile(r\"(?a:^\\s+|\\s+$)\")\n",
        "\n",
        "                        my_str = _RE_COMBINE_WHITESPACE.sub(\" \", my_str)\n",
        "                        my_str = _RE_STRIP_WHITESPACE.sub(\"\", my_str)\n",
        "                        for word in keywords:\n",
        "                          if word in my_str.lower():\n",
        "                            articles.append(my_str)\n",
        "                            g = \"https://www.business-standard.com\" + tag['href']\n",
        "                            urls.append(g)\n",
        "                            break\n",
        "        except:\n",
        "            continue\n",
        "            \n",
        "    url = ('http://newsapi.org/v2/top-headlines?'\n",
        "       'country=in&'\n",
        "       'apiKey=c8c54678d99e43d9b11a09d74e8dfa51')\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    for article in data['articles'] :\n",
        "        for word in keywords:\n",
        "            try :\n",
        "                if word in article['content'].lower():\n",
        "                    articles.append(article['description'])\n",
        "                    urls.append(article['url'])\n",
        "            except :\n",
        "                continue\n",
        "    \n",
        "    r = requests.get(url_lst_all[3]) \n",
        "    soup = BeautifulSoup(r.text, 'html5lib') \n",
        "    tags = soup.findAll('script')\n",
        "    data = json.loads(tags[1].text, strict=False)\n",
        "    for t in data['liveBlogUpdate'] :\n",
        "        for word in keywords:\n",
        "            if word in t['headline'].lower() :\n",
        "                articles.append(t['headline'])\n",
        "                urls.append(t['url'])\n",
        "                break\n",
        "    \n",
        "    return articles, urls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1rA3im8ljlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def citywise() :\n",
        "    prefix = \"https://timesofindia.indiatimes.com\"\n",
        "    covid_links = []\n",
        "    #covid_citywise = []\n",
        "    response = requests.get(url_lst_citywise[0], allow_redirects = True)\n",
        "    soup = BeautifulSoup(response.text)\n",
        "    one_a_tag = soup.findAll('a')\n",
        "    #print(one_a_tag)\n",
        "    no_cities = 67\n",
        "    index = 0\n",
        "    cities_lst = []\n",
        "    for line in one_a_tag :\n",
        "            if(index > no_cities) :\n",
        "                break\n",
        "            try:\n",
        "                link = line['href']\n",
        "                if(link[:6] == \"/city/\") :\n",
        "                    cities_lst.append(link)\n",
        "                    index = index + 1\n",
        "            except:\n",
        "                continue\n",
        "    #print(cities_lst)\n",
        "    articles_citywise = []\n",
        "    i = 0\n",
        "    for url in cities_lst:\n",
        "        covid_citywise = []\n",
        "        articles_lst = []\n",
        "        url_ = prefix + url\n",
        "        #print(url_)\n",
        "        words = url_.split(\"/\")\n",
        "        #print(words[-1])\n",
        "        #covid_citywise.append(words[-1])\n",
        "        articles_lst.append(words[-1])\n",
        "        length_ = len(url_)\n",
        "        length = len(url)\n",
        "        #print(url_)\n",
        "        response = requests.get(url_, allow_redirects = True)\n",
        "        soup = BeautifulSoup(response.text)\n",
        "        one_a_tag = soup.findAll('a')\n",
        "        for link in one_a_tag :\n",
        "            try :\n",
        "                if(link['href'][-4:] == \".cms\") :\n",
        "                    if(link['href'][:length] == url):\n",
        "                        temp = prefix + link['href']\n",
        "                        articles_lst.append(temp)\n",
        "                    elif(link['href'][:length_] == url_):\n",
        "                        articles_lst.append(link['href'])\n",
        "            except :\n",
        "                continue\n",
        "        #for ele in articles_lst :\n",
        "            #print(ele)\n",
        "        #break\n",
        "        articles_citywise.append(articles_lst)\n",
        "        #i = i + 1\n",
        "        covid_links = []\n",
        "        locations = []\n",
        "        title = []\n",
        "        content = []\n",
        "        urls = []\n",
        "        authors = []\n",
        "        sources = []\n",
        "    #print(articles_citywise)\n",
        "    #return\n",
        "    #from newspaper import Article\n",
        "    for articles_lst in articles_citywise :\n",
        "        covid_citywise = []\n",
        "        i = 0\n",
        "        for link in articles_lst:\n",
        "            #print(link)\n",
        "            if(i == 0) :\n",
        "                loc = link\n",
        "                print(loc)\n",
        "                i = i + 1\n",
        "                continue\n",
        "            try :\n",
        "                article = Article(link)\n",
        "                article.download()\n",
        "                article.parse()\n",
        "                article.nlp()\n",
        "                for word in keywords:\n",
        "                    if word in article.text.lower() :\n",
        "                        locations.append(loc)\n",
        "                        title.append(article.title)\n",
        "                        content.append(article.summary)\n",
        "                        urls.append(link)\n",
        "                        if(len(article.authors) != 0):\n",
        "                          authors.append(article.authors)\n",
        "                        else:\n",
        "                          authors.append(\"\")\n",
        "                        sources.append(article.source_url)\n",
        "                        #print(link)\n",
        "                        #print(article.title)\n",
        "                        #print(article.summary)\n",
        "                        break\n",
        "            except :\n",
        "                continue\n",
        "    \n",
        "        #break\n",
        "        #covid_links.append(covid_citywise)\n",
        "    data = dict()\n",
        "    data[\"title\"] = title\n",
        "    data[\"content\"] = content\n",
        "    data[\"location\"] = locations\n",
        "    data['url'] = urls\n",
        "    data['author'] = authors\n",
        "    data['source'] = sources\n",
        "    #with open(\"./data_scrapper/citywise.json\", 'w') as fh:\n",
        "    #    fh.write(json.dumps(data))\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY2IgiL7lmcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def statewise() :\n",
        "    prefix = \"https://timesofindia.indiatimes.com\"\n",
        "    #covid_links = []\n",
        "    response = requests.get(url_lst_statewise[0], allow_redirects = True)\n",
        "    soup = BeautifulSoup(response.text)\n",
        "    data = soup.findAll('meta')\n",
        "    links_lst =[]\n",
        "    i = -1\n",
        "    for one in data :\n",
        "        try:\n",
        "            if(one['itemprop'] == \"url\") :\n",
        "                url = str(one['content']).split('/')\n",
        "                if(url[-2] == \"india\") :\n",
        "                    i = i + 1\n",
        "                    if(i == 0) :\n",
        "                        continue\n",
        "                    else :\n",
        "                        links_lst.append(str(one['content']))\n",
        "        except:\n",
        "            continue\n",
        "    #print(links_lst)\n",
        "    locations = []\n",
        "    title = []\n",
        "    content = []\n",
        "    urls = []\n",
        "    authors = []\n",
        "    sources = []\n",
        "    for link in links_lst :\n",
        "        #print(link)\n",
        "        #covid_statewise = []\n",
        "        parser = link.split(\"/\")\n",
        "        #covid_statewise.append(parser[-1])\n",
        "        loc = parser[-1]\n",
        "        r = requests.get(link) \n",
        "        print(loc)\n",
        "        soup = BeautifulSoup(r.content, 'html5lib') \n",
        "        #tags = soup.findAll('script')\n",
        "        tags_ = soup.findAll('a')\n",
        "        #i = 0\n",
        "        for tag in tags_ :\n",
        "            try :\n",
        "                if(tag[\"hid\"] is not None) :\n",
        "                    #print(tag)\n",
        "                    article = Article(prefix + tag['href'])\n",
        "                    article.download()\n",
        "                    article.parse()\n",
        "                    article.nlp()\n",
        "                    for word in keywords:\n",
        "                        if word in article.text.lower() :\n",
        "                            locations.append(loc)\n",
        "                            title.append(article.title)\n",
        "                            content.append(article.summary)\n",
        "                            urls.append(prefix + tag['href'])\n",
        "                            if(len(article.authors) != 0):\n",
        "                              authors.append(article.authors)\n",
        "                            else:\n",
        "                              authors.append(\"\")\n",
        "                            sources.append(article.source_url)\n",
        "                            #print(article.title)\n",
        "                            #print(article.summary)\n",
        "                            #print(\"yes\")\n",
        "                            break\n",
        "                    \n",
        "            except:\n",
        "                continue\n",
        "        #break          \n",
        "    data = dict()\n",
        "    data[\"title\"] = title\n",
        "    data[\"content\"] = content\n",
        "    data[\"location\"] = locations\n",
        "    data['url'] = urls\n",
        "    data['author'] = authors\n",
        "    data['source'] = sources\n",
        "    #print(data)\n",
        "    #with open(\"./data_scrapper/statewise.json\", 'w') as fh:\n",
        "    #    fh.write(json.dumps(data))\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7do1i6tlprY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#all india news\n",
        "def get_all_news() :\n",
        "  articles, urls = allNews()\n",
        "  conn = http.client.HTTPSConnection(server)\n",
        "  #limit = 0\n",
        "  i = 0\n",
        "  for article in articles:\n",
        "      connection(conn, urls[i], \"\", \"\", article, \"india\")\n",
        "      i = i + 1\n",
        "      #limit = limit + 1\n",
        "      #if(limit == 20) :\n",
        "      #    time.sleep(61)\n",
        "      #    limit = 0\n",
        "      #    conn = http.client.HTTPSConnection(server)\n",
        "      #print(article)\n",
        "      #print(\"\")\n",
        "      #break\n",
        "  #convert set of strings into json\n",
        "  data = dict()\n",
        "  data['articles'] = articles\n",
        "  data['url'] = urls\n",
        "  #with open(\"./data_scrapper/all.json\", 'w') as fh:\n",
        "  #    fh.write(json.dumps(data))\n",
        "  return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJXxi4Wxl1ZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#statewise\n",
        "def get_statewise_news() :\n",
        "  data = statewise()\n",
        "  #title = data[\"title\"] \n",
        "  content = data[\"content\"] \n",
        "  locations = data[\"location\"]  \n",
        "  urls = data['url'] \n",
        "  authors = data['author']  \n",
        "  sources = data['source'] \n",
        "  l = len(urls)\n",
        "  #limit = 0\n",
        "  #print(data)\n",
        "  print(l)\n",
        "  conn = http.client.HTTPSConnection(server)\n",
        "  for j in range(l) :\n",
        "    connection(conn, urls[j], authors[j], sources[j], content[j], locations[j])\n",
        "    #limit = limit + 1\n",
        "    #if(limit == 20) :\n",
        "    #    time.sleep(61)\n",
        "    #    limit = 0\n",
        "    #    conn = http.client.HTTPSConnection(server)\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aat9AdzOl1W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#citywise\n",
        "def get_citywise_news() :\n",
        "  data = citywise()\n",
        "  #title = data[\"title\"] \n",
        "  content = data[\"content\"] \n",
        "  locations = data[\"location\"]  \n",
        "  urls = data['url'] \n",
        "  authors = data['author']  \n",
        "  sources = data['source'] \n",
        "  l = len(urls)\n",
        "  #limit = 0\n",
        "  conn = http.client.HTTPSConnection(server)\n",
        "  for j in range(l) :\n",
        "    connection(conn, urls[j], authors[j], sources[j], content[j], locations[j])\n",
        "    #limit = limit + 1\n",
        "    #if(limit == 20) :\n",
        "    #    time.sleep(61)\n",
        "    #    limit = 0\n",
        "    #   conn = http.client.HTTPSConnection(server)\n",
        "  return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kimkxdfZo6Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scrapper() :\n",
        "  get_all_news()\n",
        "  get_statewise_news()\n",
        "  get_citywise_news()\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZVWIYQxAMrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fake_news_detector() :\n",
        "  data = get_data(server) \n",
        "  data = json.loads(data)\n",
        "  lst_bert = []\n",
        "  #lst_url = []\n",
        "  for article in data:\n",
        "    lst_bert.append(article)\n",
        "  if(len(lst_bert) != 0):\n",
        "      #using_bert(lst_bert, \"/content/fake_news_bert.pt\", server)\n",
        "      using_bert(lst_bert, \"./fake_news_bert2.pt\", server)\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRAeyzITIYpl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08de24b9-6efe-41c5-f6c2-d56b4462600f"
      },
      "source": [
        "while(1) :\n",
        "  scrapper()\n",
        "  fake_news_detector()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1\n",
            "\n",
            "0.5017843384999504\n",
            "\n",
            "0.3973785097433934\n",
            "\n",
            "-1\n",
            "\n",
            "0.17782224242516143\n",
            "\n",
            "-1\n",
            "\n",
            "0.2546423786181662\n",
            "\n",
            "0.2503653319016115\n",
            "\n",
            "0.08561971483671527\n",
            "\n",
            "-1\n",
            "\n",
            "0.3665992148993583\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.8777034251947521\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.9359453751119622\n",
            "\n",
            "0.9182560763971985\n",
            "\n",
            "-1\n",
            "\n",
            "0.7694755936520643\n",
            "\n",
            "0.07797819705132003\n",
            "\n",
            "-1\n",
            "\n",
            "0.7207578750898236\n",
            "\n",
            "0.8947561703791825\n",
            "\n",
            "0.10990078457977137\n",
            "\n",
            "-1\n",
            "\n",
            "0.45267326879244385\n",
            "\n",
            "0.17928877559599776\n",
            "\n",
            "-1\n",
            "\n",
            "0.530804981902052\n",
            "\n",
            "0.5530908312039823\n",
            "\n",
            "0.36302042842384297\n",
            "\n",
            "0.02077476596368344\n",
            "\n",
            "0.9126893426688613\n",
            "\n",
            "0.24935028566315387\n",
            "\n",
            "0.3115058422208472\n",
            "\n",
            "0.5485804256139712\n",
            "\n",
            "0.3452677197903853\n",
            "\n",
            "0.18301520829923712\n",
            "\n",
            "0.9807258462245472\n",
            "\n",
            "0.9168274672381035\n",
            "\n",
            "maharashtra\n",
            "delhi\n",
            "karnataka\n",
            "tamil-nadu\n",
            "telangana\n",
            "uttar-pradesh\n",
            "west-bengal\n",
            "gujarat\n",
            "madhya-pradesh\n",
            "bihar\n",
            "chandigarh\n",
            "rajasthan\n",
            "arunachal-pradesh\n",
            "andhra-pradesh\n",
            "assam\n",
            "chhattisgarh\n",
            "goa\n",
            "haryana\n",
            "himachal-pradesh\n",
            "jammu-and-kashmir\n",
            "jharkhand\n",
            "kerala\n",
            "manipur\n",
            "meghalaya\n",
            "mizoram\n",
            "nagaland\n",
            "orissa\n",
            "punjab\n",
            "sikkim\n",
            "tripura\n",
            "uttarakhand\n",
            "andaman-and-nicobar-islands\n",
            "dadra-and-nagar-haveli\n",
            "daman-and-diu\n",
            "lakshadweep\n",
            "pondicherry\n",
            "1119\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.8605049483026971\n",
            "\n",
            "0.06478720310213326\n",
            "\n",
            "0.738266494636116\n",
            "\n",
            "0.20431365134109403\n",
            "\n",
            "0.3515423476303039\n",
            "\n",
            "0.7179505650879563\n",
            "\n",
            "0.00204452999055027\n",
            "\n",
            "0.600853409441294\n",
            "\n",
            "0.5221819497744629\n",
            "\n",
            "0.3711931571801983\n",
            "\n",
            "0.2184300434864458\n",
            "\n",
            "0.434897164463497\n",
            "\n",
            "0.6181850406723685\n",
            "\n",
            "0.9617979222706745\n",
            "\n",
            "0.7836064573309145\n",
            "\n",
            "0.12213410569035721\n",
            "\n",
            "0.5253012072786742\n",
            "\n",
            "0.580372682010737\n",
            "\n",
            "0.7904743388986127\n",
            "\n",
            "0.7806277946588076\n",
            "\n",
            "0.5989685081702936\n",
            "\n",
            "0.722274244943425\n",
            "\n",
            "0.47254771961623787\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.1579919166409608\n",
            "\n",
            "0.24656497505181785\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.42914171559747993\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.6450851562589714\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.2887419164958531\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.7280509588812758\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.4418095428850053\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.4868518138088672\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.44844759234264286\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.687982940501176\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.1824257464182849\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.2814769639758741\n",
            "\n",
            "0.653307289618776\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.9248954972222222\n",
            "\n",
            "0.8615626155814335\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.5229345334086922\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.5871832472607834\n",
            "\n",
            "0.9291307991112437\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.40632003742118206\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.6635867961873365\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.8022153027908517\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.2057032798360574\n",
            "\n",
            "0.026925232613043137\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.10298600447795847\n",
            "\n",
            "0.3208214570788521\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.114638080314721\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.20788245243128656\n",
            "\n",
            "0.7834632068750209\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.6350228836536114\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.754297049759135\n",
            "\n",
            "0.29638873690620626\n",
            "\n",
            "-1\n",
            "\n",
            "0.7554525152170207\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.2659773158897982\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.20858701398434887\n",
            "\n",
            "0.48795165697812704\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.5497227340377331\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.6985254350958858\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.04566538869218084\n",
            "\n",
            "-1\n",
            "\n",
            "0.3531662547349591\n",
            "\n",
            "0.9164541068600757\n",
            "\n",
            "0.10159779396165258\n",
            "\n",
            "-1\n",
            "\n",
            "0.8992925752768945\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.6649233888363284\n",
            "\n",
            "-1\n",
            "\n",
            "0.48719895958496107\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.19732306759905183\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.8480871828717533\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.9440163490529817\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.6335590117097958\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.25088725391841604\n",
            "\n",
            "-1\n",
            "\n",
            "0.034643785815054895\n",
            "\n",
            "-1\n",
            "\n",
            "0.5238690939770739\n",
            "\n",
            "0.09497735443868971\n",
            "\n",
            "-1\n",
            "\n",
            "0.46089134290565603\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.1783307379416198\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.24911359187014714\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.7045165370587014\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.6026211430194915\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.4613692091389341\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.16019861500571642\n",
            "\n",
            "0.7787500182192648\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.12299580368269092\n",
            "\n",
            "0.10042146022183729\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.8340746785639558\n",
            "\n",
            "-1\n",
            "\n",
            "0.754586037123573\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.2806628497868463\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.02462763662017231\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.005393056660148998\n",
            "\n",
            "0.5596581609686934\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.18684728114606197\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.5474302754212007\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.28307615708646294\n",
            "\n",
            "-1\n",
            "\n",
            "0.07052267940359047\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.9893830421481263\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.15500596104888675\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.9911507489660764\n",
            "\n",
            "-1\n",
            "\n",
            "0.16224031703011\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.25996709800489515\n",
            "\n",
            "0.06403568466094278\n",
            "\n",
            "0.7106941037582506\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.18318965655092945\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.48990311309649837\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.21299456457955168\n",
            "\n",
            "0.8396563455664866\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.3032507253646727\n",
            "\n",
            "0.7675129119706083\n",
            "\n",
            "0.17456040720566668\n",
            "\n",
            "-1\n",
            "\n",
            "0.03180009957808416\n",
            "\n",
            "0.7978981342666487\n",
            "\n",
            "-1\n",
            "\n",
            "0.16501392133253845\n",
            "\n",
            "0.17958696682498476\n",
            "\n",
            "0.7259920006298481\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.692509984867973\n",
            "\n",
            "0.37704681826007325\n",
            "\n",
            "0.48876012342889663\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.39404672795339646\n",
            "\n",
            "0.6088993389198059\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.1766844008774493\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.2379963045611838\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.9957338789160425\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.7930916997948385\n",
            "\n",
            "0.7781532048337644\n",
            "\n",
            "0.21051571656385026\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.5850780988902496\n",
            "\n",
            "0.9295018067909654\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.7238071485497849\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.686378068754623\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.977072805880557\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "0.42107710564706813\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "-1\n",
            "\n",
            "mumbai\n",
            "delhi\n",
            "bangalore\n",
            "hyderabad\n",
            "kolkata\n",
            "chennai\n",
            "agartala\n",
            "agra\n",
            "ajmer\n",
            "amaravati\n",
            "ahmedabad\n",
            "allahabad\n",
            "amritsar\n",
            "aurangabad\n",
            "bareilly\n",
            "bhopal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo1-3Cn1CFVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}